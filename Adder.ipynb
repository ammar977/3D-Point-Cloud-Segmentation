{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# import NALU files\n",
    "# import sys\n",
    "# sys.path.insert(0, 'C:/Users/Ammar/Documents/CV LAB internship/Sproj/NALU_files')\n",
    "# from nalu import NALU\n",
    "# from nac import NAC\n",
    "\n",
    "# import Keras items\n",
    "from keras.models import Model\n",
    "from keras.layers import Dense,Lambda,Concatenate,Input\n",
    "from keras import backend as K\n",
    "from keras.utils import to_categorical,plot_model\n",
    "from keras.initializers import constant\n",
    "\n",
    "# import other libs\n",
    "import numpy as np\n",
    "from itertools import combinations_with_replacement,product\n",
    "# from sklearn.model_selection import train_test_split\n",
    "\n",
    "from tensorflow import floor as tf_floor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model_name = 'adder_0-9'\n",
    "EPOCHS = 2000\n",
    "BATCH_SIZE = 4\n",
    "range_min = 0\n",
    "range_max = 9"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t (100, 3)\n"
     ]
    }
   ],
   "source": [
    "x = np.array(list(product(range(10),repeat = 2)))\n",
    "y = np.empty((100,3))\n",
    "y_sum = x[:,0] + x[:,1]\n",
    "y[:,0] = np.floor(y_sum / 10)\n",
    "y[:,1] = y_sum % 10\n",
    "y[:,2] = y_sum\n",
    "# y = to_categorical(y,num_classes=19)\n",
    "print('\\t',y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def net(inputs):\n",
    "    input_data = Input(shape = inputs)\n",
    "    addition = Dense(1,kernel_initializer='ones',use_bias=False)(input_data)\n",
    "    \n",
    "    carry = Dense(1,use_bias=False,kernel_initializer=constant(value=0.1))(addition)\n",
    "    carry = Lambda(lambda x: tf_floor(x))(carry)\n",
    "    \n",
    "    ones_digit = Dense(1,use_bias=False,kernel_initializer=constant(value=10))(carry)\n",
    "    temp = Concatenate()([ones_digit,addition])\n",
    "    ones_digit = Dense(1,use_bias=False)(temp)\n",
    "    \n",
    "    out = Concatenate()([carry,ones_digit,addition])\n",
    "    return Model(inputs = input_data,outputs = out)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "+ #### Model Initilization And Details"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_12 (InputLayer)           (None, 2)            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "dense_45 (Dense)                (None, 1)            2           input_12[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_46 (Dense)                (None, 1)            1           dense_45[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "lambda_12 (Lambda)              (None, 1)            0           dense_46[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_47 (Dense)                (None, 1)            1           lambda_12[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_21 (Concatenate)    (None, 2)            0           dense_47[0][0]                   \n",
      "                                                                 dense_45[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_48 (Dense)                (None, 1)            2           concatenate_21[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_22 (Concatenate)    (None, 3)            0           lambda_12[0][0]                  \n",
      "                                                                 dense_48[0][0]                   \n",
      "                                                                 dense_45[0][0]                   \n",
      "==================================================================================================\n",
      "Total params: 6\n",
      "Trainable params: 0\n",
      "Non-trainable params: 6\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = net((2,))\n",
    "model.layers[6].set_weights([np.array(([-1],[1]))])\n",
    "model.trainable = False\n",
    "model.compile(loss = 'MSE',optimizer = 'Adam',metrics = ['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "+ #### Fit Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Error when checking target: expected lambda_9 to have 1 dimensions, but got array with shape (100, 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-41-3db45595f20f>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m fitted = model.fit(x, y, validation_data = (x,y),\n\u001b[0;32m      2\u001b[0m           \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mBATCH_SIZE\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mEPOCHS\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m           verbose=1)\n\u001b[0m",
      "\u001b[1;32m~\\Anaconda2\\envs\\Dip-demo\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[0;32m   1628\u001b[0m             \u001b[0msample_weight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1629\u001b[0m             \u001b[0mclass_weight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mclass_weight\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1630\u001b[1;33m             batch_size=batch_size)\n\u001b[0m\u001b[0;32m   1631\u001b[0m         \u001b[1;31m# Prepare validation data.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1632\u001b[0m         \u001b[0mdo_validation\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda2\\envs\\Dip-demo\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36m_standardize_user_data\u001b[1;34m(self, x, y, sample_weight, class_weight, check_array_lengths, batch_size)\u001b[0m\n\u001b[0;32m   1478\u001b[0m                                     \u001b[0moutput_shapes\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1479\u001b[0m                                     \u001b[0mcheck_batch_axis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1480\u001b[1;33m                                     exception_prefix='target')\n\u001b[0m\u001b[0;32m   1481\u001b[0m         sample_weights = _standardize_sample_weights(sample_weight,\n\u001b[0;32m   1482\u001b[0m                                                      self._feed_output_names)\n",
      "\u001b[1;32m~\\Anaconda2\\envs\\Dip-demo\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36m_standardize_input_data\u001b[1;34m(data, names, shapes, check_batch_axis, exception_prefix)\u001b[0m\n\u001b[0;32m    111\u001b[0m                         \u001b[1;34m': expected '\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mnames\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m' to have '\u001b[0m \u001b[1;33m+\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    112\u001b[0m                         \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m' dimensions, but got array '\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 113\u001b[1;33m                         'with shape ' + str(data_shape))\n\u001b[0m\u001b[0;32m    114\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mcheck_batch_axis\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    115\u001b[0m                     \u001b[0mdata_shape\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdata_shape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Error when checking target: expected lambda_9 to have 1 dimensions, but got array with shape (100, 1)"
     ]
    }
   ],
   "source": [
    "fitted = model.fit(x, y, validation_data = (x,y),\n",
    "          batch_size=BATCH_SIZE, epochs=EPOCHS,\n",
    "          verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "+ #### Test Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t [0 0]  =  [ 0.  0.  0.]\n",
      "\t predicted:  [ 0.  0.  0.]\n",
      "\t [0 1]  =  [ 0.  1.  1.]\n",
      "\t predicted:  [ 0.  1.  1.]\n",
      "\t [0 2]  =  [ 0.  2.  2.]\n",
      "\t predicted:  [ 0.  2.  2.]\n",
      "\t [0 3]  =  [ 0.  3.  3.]\n",
      "\t predicted:  [ 0.  3.  3.]\n",
      "\t [0 4]  =  [ 0.  4.  4.]\n",
      "\t predicted:  [ 0.  4.  4.]\n",
      "\t [0 5]  =  [ 0.  5.  5.]\n",
      "\t predicted:  [ 0.  5.  5.]\n",
      "\t [0 6]  =  [ 0.  6.  6.]\n",
      "\t predicted:  [ 0.  6.  6.]\n",
      "\t [0 7]  =  [ 0.  7.  7.]\n",
      "\t predicted:  [ 0.  7.  7.]\n",
      "\t [0 8]  =  [ 0.  8.  8.]\n",
      "\t predicted:  [ 0.  8.  8.]\n",
      "\t [0 9]  =  [ 0.  9.  9.]\n",
      "\t predicted:  [ 0.  9.  9.]\n",
      "\t [1 0]  =  [ 0.  1.  1.]\n",
      "\t predicted:  [ 0.  1.  1.]\n",
      "\t [1 1]  =  [ 0.  2.  2.]\n",
      "\t predicted:  [ 0.  2.  2.]\n",
      "\t [1 2]  =  [ 0.  3.  3.]\n",
      "\t predicted:  [ 0.  3.  3.]\n",
      "\t [1 3]  =  [ 0.  4.  4.]\n",
      "\t predicted:  [ 0.  4.  4.]\n",
      "\t [1 4]  =  [ 0.  5.  5.]\n",
      "\t predicted:  [ 0.  5.  5.]\n",
      "\t [1 5]  =  [ 0.  6.  6.]\n",
      "\t predicted:  [ 0.  6.  6.]\n",
      "\t [1 6]  =  [ 0.  7.  7.]\n",
      "\t predicted:  [ 0.  7.  7.]\n",
      "\t [1 7]  =  [ 0.  8.  8.]\n",
      "\t predicted:  [ 0.  8.  8.]\n",
      "\t [1 8]  =  [ 0.  9.  9.]\n",
      "\t predicted:  [ 0.  9.  9.]\n",
      "\t [1 9]  =  [  1.   0.  10.]\n",
      "\t predicted:  [  1.   0.  10.]\n",
      "\t [2 0]  =  [ 0.  2.  2.]\n",
      "\t predicted:  [ 0.  2.  2.]\n",
      "\t [2 1]  =  [ 0.  3.  3.]\n",
      "\t predicted:  [ 0.  3.  3.]\n",
      "\t [2 2]  =  [ 0.  4.  4.]\n",
      "\t predicted:  [ 0.  4.  4.]\n",
      "\t [2 3]  =  [ 0.  5.  5.]\n",
      "\t predicted:  [ 0.  5.  5.]\n",
      "\t [2 4]  =  [ 0.  6.  6.]\n",
      "\t predicted:  [ 0.  6.  6.]\n",
      "\t [2 5]  =  [ 0.  7.  7.]\n",
      "\t predicted:  [ 0.  7.  7.]\n",
      "\t [2 6]  =  [ 0.  8.  8.]\n",
      "\t predicted:  [ 0.  8.  8.]\n",
      "\t [2 7]  =  [ 0.  9.  9.]\n",
      "\t predicted:  [ 0.  9.  9.]\n",
      "\t [2 8]  =  [  1.   0.  10.]\n",
      "\t predicted:  [  1.   0.  10.]\n",
      "\t [2 9]  =  [  1.   1.  11.]\n",
      "\t predicted:  [  1.   1.  11.]\n",
      "\t [3 0]  =  [ 0.  3.  3.]\n",
      "\t predicted:  [ 0.  3.  3.]\n",
      "\t [3 1]  =  [ 0.  4.  4.]\n",
      "\t predicted:  [ 0.  4.  4.]\n",
      "\t [3 2]  =  [ 0.  5.  5.]\n",
      "\t predicted:  [ 0.  5.  5.]\n",
      "\t [3 3]  =  [ 0.  6.  6.]\n",
      "\t predicted:  [ 0.  6.  6.]\n",
      "\t [3 4]  =  [ 0.  7.  7.]\n",
      "\t predicted:  [ 0.  7.  7.]\n",
      "\t [3 5]  =  [ 0.  8.  8.]\n",
      "\t predicted:  [ 0.  8.  8.]\n",
      "\t [3 6]  =  [ 0.  9.  9.]\n",
      "\t predicted:  [ 0.  9.  9.]\n",
      "\t [3 7]  =  [  1.   0.  10.]\n",
      "\t predicted:  [  1.   0.  10.]\n",
      "\t [3 8]  =  [  1.   1.  11.]\n",
      "\t predicted:  [  1.   1.  11.]\n",
      "\t [3 9]  =  [  1.   2.  12.]\n",
      "\t predicted:  [  1.   2.  12.]\n",
      "\t [4 0]  =  [ 0.  4.  4.]\n",
      "\t predicted:  [ 0.  4.  4.]\n",
      "\t [4 1]  =  [ 0.  5.  5.]\n",
      "\t predicted:  [ 0.  5.  5.]\n",
      "\t [4 2]  =  [ 0.  6.  6.]\n",
      "\t predicted:  [ 0.  6.  6.]\n",
      "\t [4 3]  =  [ 0.  7.  7.]\n",
      "\t predicted:  [ 0.  7.  7.]\n",
      "\t [4 4]  =  [ 0.  8.  8.]\n",
      "\t predicted:  [ 0.  8.  8.]\n",
      "\t [4 5]  =  [ 0.  9.  9.]\n",
      "\t predicted:  [ 0.  9.  9.]\n",
      "\t [4 6]  =  [  1.   0.  10.]\n",
      "\t predicted:  [  1.   0.  10.]\n",
      "\t [4 7]  =  [  1.   1.  11.]\n",
      "\t predicted:  [  1.   1.  11.]\n",
      "\t [4 8]  =  [  1.   2.  12.]\n",
      "\t predicted:  [  1.   2.  12.]\n",
      "\t [4 9]  =  [  1.   3.  13.]\n",
      "\t predicted:  [  1.   3.  13.]\n",
      "\t [5 0]  =  [ 0.  5.  5.]\n",
      "\t predicted:  [ 0.  5.  5.]\n",
      "\t [5 1]  =  [ 0.  6.  6.]\n",
      "\t predicted:  [ 0.  6.  6.]\n",
      "\t [5 2]  =  [ 0.  7.  7.]\n",
      "\t predicted:  [ 0.  7.  7.]\n",
      "\t [5 3]  =  [ 0.  8.  8.]\n",
      "\t predicted:  [ 0.  8.  8.]\n",
      "\t [5 4]  =  [ 0.  9.  9.]\n",
      "\t predicted:  [ 0.  9.  9.]\n",
      "\t [5 5]  =  [  1.   0.  10.]\n",
      "\t predicted:  [  1.   0.  10.]\n",
      "\t [5 6]  =  [  1.   1.  11.]\n",
      "\t predicted:  [  1.   1.  11.]\n",
      "\t [5 7]  =  [  1.   2.  12.]\n",
      "\t predicted:  [  1.   2.  12.]\n",
      "\t [5 8]  =  [  1.   3.  13.]\n",
      "\t predicted:  [  1.   3.  13.]\n",
      "\t [5 9]  =  [  1.   4.  14.]\n",
      "\t predicted:  [  1.   4.  14.]\n",
      "\t [6 0]  =  [ 0.  6.  6.]\n",
      "\t predicted:  [ 0.  6.  6.]\n",
      "\t [6 1]  =  [ 0.  7.  7.]\n",
      "\t predicted:  [ 0.  7.  7.]\n",
      "\t [6 2]  =  [ 0.  8.  8.]\n",
      "\t predicted:  [ 0.  8.  8.]\n",
      "\t [6 3]  =  [ 0.  9.  9.]\n",
      "\t predicted:  [ 0.  9.  9.]\n",
      "\t [6 4]  =  [  1.   0.  10.]\n",
      "\t predicted:  [  1.   0.  10.]\n",
      "\t [6 5]  =  [  1.   1.  11.]\n",
      "\t predicted:  [  1.   1.  11.]\n",
      "\t [6 6]  =  [  1.   2.  12.]\n",
      "\t predicted:  [  1.   2.  12.]\n",
      "\t [6 7]  =  [  1.   3.  13.]\n",
      "\t predicted:  [  1.   3.  13.]\n",
      "\t [6 8]  =  [  1.   4.  14.]\n",
      "\t predicted:  [  1.   4.  14.]\n",
      "\t [6 9]  =  [  1.   5.  15.]\n",
      "\t predicted:  [  1.   5.  15.]\n",
      "\t [7 0]  =  [ 0.  7.  7.]\n",
      "\t predicted:  [ 0.  7.  7.]\n",
      "\t [7 1]  =  [ 0.  8.  8.]\n",
      "\t predicted:  [ 0.  8.  8.]\n",
      "\t [7 2]  =  [ 0.  9.  9.]\n",
      "\t predicted:  [ 0.  9.  9.]\n",
      "\t [7 3]  =  [  1.   0.  10.]\n",
      "\t predicted:  [  1.   0.  10.]\n",
      "\t [7 4]  =  [  1.   1.  11.]\n",
      "\t predicted:  [  1.   1.  11.]\n",
      "\t [7 5]  =  [  1.   2.  12.]\n",
      "\t predicted:  [  1.   2.  12.]\n",
      "\t [7 6]  =  [  1.   3.  13.]\n",
      "\t predicted:  [  1.   3.  13.]\n",
      "\t [7 7]  =  [  1.   4.  14.]\n",
      "\t predicted:  [  1.   4.  14.]\n",
      "\t [7 8]  =  [  1.   5.  15.]\n",
      "\t predicted:  [  1.   5.  15.]\n",
      "\t [7 9]  =  [  1.   6.  16.]\n",
      "\t predicted:  [  1.   6.  16.]\n",
      "\t [8 0]  =  [ 0.  8.  8.]\n",
      "\t predicted:  [ 0.  8.  8.]\n",
      "\t [8 1]  =  [ 0.  9.  9.]\n",
      "\t predicted:  [ 0.  9.  9.]\n",
      "\t [8 2]  =  [  1.   0.  10.]\n",
      "\t predicted:  [  1.   0.  10.]\n",
      "\t [8 3]  =  [  1.   1.  11.]\n",
      "\t predicted:  [  1.   1.  11.]\n",
      "\t [8 4]  =  [  1.   2.  12.]\n",
      "\t predicted:  [  1.   2.  12.]\n",
      "\t [8 5]  =  [  1.   3.  13.]\n",
      "\t predicted:  [  1.   3.  13.]\n",
      "\t [8 6]  =  [  1.   4.  14.]\n",
      "\t predicted:  [  1.   4.  14.]\n",
      "\t [8 7]  =  [  1.   5.  15.]\n",
      "\t predicted:  [  1.   5.  15.]\n",
      "\t [8 8]  =  [  1.   6.  16.]\n",
      "\t predicted:  [  1.   6.  16.]\n",
      "\t [8 9]  =  [  1.   7.  17.]\n",
      "\t predicted:  [  1.   7.  17.]\n",
      "\t [9 0]  =  [ 0.  9.  9.]\n",
      "\t predicted:  [ 0.  9.  9.]\n",
      "\t [9 1]  =  [  1.   0.  10.]\n",
      "\t predicted:  [  1.   0.  10.]\n",
      "\t [9 2]  =  [  1.   1.  11.]\n",
      "\t predicted:  [  1.   1.  11.]\n",
      "\t [9 3]  =  [  1.   2.  12.]\n",
      "\t predicted:  [  1.   2.  12.]\n",
      "\t [9 4]  =  [  1.   3.  13.]\n",
      "\t predicted:  [  1.   3.  13.]\n",
      "\t [9 5]  =  [  1.   4.  14.]\n",
      "\t predicted:  [  1.   4.  14.]\n",
      "\t [9 6]  =  [  1.   5.  15.]\n",
      "\t predicted:  [  1.   5.  15.]\n",
      "\t [9 7]  =  [  1.   6.  16.]\n",
      "\t predicted:  [  1.   6.  16.]\n",
      "\t [9 8]  =  [  1.   7.  17.]\n",
      "\t predicted:  [  1.   7.  17.]\n",
      "\t [9 9]  =  [  1.   8.  18.]\n",
      "\t predicted:  [  1.   8.  18.]\n"
     ]
    }
   ],
   "source": [
    "out = model.predict(x)\n",
    "for i in range(100):\n",
    "    print ('\\t',x[i,:],' = ', y[i])\n",
    "    print('\\t predicted: ',out[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "+ #### Save Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.save_weights('adder_0-9_classifier.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plot_model(model,to_file = 'mul_0-9.png',show_shapes=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
