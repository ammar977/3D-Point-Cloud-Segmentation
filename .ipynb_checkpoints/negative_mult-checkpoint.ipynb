{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using matplotlib backend: Qt5Agg\n"
     ]
    }
   ],
   "source": [
    "%matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "\n",
    "# import NALU files\n",
    "import sys\n",
    "sys.path.insert(0, 'C:/Users/Ammar/Documents/CV LAB internship/Sproj/NALU_files')\n",
    "from nalu import NALU\n",
    "from nac import NAC\n",
    "\n",
    "# import Keras items\n",
    "from keras.models import Model\n",
    "from keras.layers import Dense,Lambda,Concatenate,Input,Flatten,Reshape\n",
    "from keras.callbacks import ModelCheckpoint, EarlyStopping, CSVLogger, ReduceLROnPlateau, TensorBoard\n",
    "from keras import backend as K\n",
    "# from keras.utils import to_categorical,plot_model\n",
    "from keras.initializers import constant\n",
    "from keras.constraints import MinMaxNorm\n",
    "\n",
    "# import other libs\n",
    "import os\n",
    "import numpy as np\n",
    "# from itertools import combinations_with_replacement,product\n",
    "# from sklearn.model_selection import train_test_split\n",
    "from tensorflow import floor as tf_floor\n",
    "# from tensorflow.dtypes import as_string\n",
    "# from tensorflow.strings import join,to_number\n",
    "# from tensorflow import add"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = 'generalized_mult'\n",
    "EPOCHS = 10\n",
    "batch_size = 4 \n",
    "num_digits = 3\n",
    "range_min = 0\n",
    "range_max = 999\n",
    "train_samples = 10000\n",
    "test_samples = 1000\n",
    "num_pts = 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sep(x,num_digits):\n",
    "    x = np.array([int(i) for i in str(x)])\n",
    "    while (x.shape[0] < num_digits):\n",
    "        x = np.insert(x,0,0)\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_a = np.random.randint(low = range_min,high = range_max,size =100)\n",
    "x_train_b = np.random.randint(low = range_min,high = range_max,size =100)\n",
    "\n",
    "x_train = np.empty((100,2,num_digits),dtype = np.int32)\n",
    "\n",
    "y_train_a = x_train_a * x_train_b\n",
    "y_train = np.empty((100,num_digits*2),dtype = np.int32)\n",
    "\n",
    "for i in range(100):\n",
    "    x_train[i,0] = sep(x_train_a[i],num_digits)\n",
    "    \n",
    "    x_train[i,1] = sep(x_train_b[i],num_digits)\n",
    "    y_train[i] = sep(y_train_a[i],num_digits*2)\n",
    "    \n",
    "print('\\t',x_train.shape)\n",
    "print('\\t',y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_pts_plane(normal,n_pts,min_range = -10000,max_range = 10000,noise_d = 0):\n",
    "    # Generates n number of points \n",
    "    # normal : array like plane normal [a,b,c,d]\n",
    "    # n_pts: total points to generate\n",
    "    # min_range,max_range: range b/w which points are to be generated. default is -10000 to 10000\n",
    "    # noise_d: +- noise allowed in generated point from plane in terms of d = ax + by + cz. default = 0\n",
    "    # return np array of generated points 3xn_pts\n",
    "    \n",
    "    planar_points = np.empty((n_pts,3),dtype = np.int32)\n",
    "    num = 0\n",
    "    plane_normal = normal[:3]\n",
    "    d = normal[3]\n",
    "    while (num < n_pts):\n",
    "        p = np.random.randint(min_range,max_range,size = (1,3))\n",
    "        dot = np.dot(p,plane_normal)\n",
    "        if (dot >= d - noise_d and dot <= d + noise_d ):\n",
    "            planar_points[num,:] = np.squeeze(p.T,-1)\n",
    "            num = num + 1\n",
    "    return planar_points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# random plane normals\n",
    "train_data = np.empty((train_samples,num_pts,3))\n",
    "train_normals = np.empty((train_samples,4))\n",
    "for i in range(train_samples):\n",
    "    plane_normal = np.random.randint(low = range_min,high = range_max, size = (3,1))\n",
    "    plane_normal = plane_normal / np.linalg.norm(plane_normal)\n",
    "    p = np.random.randint(range_min,range_max,size = (1,3))\n",
    "    d = np.dot(p,plane_normal)\n",
    "    train_normals[i,:] = np.append(plane_normal[:,0],d[0])\n",
    "    train_data[i,:,:] = generate_pts_plane(train_normals[i,:],num_pts,noise_d = 0.05)\n",
    "    print('\\t',i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = np.empty((test_samples,num_pts,3))\n",
    "test_normals = np.empty((test_samples,4))\n",
    "for i in range(test_samples):\n",
    "    plane_normal = np.random.randint(low = range_min,high = range_max, size = (3,1))\n",
    "    plane_normal = plane_normal / np.linalg.norm(plane_normal)\n",
    "    p = np.random.randint(range_min,range_max,size = (1,3))\n",
    "    d = np.dot(p,plane_normal)\n",
    "    test_normals[i,:] = np.append(plane_normal[:,0],d[0])\n",
    "    test_data[i,:,:] = generate_pts_plane(test_normals[i,:],num_pts,noise_d = 0.05)\n",
    "    print('\\t',i)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data to train plane normal model \n",
    "train_points = np.empty((train_samples,3,3))\n",
    "train_normals = np.zeros((train_samples,3))\n",
    "\n",
    "for i in range(train_samples):\n",
    "    points = np.random.uniform(low = range_min,high = range_max,size = (3,3))\n",
    "    train_normals[i,:] = np.cross(points[0,:] - points[1,:],points[2,:] - points[1,:])\n",
    "#     train_normals[i,:] = n / np.linalg.norm(n)\n",
    "    train_points[i,:,:] = points\n",
    "    \n",
    "    \n",
    "test_points = np.empty((test_samples,3,3))\n",
    "test_normals = np.zeros((test_samples,3))\n",
    "\n",
    "for i in range(test_samples):\n",
    "    points = np.random.uniform(low = range_min,high = range_max,size = (3,3))\n",
    "    test_normals[i,:] = np.cross(points[0,:] - points[1,:],points[2,:] - points[1,:])\n",
    "#     test_normals[i,:] = n / np.linalg.norm(n)\n",
    "    test_points[i,:,:] = points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data to train cross product model\n",
    "train_points = np.empty((train_samples,2,3))\n",
    "train_normals = np.zeros((train_samples,3))\n",
    "\n",
    "for i in range(train_samples):\n",
    "    points = np.random.randint(low = range_min,high = range_max,size = (2,3))\n",
    "    train_normals[i,:] = np.cross(points[0,:], points[1,:])\n",
    "#     train_normals[i,:] = n / np.linalg.norm(n)\n",
    "    train_points[i,:,:] = points\n",
    "    \n",
    "    \n",
    "test_points = np.empty((test_samples,2,3))\n",
    "test_normals = np.zeros((test_samples,3))\n",
    "\n",
    "for i in range(test_samples):\n",
    "    points = np.random.randint(low = range_min,high = range_max,size = (2,3))\n",
    "    test_normals[i,:] = np.cross(points[0,:], points[1,:])\n",
    "#     test_normals[i,:] = n / np.linalg.norm(n)\n",
    "    test_points[i,:,:] = points"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def net_diff(inputs):\n",
    "    input_data = Input(shape = inputs)\n",
    "    net = Flatten()(input_data)\n",
    "    net = Dense(6)(net)\n",
    "    return Model(inputs = input_data, outputs = net)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_diff = net_diff((3,3))\n",
    "model_diff.compile(loss = 'MSE',optimizer = 'Adam',metrics = ['accuracy'])\n",
    "model_diff.load_weights('diff.h5')\n",
    "model_diff.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def net(inputs):\n",
    "    input_data = Input(shape = inputs)\n",
    "    out = Dense(30,activation = 'relu',name='my_layer')(input_data)\n",
    "    out = Dense(82,activation='softmax')(out)\n",
    "    \n",
    "    return Model(inputs = input_data,outputs = out)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_mul = net((2,))\n",
    "model_mul.trainable = False\n",
    "model_mul.compile(loss = 'categorical_crossentropy',optimizer = 'Adam',metrics = ['accuracy'])\n",
    "# model_mul.summary()\n",
    "model_mul.load_weights('mul_0-9_classifier.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def separator(inputs):\n",
    "    input_data = Input(shape = inputs)\n",
    "    # addition = Dense(1,kernel_initializer='ones',use_bias=False)(input_data)\n",
    "    carry = Dense(1,use_bias=False,kernel_initializer=constant(value=0.1))(input_data)\n",
    "    carry = Lambda(lambda x: tf_floor(x))(carry)\n",
    "    \n",
    "    ones_digit = Dense(1,use_bias=False,kernel_initializer=constant(value=10))(carry)\n",
    "    temp = Concatenate()([ones_digit,input_data])\n",
    "    ones_digit = Dense(1,use_bias=False)(temp)\n",
    "    \n",
    "    out = Concatenate()([carry,ones_digit])\n",
    "    return Model(inputs = input_data,outputs = out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_separator = separator((1,))\n",
    "model_separator.layers[5].set_weights([np.array(([-1],[1]))])\n",
    "model_separator.trainable = False\n",
    "model_separator.compile(loss = 'MSE',optimizer = 'Adam',metrics = ['accuracy'])\n",
    "# model_separator.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def net_sub(inputs):\n",
    "    input_data = Input(shape=inputs)\n",
    "    out = Dense(1,use_bias = False)(input_data)\n",
    "    \n",
    "    return Model(inputs = input_data,outputs =out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_sub = net_sub((2,))\n",
    "model_sub.layers[1].set_weights([np.array(([-1],[1]))])\n",
    "model_sub.trainable=False\n",
    "model_sub.compile(loss = 'MSE',optimizer = 'Adam',metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def net_separate(inputs):\n",
    "    input_data = Input(shape = inputs)\n",
    "    n = input_data.shape[-1]\n",
    "#     data = Lambda(lambda x: K.abs(x))(input_data)\n",
    "    data = input_data\n",
    "    digits = []\n",
    "    for i in range(2):\n",
    "        \n",
    "        temp = Dense(1,use_bias=False,kernel_initializer=constant(value=0.1))(data)\n",
    "        temp = Lambda(lambda x: tf_floor(x))(temp)\n",
    "        \n",
    "        digit = Dense(1,use_bias=False,kernel_initializer=constant(value=10))(temp)\n",
    "        temp1 = Concatenate()([digit,data])\n",
    "        digit = model_sub(temp1)\n",
    "#         digit = Lambda(lambda x: tf_floor(x))(digit)\n",
    "        digits.append(digit)\n",
    "        data = temp\n",
    "    \n",
    "    digits.append(data)\n",
    "    digits = digits[::-1]\n",
    "    out = Concatenate()(digits)\n",
    "    return Model(inputs = input_data,outputs = out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_separate = net_separate((1,))\n",
    "model_separate.trainable=False\n",
    "model_separate.compile(loss = 'MSE',optimizer = 'Adam')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def net_regression(inputs):\n",
    "    input_data = Input(shape=inputs)\n",
    "    out = Dense(3,use_bias=False)(input_data)\n",
    "    \n",
    "    return Model(inputs = input_data,outputs = out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_reg = net_regression((30,))\n",
    "model_reg.compile(loss='MSE',optimizer='adam',metrics=['accuracy'])\n",
    "# model_reg.summary()\n",
    "model_reg.trainable=False\n",
    "model_reg.load_weights('regression_test.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def net_mul(inputs):\n",
    "    input_data = Input(shape = inputs)\n",
    "    n = input_data[0].shape[-1]\n",
    "    m = input_data[1].shape[-1]\n",
    "    # get initial products\n",
    "    products=[]\n",
    "    for i in range(input_data.shape[-1]):\n",
    "        mul = Lambda(lambda x: x[:,0,i:i+1])(input_data)\n",
    "        for j in range(input_data.shape[-1]):\n",
    "            a = Lambda(lambda x: x[:,1,j:j+1])(input_data)\n",
    "            concat = Concatenate()([a,mul])\n",
    "            prod = model_mul(concat)\n",
    "            prod =  Lambda(lambda x: K.expand_dims(K.cast(K.argmax(x),dtype ='float32')))(prod)\n",
    "            products.append(prod)\n",
    "            \n",
    "    # get individual rows\n",
    "    products = products[::-1]\n",
    "    row_values = []\n",
    "    prod_index = 0\n",
    "    for r in range(n):\n",
    "        for i in range(m+1):\n",
    "            if i==0:\n",
    "                sep = model_separator(products[prod_index])\n",
    "                ones_digit = Lambda(lambda x: x[:,1:])(sep)\n",
    "                carry = Lambda(lambda x: x[:,0:1])(sep)\n",
    "                row_values.append(ones_digit)\n",
    "                prod_index+=1\n",
    "                \n",
    "            elif i == m :\n",
    "                row_values.append(carry)\n",
    "            else:\n",
    "                concat = Concatenate()([products[prod_index],carry])\n",
    "                addition =  Dense(1,use_bias=False,kernel_initializer='ones')(concat)\n",
    "                sep = model_separator(addition)\n",
    "                ones_digit = Lambda(lambda x: x[:,1:])(sep)\n",
    "                carry = Lambda(lambda x: x[:,0:1])(sep)\n",
    "                row_values.append(ones_digit)\n",
    "                prod_index+=1\n",
    "                \n",
    "    final_row = []\n",
    "    current_ind = 0\n",
    "    for i in range(m+n):\n",
    "        if i == 0:\n",
    "            final_row.append(row_values[0])\n",
    "            sep = model_separator(row_values[0])\n",
    "            carry = Lambda(lambda x: x[:,0:1])(sep)\n",
    "            current_ind+=1\n",
    "        else:\n",
    "            to_add = []\n",
    "            to_add.append(row_values[current_ind])\n",
    "            to_add.append(carry)\n",
    "            next_ind = current_ind + m\n",
    "            while(next_ind < n * (m+1) and next_ind%(m+1)!=0):\n",
    "                to_add.append(row_values[next_ind])\n",
    "                next_ind+=m\n",
    "            if (next_ind < n * (m+1) and next_ind%(m+1)==0):\n",
    "                to_add.append(row_values[next_ind])\n",
    "                \n",
    "            concat = Concatenate()(to_add)\n",
    "            addition =  Dense(1,use_bias=False,kernel_initializer='ones')(concat)\n",
    "            sep = model_separator(addition)\n",
    "            ones_digit = Lambda(lambda x: x[:,1:])(sep)\n",
    "            carry = Lambda(lambda x: x[:,0:1])(sep)\n",
    "            final_row.append(ones_digit)\n",
    "            \n",
    "            if (current_ind + 1) % (m+1) !=0:\n",
    "                current_ind+=1\n",
    "            else:\n",
    "                current_ind+=m+1\n",
    "\n",
    "    \n",
    "    concat = Concatenate()(final_row[::-1])\n",
    "    return Model(inputs = input_data,outputs =concat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_mult = net_mul((2,num_digits))\n",
    "model_mult.trainable=False\n",
    "model_mult.compile(loss = 'MSE',optimizer = 'Adam',metrics = ['accuracy'])\n",
    "# model_mult.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def net_merge(inputs):\n",
    "    input_data = Input(shape=inputs)\n",
    "    add_list = []\n",
    "    n = input_data.shape[-1]\n",
    "    i = 0\n",
    "    while(n>0):\n",
    "        temp = Lambda(lambda x: x[:,n-1:n])(input_data)\n",
    "        temp = Dense(1,kernel_initializer=constant(value=10**i))(temp)\n",
    "        add_list.append(temp)\n",
    "        i = i+1\n",
    "        n = n-1\n",
    "        \n",
    "    concat = Concatenate()(add_list)\n",
    "    out = Dense(1,kernel_initializer='ones')(concat)\n",
    "    return Model(inputs = input_data,outputs =out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_merge = net_merge((num_digits*2,))\n",
    "model_merge.trainable=False\n",
    "model_merge.compile(loss = 'MSE',optimizer = 'Adam')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def net_plane(inputs):\n",
    "    \n",
    "    input_data = Input(shape = inputs)\n",
    "    # Take 2 difference vectors\n",
    "    out = model_diff(input_data)\n",
    "#     out = Lambda(lambda x: K.abs(x))(out)\n",
    "    \n",
    "    # separate difference vectors to give to multiplication model\n",
    "    concat_list = []\n",
    "    for i in range(out.shape[-1]):\n",
    "        temp = Lambda(lambda x: x[:,i:i+1])(out)\n",
    "        temp = model_separate(temp)\n",
    "        temp = Lambda(lambda x: K.expand_dims(x,1))(temp)\n",
    "        concat_list.append(temp)\n",
    "\n",
    "    out = Concatenate(axis = 1)(concat_list)\n",
    "    \n",
    "    # Multiply components of difference vectors\n",
    "    concat_list = []\n",
    "    for i1 in range(out.shape[1]):\n",
    "        temp1 = Lambda(lambda x: x[:,i1:i1+1])(out)\n",
    "        for j1 in range(out.shape[1]):\n",
    "            if i1 == j1:\n",
    "                continue\n",
    "            temp2  = Lambda(lambda x: x[:,j1:j1+1])(out)\n",
    "            mult_input = Concatenate(axis = 1)([temp1,temp2])\n",
    "#             temp = model_mult(concat)\n",
    "\n",
    "            n = mult_input[:,0].shape[-1]\n",
    "            m = mult_input[:,1].shape[-1]\n",
    "            # get initial products\n",
    "            products=[]\n",
    "            for i in range(mult_input.shape[-1]):\n",
    "                mul = Lambda(lambda x: x[:,0,i:i+1])(mult_input)\n",
    "                for j in range(mult_input.shape[-1]):\n",
    "                    a = Lambda(lambda x: x[:,1,j:j+1])(mult_input)\n",
    "                    concat = Concatenate()([a,mul])\n",
    "                    prod = model_mul(concat)\n",
    "                    prod =  Lambda(lambda x: K.expand_dims(K.cast(K.argmax(x),dtype ='float32')))(prod)\n",
    "                    products.append(prod)\n",
    "\n",
    "            # get individual rows\n",
    "            products = products[::-1]\n",
    "            row_values = []\n",
    "            prod_index = 0\n",
    "            for r in range(n):\n",
    "                for i in range(m+1):\n",
    "                    if i==0:\n",
    "                        sep = model_separator(products[prod_index])\n",
    "                        ones_digit = Lambda(lambda x: x[:,1:])(sep)\n",
    "                        carry = Lambda(lambda x: x[:,0:1])(sep)\n",
    "                        row_values.append(ones_digit)\n",
    "                        prod_index+=1\n",
    "\n",
    "                    elif i == m :\n",
    "                        row_values.append(carry)\n",
    "                    else:\n",
    "                        concat = Concatenate()([products[prod_index],carry])\n",
    "                        addition =  Dense(1,use_bias=False,kernel_initializer='ones')(concat)\n",
    "                        sep = model_separator(addition)\n",
    "                        ones_digit = Lambda(lambda x: x[:,1:])(sep)\n",
    "                        carry = Lambda(lambda x: x[:,0:1])(sep)\n",
    "                        row_values.append(ones_digit)\n",
    "                        prod_index+=1\n",
    "\n",
    "            final_row = []\n",
    "            current_ind = 0\n",
    "            for i in range(m+n):\n",
    "                if i == 0:\n",
    "                    final_row.append(row_values[0])\n",
    "                    sep = model_separator(row_values[0])\n",
    "                    carry = Lambda(lambda x: x[:,0:1])(sep)\n",
    "                    current_ind+=1\n",
    "                else:\n",
    "                    to_add = []\n",
    "                    to_add.append(row_values[current_ind])\n",
    "                    to_add.append(carry)\n",
    "                    next_ind = current_ind + m\n",
    "                    while(next_ind < n * (m+1) and next_ind%(m+1)!=0):\n",
    "                        to_add.append(row_values[next_ind])\n",
    "                        next_ind+=m\n",
    "                    if (next_ind < n * (m+1) and next_ind%(m+1)==0):\n",
    "                        to_add.append(row_values[next_ind])\n",
    "\n",
    "                    concat = Concatenate()(to_add)\n",
    "                    addition =  Dense(1,use_bias=False,kernel_initializer='ones')(concat)\n",
    "                    sep = model_separator(addition)\n",
    "                    ones_digit = Lambda(lambda x: x[:,1:])(sep)\n",
    "                    carry = Lambda(lambda x: x[:,0:1])(sep)\n",
    "                    final_row.append(ones_digit)\n",
    "\n",
    "                    if (current_ind + 1) % (m+1) !=0:\n",
    "                        current_ind+=1\n",
    "                    else:\n",
    "                        current_ind+=m+1\n",
    "\n",
    "\n",
    "            mult_output = Concatenate()(final_row[::-1])\n",
    "            \n",
    "#             print(mult_output.shape)\n",
    "#             temp = model_merge(mult_output)\n",
    "            add_list = []\n",
    "            n = mult_output.shape[-1]\n",
    "            i = 0\n",
    "            while(n>0):\n",
    "                temp = Lambda(lambda x: x[:,n-1:n])(mult_output)\n",
    "                temp = Dense(1,kernel_initializer=constant(value=10**i))(temp)\n",
    "                add_list.append(temp)\n",
    "                i = i+1\n",
    "                n = n-1\n",
    "\n",
    "            concat = Concatenate()(add_list)\n",
    "            merge_output = Dense(1,kernel_initializer='ones')(concat)\n",
    "\n",
    "            concat_list.append(merge_output)\n",
    "\n",
    "    out = Concatenate()(concat_list)\n",
    "\n",
    "    # Let the model learn the rest\n",
    "    out = Dense(3)(out)\n",
    "    \n",
    "    return Model(inputs = input_data, outputs = out)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def net_cross(inputs):\n",
    "    \n",
    "    input_data = Input(shape = inputs)\n",
    "    out = Flatten()(input_data)\n",
    "    # separate difference vectors to give to multiplication model\n",
    "    concat_list = []\n",
    "    for i in range(6):\n",
    "        temp = Lambda(lambda x: x[:,i:i+1])(out)\n",
    "        temp = model_separate(temp)\n",
    "        temp = Lambda(lambda x: K.expand_dims(x,1))(temp)\n",
    "        concat_list.append(temp)\n",
    "\n",
    "    out = Concatenate(axis = 1)(concat_list)\n",
    "    \n",
    "    # Multiply components of difference vectors\n",
    "    concat_list = []\n",
    "    for i1 in range(out.shape[1]):\n",
    "        temp1 = Lambda(lambda x: x[:,i1:i1+1])(out)\n",
    "        for j1 in range(out.shape[1]):\n",
    "            if i1 == j1:\n",
    "                continue\n",
    "            temp2 = Lambda(lambda x: x[:,j1:j1+1])(out)\n",
    "            mult_input = Concatenate(axis = 1)([temp1,temp2])\n",
    "#             temp = model_mult(concat)\n",
    "\n",
    "            n = mult_input[:,0].shape[-1]\n",
    "            m = mult_input[:,1].shape[-1]\n",
    "            # get initial products\n",
    "            products=[]\n",
    "            for i in range(mult_input.shape[-1]):\n",
    "                mul = Lambda(lambda x: x[:,0,i:i+1])(mult_input)\n",
    "                for j in range(mult_input.shape[-1]):\n",
    "                    a = Lambda(lambda x: x[:,1,j:j+1])(mult_input)\n",
    "                    concat = Concatenate()([a,mul])\n",
    "                    prod = model_mul(concat)\n",
    "                    prod =  Lambda(lambda x: K.expand_dims(K.cast(K.argmax(x),dtype ='float32')))(prod)\n",
    "                    products.append(prod)\n",
    "\n",
    "            # get individual rows\n",
    "            products = products[::-1]\n",
    "            row_values = []\n",
    "            prod_index = 0\n",
    "            for r in range(n):\n",
    "                for i in range(m+1):\n",
    "                    if i==0:\n",
    "                        sep = model_separator(products[prod_index])\n",
    "                        ones_digit = Lambda(lambda x: x[:,1:])(sep)\n",
    "                        carry = Lambda(lambda x: x[:,0:1])(sep)\n",
    "                        row_values.append(ones_digit)\n",
    "                        prod_index+=1\n",
    "\n",
    "                    elif i == m :\n",
    "                        row_values.append(carry)\n",
    "                    else:\n",
    "                        concat = Concatenate()([products[prod_index],carry])\n",
    "                        addition =  Dense(1,use_bias=False,kernel_initializer='ones')(concat)\n",
    "                        sep = model_separator(addition)\n",
    "                        ones_digit = Lambda(lambda x: x[:,1:])(sep)\n",
    "                        carry = Lambda(lambda x: x[:,0:1])(sep)\n",
    "                        row_values.append(ones_digit)\n",
    "                        prod_index+=1\n",
    "\n",
    "            final_row = []\n",
    "            current_ind = 0\n",
    "            for i in range(m+n):\n",
    "                if i == 0:\n",
    "                    final_row.append(row_values[0])\n",
    "                    sep = model_separator(row_values[0])\n",
    "                    carry = Lambda(lambda x: x[:,0:1])(sep)\n",
    "                    current_ind+=1\n",
    "                else:\n",
    "                    to_add = []\n",
    "                    to_add.append(row_values[current_ind])\n",
    "                    to_add.append(carry)\n",
    "                    next_ind = current_ind + m\n",
    "                    while(next_ind < n * (m+1) and next_ind%(m+1)!=0):\n",
    "                        to_add.append(row_values[next_ind])\n",
    "                        next_ind+=m\n",
    "                    if (next_ind < n * (m+1) and next_ind%(m+1)==0):\n",
    "                        to_add.append(row_values[next_ind])\n",
    "\n",
    "                    concat = Concatenate()(to_add)\n",
    "                    addition =  Dense(1,use_bias=False,kernel_initializer='ones')(concat)\n",
    "                    sep = model_separator(addition)\n",
    "                    ones_digit = Lambda(lambda x: x[:,1:])(sep)\n",
    "                    carry = Lambda(lambda x: x[:,0:1])(sep)\n",
    "                    final_row.append(ones_digit)\n",
    "\n",
    "                    if (current_ind + 1) % (m+1) !=0:\n",
    "                        current_ind+=1\n",
    "                    else:\n",
    "                        current_ind+=m+1\n",
    "\n",
    "\n",
    "            mult_output = Concatenate()(final_row[::-1])\n",
    "            \n",
    "#             temp = model_merge(mult_output)\n",
    "            add_list = []\n",
    "            n = mult_output.shape[-1]\n",
    "            i = 0\n",
    "            while(n>0):\n",
    "                temp = Lambda(lambda x: x[:,n-1:n])(mult_output)\n",
    "                temp = Dense(1,kernel_initializer=constant(value=10**i))(temp)\n",
    "                add_list.append(temp)\n",
    "                i = i+1\n",
    "                n = n-1\n",
    "\n",
    "            concat = Concatenate()(add_list)\n",
    "            merge_output = Dense(1,kernel_initializer='ones',use_bias=False)(concat)\n",
    "\n",
    "            concat_list.append(merge_output)\n",
    "            \n",
    "    out = Concatenate()(concat_list)\n",
    "\n",
    "    # Let the model learn the rest\n",
    "#     out = Dense(18,activation='sigmoid')(out)\n",
    "#     out = Dense(9,activation='sigmoid')(out)\n",
    "#     out = Dense(3,activation='linear')(out)\n",
    "    \n",
    "    out = model_reg(out)\n",
    "\n",
    "    \n",
    "    return Model(inputs = input_data, outputs = out)    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "+ #### Model Initilization And Details"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = net_cross((2,3))\n",
    "model.compile(loss = 'MSE',optimizer = 'adam',metrics = ['accuracy'])\n",
    "# model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = 'cross_product_17'\n",
    "\n",
    "if not os.path.exists('./'+model_name):\n",
    "    os.mkdir(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# checkpoint = ModelCheckpoint(model_name+'/'+model_name+'-{epoch:02d}-{val_loss:.2f}.h5', \n",
    "#                              monitor='val_loss', verbose=1, save_best_only=True, mode='auto')\n",
    "cvslogger = CSVLogger(model_name+'/logs.csv', separator=',', append=True)\n",
    "reducelr = ReduceLROnPlateau(monitor='val_loss', factor=0.2, patience=3, min_lr=0.000001)\n",
    "# tensorboard = LRTensorBoard(log_dir='./'+model_name, histogram_freq=0, write_graph=True, write_grads=1, \n",
    "#                             batch_size=batch_size, write_images=True)\n",
    "\n",
    "callbacks = [cvslogger, reducelr]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 10000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      " 9968/10000 [============================>.] - ETA: 0s - loss: 96997174868.6485 - acc: 0.5616"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-26-82fe55b3aa1c>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m fitted = model.fit(train_points, train_normals, validation_data = (test_points,test_normals),\n\u001b[1;32m----> 2\u001b[1;33m           batch_size=16, epochs=1 ,verbose=1)\n\u001b[0m",
      "\u001b[1;32m~\\.conda\\envs\\neuralnets\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[0;32m   1037\u001b[0m                                         \u001b[0minitial_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1038\u001b[0m                                         \u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1039\u001b[1;33m                                         validation_steps=validation_steps)\n\u001b[0m\u001b[0;32m   1040\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1041\u001b[0m     def evaluate(self, x=None, y=None,\n",
      "\u001b[1;32m~\\.conda\\envs\\neuralnets\\lib\\site-packages\\keras\\engine\\training_arrays.py\u001b[0m in \u001b[0;36mfit_loop\u001b[1;34m(model, f, ins, out_labels, batch_size, epochs, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch, steps_per_epoch, validation_steps)\u001b[0m\n\u001b[0;32m    210\u001b[0m                         val_outs = test_loop(model, val_f, val_ins,\n\u001b[0;32m    211\u001b[0m                                              \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 212\u001b[1;33m                                              verbose=0)\n\u001b[0m\u001b[0;32m    213\u001b[0m                         \u001b[0mval_outs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mval_outs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    214\u001b[0m                         \u001b[1;31m# Same labels assumed.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\neuralnets\\lib\\site-packages\\keras\\engine\\training_arrays.py\u001b[0m in \u001b[0;36mtest_loop\u001b[1;34m(model, f, ins, batch_size, verbose, steps)\u001b[0m\n\u001b[0;32m    390\u001b[0m                 \u001b[0mins_batch\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    391\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 392\u001b[1;33m             \u001b[0mbatch_outs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    393\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch_outs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    394\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0mbatch_index\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\neuralnets\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m   2713\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_legacy_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2714\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2715\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2716\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2717\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mpy_any\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mis_tensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\neuralnets\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py\u001b[0m in \u001b[0;36m_call\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m   2673\u001b[0m             \u001b[0mfetched\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun_metadata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2674\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2675\u001b[1;33m             \u001b[0mfetched\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2676\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mfetched\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2677\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\neuralnets\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1437\u001b[0m           ret = tf_session.TF_SessionRunCallable(\n\u001b[0;32m   1438\u001b[0m               \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstatus\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1439\u001b[1;33m               run_metadata_ptr)\n\u001b[0m\u001b[0;32m   1440\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1441\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "fitted = model.fit(train_points, train_normals, validation_data = (test_points,test_normals),\n",
    "          batch_size=16, epochs=1 ,verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "+ #### Test Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def func(x):\n",
    "    x = x.flat\n",
    "    ans = []\n",
    "    for i in range(6):\n",
    "        for j in range(6):\n",
    "            if i==j:\n",
    "                continue\n",
    "            ans.append(x[i] * x[j])\n",
    "    return ans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "actual answer:  [ 0.78690259 -0.60943698 -0.09680331]\n",
      "predicted answer:  [[ 0.78690284 -0.60943663 -0.09680329]]\n",
      "actual answer:  [ 349550. -270718.  -43001.]\n",
      "predicted answer:  [[ 349550.2   -270717.9    -43000.996]]\n"
     ]
    }
   ],
   "source": [
    "n = 6\n",
    "out = model.predict(test_points[n:n+1,:,:])\n",
    "# print(test_points[0])\n",
    "# print('intermediate products',func(test_points[0]))\n",
    "\n",
    "print('actual answer: ', test_normals[n]/np.linalg.norm(test_normals[n]))\n",
    "print('predicted answer: ', out/np.linalg.norm(out))\n",
    "print('actual answer: ', test_normals[n])\n",
    "print('predicted answer: ', out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000/1000 [==============================] - 1s 660us/step\n",
      "loss =  0.01140802662819624\n",
      "acc =  1.0\n"
     ]
    }
   ],
   "source": [
    "out = model.evaluate(test_points,test_normals)\n",
    "print('loss = ',out[0])\n",
    "print('acc = ',out[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 5\n",
    "test = test_points[n:n+1,:,:]\n",
    "\n",
    "fig = plt.figure(figsize = (20,10))\n",
    "ax = fig.add_subplot(111, projection='3d')\n",
    "out = model.predict(test_points[0:10,:,:])\n",
    "# out_nor = normalize(out)\n",
    "\n",
    "origin = [0,0,0]\n",
    "# X,Y,Z = zip(origin,origin,origin,origin,origin,origin,origin)\n",
    "# U,V,W = zip(test_normals[n,:3],x1,x2,x3,x4,out_prop,out_nor[n,:])\n",
    "# ax.quiver(X,Y,Z,U,V,W,color = ['k','r','b','y','c','m','g'])\n",
    "X,Y,Z = zip(origin,origin)\n",
    "U,V,W = zip(test_normals[n,:]/np.linalg.norm(test_normals[n,:]),out[n,:]/np.linalg.norm(out[n,:]))\n",
    "ax.quiver(X,Y,Z,U,V,W,color = ['r','b'])\n",
    "ax.set_xlim([-1,1])\n",
    "ax.set_ylim([-1,1])\n",
    "ax.set_zlim([-1,1])\n",
    "ax.set_xlabel('x')\n",
    "ax.set_ylabel('y')\n",
    "ax.set_zlabel('z')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "+ #### Save Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
