{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using matplotlib backend: Qt5Agg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "%matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "\n",
    "# import NALU files\n",
    "import sys\n",
    "sys.path.insert(0, 'C:/Users/Ammar/Documents/CV LAB internship/Sproj/NALU_files')\n",
    "from nalu import NALU\n",
    "from nac import NAC\n",
    "\n",
    "# import Keras items\n",
    "from keras.models import Model\n",
    "from keras.layers import Dense,Lambda,Concatenate,Input,Flatten,Reshape,MaxPooling1D,Layer\n",
    "from keras.callbacks import ModelCheckpoint, EarlyStopping, CSVLogger, ReduceLROnPlateau, TensorBoard\n",
    "from keras import backend as K\n",
    "# from keras.utils import to_categorical,plot_model\n",
    "from keras.initializers import constant\n",
    "from keras.constraints import MinMaxNorm\n",
    "from keras.utils import to_categorical\n",
    "\n",
    "# import other libs\n",
    "import os\n",
    "import numpy as np\n",
    "# from itertools import combinations_with_replacement,product\n",
    "# from sklearn.model_selection import train_test_split\n",
    "from tensorflow import floor as tf_floor\n",
    "# from tensorflow.dtypes import as_string\n",
    "# from tensorflow.strings import join,to_number\n",
    "# from tensorflow import add"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = 'generalized_mult'\n",
    "EPOCHS = 10\n",
    "batch_size = 4 \n",
    "num_digits = 3\n",
    "range_min = -999\n",
    "range_max = 999\n",
    "train_samples = 10000\n",
    "test_samples = 1000\n",
    "num_pts = 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = np.random.randint(low=range_min,high=range_max+1,size = (train_samples,2))\n",
    "y_train = x_train[:,0] * x_train[:,1]\n",
    "\n",
    "x_test = np.random.randint(low=range_min,high=range_max+1,size = (test_samples,2))\n",
    "y_test = x_test[:,0] * x_test[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sep(x,num_digits):\n",
    "    x = np.array([int(i) for i in str(x)])\n",
    "    while (x.shape[0] < num_digits):\n",
    "        x = np.insert(x,0,0)\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t (100, 2, 3)\n",
      "\t (100, 6)\n"
     ]
    }
   ],
   "source": [
    "x_train_a = np.random.randint(low = range_min,high = range_max,size =100)\n",
    "x_train_b = np.random.randint(low = range_min,high = range_max,size =100)\n",
    "\n",
    "x_train = np.empty((100,2,num_digits),dtype = np.int32)\n",
    "\n",
    "y_train_a = x_train_a * x_train_b\n",
    "y_train = np.empty((100,num_digits*2),dtype = np.int32)\n",
    "\n",
    "for i in range(100):\n",
    "    x_train[i,0] = sep(x_train_a[i],num_digits)\n",
    "    \n",
    "    x_train[i,1] = sep(x_train_b[i],num_digits)\n",
    "    y_train[i] = sep(y_train_a[i],num_digits*2)\n",
    "    \n",
    "print('\\t',x_train.shape)\n",
    "print('\\t',y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_pts_plane(normal,n_pts,min_range = -10000,max_range = 10000,noise_d = 0):\n",
    "    # Generates n number of points \n",
    "    # normal : array like plane normal [a,b,c,d]\n",
    "    # n_pts: total points to generate\n",
    "    # min_range,max_range: range b/w which points are to be generated. default is -10000 to 10000\n",
    "    # noise_d: +- noise allowed in generated point from plane in terms of d = ax + by + cz. default = 0\n",
    "    # return np array of generated points 3xn_pts\n",
    "    \n",
    "    planar_points = np.empty((n_pts,3),dtype = np.int32)\n",
    "    num = 0\n",
    "    plane_normal = normal[:3]\n",
    "    d = normal[3]\n",
    "    while (num < n_pts):\n",
    "        p = np.random.randint(min_range,max_range,size = (1,3))\n",
    "        dot = np.dot(p,plane_normal)\n",
    "        if (dot >= d - noise_d and dot <= d + noise_d ):\n",
    "            planar_points[num,:] = np.squeeze(p.T,-1)\n",
    "            num = num + 1\n",
    "    return planar_points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# random plane normals\n",
    "train_data = np.empty((train_samples,num_pts,3))\n",
    "train_normals = np.empty((train_samples,4))\n",
    "for i in range(train_samples):\n",
    "    plane_normal = np.random.randint(low = range_min,high = range_max, size = (3,1))\n",
    "    plane_normal = plane_normal / np.linalg.norm(plane_normal)\n",
    "    p = np.random.randint(range_min,range_max,size = (1,3))\n",
    "    d = np.dot(p,plane_normal)\n",
    "    train_normals[i,:] = np.append(plane_normal[:,0],d[0])\n",
    "    train_data[i,:,:] = generate_pts_plane(train_normals[i,:],num_pts,noise_d = 0.05)\n",
    "    print('\\t',i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = np.empty((test_samples,num_pts,3))\n",
    "test_normals = np.empty((test_samples,4))\n",
    "for i in range(test_samples):\n",
    "    plane_normal = np.random.randint(low = range_min,high = range_max, size = (3,1))\n",
    "    plane_normal = plane_normal / np.linalg.norm(plane_normal)\n",
    "    p = np.random.randint(range_min,range_max,size = (1,3))\n",
    "    d = np.dot(p,plane_normal)\n",
    "    test_normals[i,:] = np.append(plane_normal[:,0],d[0])\n",
    "    test_data[i,:,:] = generate_pts_plane(test_normals[i,:],num_pts,noise_d = 0.05)\n",
    "    print('\\t',i)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data to train plane normal model \n",
    "train_points = np.empty((train_samples,3,3))\n",
    "train_normals = np.zeros((train_samples,3))\n",
    "\n",
    "for i in range(train_samples):\n",
    "    points = np.random.uniform(low = range_min,high = range_max,size = (3,3))\n",
    "    train_normals[i,:] = np.cross(points[0,:] - points[1,:],points[2,:] - points[1,:])\n",
    "#     train_normals[i,:] = n / np.linalg.norm(n)\n",
    "    train_points[i,:,:] = points\n",
    "    \n",
    "    \n",
    "test_points = np.empty((test_samples,3,3))\n",
    "test_normals = np.zeros((test_samples,3))\n",
    "\n",
    "for i in range(test_samples):\n",
    "    points = np.random.uniform(low = range_min,high = range_max,size = (3,3))\n",
    "    test_normals[i,:] = np.cross(points[0,:] - points[1,:],points[2,:] - points[1,:])\n",
    "#     test_normals[i,:] = n / np.linalg.norm(n)\n",
    "    test_points[i,:,:] = points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data to train cross product model\n",
    "train_points = np.empty((train_samples,2,3))\n",
    "train_normals = np.zeros((train_samples,3))\n",
    "\n",
    "for i in range(train_samples):\n",
    "    points = np.random.randint(low = range_min,high = range_max,size = (2,3))\n",
    "    train_normals[i,:] = np.cross(points[0,:], points[1,:])\n",
    "#     train_normals[i,:] = n / np.linalg.norm(n)\n",
    "    train_points[i,:,:] = points\n",
    "    \n",
    "    \n",
    "test_points = np.empty((test_samples,2,3))\n",
    "test_normals = np.zeros((test_samples,3))\n",
    "\n",
    "for i in range(test_samples):\n",
    "    points = np.random.randint(low = range_min,high = range_max,size = (2,3))\n",
    "    test_normals[i,:] = np.cross(points[0,:], points[1,:])\n",
    "#     test_normals[i,:] = n / np.linalg.norm(n)\n",
    "    test_points[i,:,:] = points"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def net_diff(inputs):\n",
    "    input_data = Input(shape = inputs)\n",
    "    net = Flatten()(input_data)\n",
    "    net = Dense(6)(net)\n",
    "    return Model(inputs = input_data, outputs = net)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_diff = net_diff((3,3))\n",
    "model_diff.compile(loss = 'MSE',optimizer = 'Adam',metrics = ['accuracy'])\n",
    "model_diff.load_weights('diff.h5')\n",
    "model_diff.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def net(inputs):\n",
    "    input_data = Input(shape = inputs)\n",
    "    out = Dense(30,activation = 'relu',name='my_layer')(input_data)\n",
    "    out = Dense(82,activation='softmax')(out)\n",
    "    \n",
    "    return Model(inputs = input_data,outputs = out)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_mul = net((2,))\n",
    "model_mul.trainable = False\n",
    "model_mul.compile(loss = 'categorical_crossentropy',optimizer = 'Adam',metrics = ['accuracy'])\n",
    "# model_mul.summary()\n",
    "model_mul.load_weights('mul_0-9_classifier.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def separator(inputs):\n",
    "    input_data = Input(shape = inputs)\n",
    "    # addition = Dense(1,kernel_initializer='ones',use_bias=False)(input_data)\n",
    "    carry = Dense(1,use_bias=False,kernel_initializer=constant(value=0.1))(input_data)\n",
    "    carry = Lambda(lambda x: tf_floor(x))(carry)\n",
    "    \n",
    "    ones_digit = Dense(1,use_bias=False,kernel_initializer=constant(value=10))(carry)\n",
    "    temp = Concatenate()([ones_digit,input_data])\n",
    "    ones_digit = Dense(1,use_bias=False)(temp)\n",
    "    \n",
    "    out = Concatenate()([carry,ones_digit])\n",
    "    return Model(inputs = input_data,outputs = out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_separator = separator((1,))\n",
    "model_separator.layers[5].set_weights([np.array(([-1],[1]))])\n",
    "model_separator.trainable = False\n",
    "model_separator.compile(loss = 'MSE',optimizer = 'Adam',metrics = ['accuracy'])\n",
    "# model_separator.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def net_sub(inputs):\n",
    "    input_data = Input(shape=inputs)\n",
    "    out = Dense(1,use_bias = False)(input_data)\n",
    "    \n",
    "    return Model(inputs = input_data,outputs =out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_sub = net_sub((2,))\n",
    "model_sub.layers[1].set_weights([np.array(([-1],[1]))])\n",
    "model_sub.trainable=False\n",
    "model_sub.compile(loss = 'MSE',optimizer = 'Adam',metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def net_separate(inputs):\n",
    "    input_data = Input(shape = inputs)\n",
    "    n = input_data.shape[-1]\n",
    "#     data = Lambda(lambda x: K.abs(x))(input_data)\n",
    "    data = input_data\n",
    "    digits = []\n",
    "    for i in range(2):\n",
    "        \n",
    "        temp = Dense(1,use_bias=False,kernel_initializer=constant(value=0.1))(data)\n",
    "        temp = Lambda(lambda x: tf_floor(x))(temp)\n",
    "        \n",
    "        digit = Dense(1,use_bias=False,kernel_initializer=constant(value=10))(temp)\n",
    "        temp1 = Concatenate()([digit,data])\n",
    "        digit = model_sub(temp1)\n",
    "#         digit = Lambda(lambda x: tf_floor(x))(digit)\n",
    "        digits.append(digit)\n",
    "        data = temp\n",
    "    \n",
    "    digits.append(data)\n",
    "    digits = digits[::-1]\n",
    "    out = Concatenate()(digits)\n",
    "    return Model(inputs = input_data,outputs = out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_separate = net_separate((1,))\n",
    "model_separate.trainable=False\n",
    "model_separate.compile(loss = 'MSE',optimizer = 'Adam')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def net_separate_6(inputs):\n",
    "    input_data = Input(shape = inputs)\n",
    "    data = input_data\n",
    "    digits = []\n",
    "    for i in range(5):\n",
    "        \n",
    "        temp = Dense(1,use_bias=False,kernel_initializer=constant(value=0.1))(data)\n",
    "        temp = Lambda(lambda x: tf_floor(x))(temp)\n",
    "        \n",
    "        digit = Dense(1,use_bias=False,kernel_initializer=constant(value=10))(temp)\n",
    "        temp1 = Concatenate()([digit,data])\n",
    "        digit = model_sub(temp1)\n",
    "#         digit = Lambda(lambda x: tf_floor(x))(digit)\n",
    "        digits.append(digit)\n",
    "        data = temp\n",
    "    \n",
    "    digits.append(data)\n",
    "    digits = digits[::-1]\n",
    "    out = Concatenate()(digits)\n",
    "    return Model(inputs = input_data,outputs = out)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_separate_6 = net_separate_6((1,))\n",
    "model_separate_6.trainable=False\n",
    "model_separate_6.compile(loss = 'MSE',optimizer = 'Adam')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def net_regression(inputs):\n",
    "    input_data = Input(shape=inputs)\n",
    "    out = Dense(3,use_bias=False)(input_data)\n",
    "    \n",
    "    return Model(inputs = input_data,outputs = out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_reg = net_regression((30,))\n",
    "model_reg.compile(loss='MSE',optimizer='adam',metrics=['accuracy'])\n",
    "# model_reg.summary()\n",
    "model_reg.trainable=False\n",
    "model_reg.load_weights('regression_test.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def net_mul(inputs):\n",
    "    input_data = Input(shape = inputs)\n",
    "    n = input_data[0].shape[-1]\n",
    "    m = input_data[1].shape[-1]\n",
    "    # get initial products\n",
    "    products=[]\n",
    "    for i in range(input_data.shape[-1]):\n",
    "        mul = Lambda(lambda x: x[:,0,i:i+1])(input_data)\n",
    "        for j in range(input_data.shape[-1]):\n",
    "            a = Lambda(lambda x: x[:,1,j:j+1])(input_data)\n",
    "            concat = Concatenate()([a,mul])\n",
    "            prod = model_mul(concat)\n",
    "            prod =  Lambda(lambda x: K.expand_dims(K.cast(K.argmax(x),dtype ='float32')))(prod)\n",
    "            products.append(prod)\n",
    "            \n",
    "    # get individual rows\n",
    "    products = products[::-1]\n",
    "    row_values = []\n",
    "    prod_index = 0\n",
    "    for r in range(n):\n",
    "        for i in range(m+1):\n",
    "            if i==0:\n",
    "                sep = model_separator(products[prod_index])\n",
    "                ones_digit = Lambda(lambda x: x[:,1:])(sep)\n",
    "                carry = Lambda(lambda x: x[:,0:1])(sep)\n",
    "                row_values.append(ones_digit)\n",
    "                prod_index+=1\n",
    "                \n",
    "            elif i == m :\n",
    "                row_values.append(carry)\n",
    "            else:\n",
    "                concat = Concatenate()([products[prod_index],carry])\n",
    "                addition =  Dense(1,use_bias=False,kernel_initializer='ones')(concat)\n",
    "                sep = model_separator(addition)\n",
    "                ones_digit = Lambda(lambda x: x[:,1:])(sep)\n",
    "                carry = Lambda(lambda x: x[:,0:1])(sep)\n",
    "                row_values.append(ones_digit)\n",
    "                prod_index+=1\n",
    "                \n",
    "    final_row = []\n",
    "    current_ind = 0\n",
    "    for i in range(m+n):\n",
    "        if i == 0:\n",
    "            final_row.append(row_values[0])\n",
    "            sep = model_separator(row_values[0])\n",
    "            carry = Lambda(lambda x: x[:,0:1])(sep)\n",
    "            current_ind+=1\n",
    "        else:\n",
    "            to_add = []\n",
    "            to_add.append(row_values[current_ind])\n",
    "            to_add.append(carry)\n",
    "            next_ind = current_ind + m\n",
    "            while(next_ind < n * (m+1) and next_ind%(m+1)!=0):\n",
    "                to_add.append(row_values[next_ind])\n",
    "                next_ind+=m\n",
    "            if (next_ind < n * (m+1) and next_ind%(m+1)==0):\n",
    "                to_add.append(row_values[next_ind])\n",
    "                \n",
    "            concat = Concatenate()(to_add)\n",
    "            addition =  Dense(1,use_bias=False,kernel_initializer='ones')(concat)\n",
    "            sep = model_separator(addition)\n",
    "            ones_digit = Lambda(lambda x: x[:,1:])(sep)\n",
    "            carry = Lambda(lambda x: x[:,0:1])(sep)\n",
    "            final_row.append(ones_digit)\n",
    "            \n",
    "            if (current_ind + 1) % (m+1) !=0:\n",
    "                current_ind+=1\n",
    "            else:\n",
    "                current_ind+=m+1\n",
    "\n",
    "    \n",
    "    concat = Concatenate()(final_row[::-1])\n",
    "    return Model(inputs = input_data,outputs =concat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_mult = net_mul((2,num_digits))\n",
    "model_mult.trainable=False\n",
    "model_mult.compile(loss = 'MSE',optimizer = 'Adam',metrics = ['accuracy'])\n",
    "# model_mult.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def net_merge(inputs):\n",
    "    input_data = Input(shape=inputs)\n",
    "    add_list = []\n",
    "    n = input_data.shape[-1]\n",
    "    i = 0\n",
    "    while(n>=1):\n",
    "        temp = Lambda(lambda x: x[:,n-1:n])(input_data)\n",
    "        temp = Dense(1,kernel_initializer=constant(value=10**i))(temp)\n",
    "        add_list.append(temp)\n",
    "        i = i+1\n",
    "        n = n-1\n",
    "        \n",
    "    concat = Concatenate()(add_list)\n",
    "    out = Dense(1,kernel_initializer='ones')(concat)\n",
    "    return Model(inputs = input_data,outputs = out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_merge = net_merge((num_digits*2,))\n",
    "model_merge.compile(loss = 'MSE',optimizer = 'Adam')\n",
    "model_merge.trainable=False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def net_sign(inputs):\n",
    "    input_data = Input(shape=inputs)\n",
    "    out = Dense(15,activation = 'softsign')(input_data)\n",
    "    out = Dense(15,activation = 'softsign')(out)\n",
    "    out = Dense(2,activation = 'softmax')(out)\n",
    "\n",
    "    return Model(inputs=input_data,outputs=out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_sign = net_sign((2,))\n",
    "model_sign.compile(loss='categorical_crossentropy',optimizer = 'adam',metrics=['accuracy'])\n",
    "# model_sign.summary()\n",
    "model_sign.trainable=False\n",
    "model_sign.load_weights('neg_pos.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def net_abs(inputs):\n",
    "    input_data = Input(shape=inputs)\n",
    "    concat = Concatenate()([input_data,input_data])\n",
    "    add = Dense(1,use_bias=False,kernel_initializer='ones')(concat)\n",
    "    sub = model_sub(concat)\n",
    "    concat = Concatenate()([add,sub])\n",
    "    concat = Lambda(lambda x : K.expand_dims(x,-1))(concat)\n",
    "    out = MaxPooling1D(pool_size=2)(concat)\n",
    "    out = Lambda(lambda x : K.squeeze(x,axis=-1))(out)\n",
    "    concat = Concatenate()([input_data,out])\n",
    "    out = model_sub(concat)\n",
    "    \n",
    "    return Model(inputs = input_data,outputs=out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_abs = net_abs((1,))\n",
    "model_abs.compile(loss='MSE',optimizer = 'adam',metrics=['accuracy'])\n",
    "# model_abs.summary()\n",
    "model_abs.trainable=False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def net_exp(inputs):\n",
    "    input_data = Input(shape = inputs)\n",
    "    \n",
    "    out = Dense(10,activation='softsign')(input_data)\n",
    "    out = Dense(1,activation = 'linear')(out)\n",
    "    return Model(inputs = input_data,outputs=out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_exp = net_exp((2,))\n",
    "model_exp.compile(loss='MSE',optimizer = 'adam',metrics=['accuracy'])\n",
    "model_exp.load_weights('final_mult.h5')\n",
    "# model_exp.summary()\n",
    "model_exp.trainable=False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp = np.random.randint(low=0,high=10,size = (train_samples,1))\n",
    "temp2 = np.ones((train_samples // 2,1))\n",
    "temp2 = np.concatenate((temp2,-temp2))\n",
    "np.random.shuffle(temp2)\n",
    "train_data = np.hstack((temp,temp2))\n",
    "train_labels = train_data[:,0] * train_data[:,1]\n",
    "# train_labels = to_categorical(train_labels,num_classes = 19 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "10000/10000 [==============================] - 1s 58us/step - loss: 0.0186 - acc: 1.0000\n",
      "Epoch 2/20\n",
      "10000/10000 [==============================] - 1s 73us/step - loss: 0.0147 - acc: 1.0000\n",
      "Epoch 3/20\n",
      "10000/10000 [==============================] - 1s 72us/step - loss: 0.0112 - acc: 1.0000\n",
      "Epoch 4/20\n",
      "10000/10000 [==============================] - 1s 64us/step - loss: 0.0083 - acc: 1.0000\n",
      "Epoch 5/20\n",
      "10000/10000 [==============================] - 1s 72us/step - loss: 0.0057 - acc: 1.0000\n",
      "Epoch 6/20\n",
      "10000/10000 [==============================] - 1s 80us/step - loss: 0.0037 - acc: 1.0000\n",
      "Epoch 7/20\n",
      "10000/10000 [==============================] - 1s 66us/step - loss: 0.0023 - acc: 1.0000\n",
      "Epoch 8/20\n",
      "10000/10000 [==============================] - 1s 72us/step - loss: 0.0015 - acc: 1.0000\n",
      "Epoch 9/20\n",
      "10000/10000 [==============================] - 1s 82us/step - loss: 9.9220e-04 - acc: 1.0000\n",
      "Epoch 10/20\n",
      "10000/10000 [==============================] - 1s 74us/step - loss: 7.1069e-04 - acc: 1.0000\n",
      "Epoch 11/20\n",
      "10000/10000 [==============================] - 1s 71us/step - loss: 5.5044e-04 - acc: 1.0000\n",
      "Epoch 12/20\n",
      "10000/10000 [==============================] - 1s 68us/step - loss: 4.4784e-04 - acc: 1.0000: 0s - loss: 4.7654e-04 - acc: \n",
      "Epoch 13/20\n",
      "10000/10000 [==============================] - 1s 86us/step - loss: 3.6605e-04 - acc: 1.0000\n",
      "Epoch 14/20\n",
      "10000/10000 [==============================] - 1s 87us/step - loss: 2.9808e-04 - acc: 1.0000\n",
      "Epoch 15/20\n",
      "10000/10000 [==============================] - 1s 76us/step - loss: 2.5828e-04 - acc: 1.0000\n",
      "Epoch 16/20\n",
      "10000/10000 [==============================] - 1s 79us/step - loss: 2.1439e-04 - acc: 1.0000\n",
      "Epoch 17/20\n",
      "10000/10000 [==============================] - 1s 70us/step - loss: 1.8444e-04 - acc: 1.0000\n",
      "Epoch 18/20\n",
      "10000/10000 [==============================] - 1s 75us/step - loss: 1.6338e-04 - acc: 1.0000\n",
      "Epoch 19/20\n",
      "10000/10000 [==============================] - 1s 72us/step - loss: 1.5108e-04 - acc: 1.0000\n",
      "Epoch 20/20\n",
      "10000/10000 [==============================] - 1s 67us/step - loss: 1.3783e-04 - acc: 1.0000\n"
     ]
    }
   ],
   "source": [
    "fitted = model_exp.fit(train_data,train_labels,epochs = 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 1. -1.]\n",
      " [ 6.  1.]\n",
      " [ 8.  1.]\n",
      " [ 1.  1.]\n",
      " [ 7.  1.]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[-1.0020962],\n",
       "       [ 6.0141015],\n",
       "       [ 7.997643 ],\n",
       "       [ 1.0041726],\n",
       "       [ 6.9879255]], dtype=float32)"
      ]
     },
     "execution_count": 273,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(train_data[0:5])\n",
    "model_exp.predict(train_data[0:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def net_final_mult(inputs):\n",
    "    input_data = Input(shape = inputs)\n",
    "    temp = Lambda(lambda x: x[:,0:1])(input_data)\n",
    "    temp = model_separate_6(temp)\n",
    "    mul = Lambda(lambda x: x[:,1:2])(input_data)\n",
    "    products = []\n",
    "    i = 0\n",
    "    j = temp.shape[-1]\n",
    "    for n in range(j,0,-1):\n",
    "        a = Lambda(lambda x: x[:,n-1:n])(temp)\n",
    "        concat = Concatenate()([a,mul])\n",
    "        prod = model_exp(concat)\n",
    "        prod =  Lambda(lambda x: K.round(x))(prod)\n",
    "        prod = Dense(1,kernel_initializer=constant(10**i))(prod)\n",
    "        products.append(prod)\n",
    "#         n = n - 1 \n",
    "        i = i + 1\n",
    "    \n",
    "    concat = Concatenate()(products)\n",
    "    out = Dense(1,kernel_initializer='ones')(concat)\n",
    "    \n",
    "    return Model(inputs = input_data,outputs=out)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_final_mult = net_final_mult((2,))\n",
    "model_final_mult.compile(loss='MSE',optimizer = 'adam',metrics=['accuracy'])\n",
    "# model_final_mult.summary()\n",
    "model_final_mult.trainable=False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-123456.]], dtype=float32)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temp = np.array([123456,-1])\n",
    "temp = np.expand_dims(temp,0)\n",
    "model_final_mult.predict(temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_exp.save_weights('final_mult.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def neg_mult(inputs):\n",
    "    input_data = Input(shape = inputs)\n",
    "    \n",
    "    # get the sign of the output\n",
    "    sign = Lambda(lambda x: K.expand_dims(K.cast(K.argmax(model_sign(x)),dtype ='float32')))(input_data)\n",
    "    sign = Dense(1,kernel_initializer=constant(value=2.0))(sign)\n",
    "    var = Lambda(lambda x : K.ones((K.shape(input_data)[0],1),dtype = 'float32'))(sign)\n",
    "    concat_list = Concatenate()([var,sign])\n",
    "    sign = model_sub(concat_list)\n",
    "    \n",
    "    # get absolute values of the inputs\n",
    "    inp1 = Lambda(lambda x: x[:,0:1])(input_data)\n",
    "    inp2 = Lambda(lambda x: x[:,1:2])(input_data)\n",
    "    inp1 = model_abs(inp1)\n",
    "    inp2 = model_abs(inp2)\n",
    "    \n",
    "    abs_input = Concatenate()([inp1,inp2])\n",
    "    \n",
    "    # separate abs inputs to give to multiplication model\n",
    "    concat_list = []\n",
    "    for i in range(abs_input.shape[-1]):\n",
    "        temp = Lambda(lambda x: x[:,i:i+1])(abs_input)\n",
    "        temp = model_separate(temp)\n",
    "        temp = Lambda(lambda x: K.expand_dims(x,1))(temp)\n",
    "        concat_list.append(temp)\n",
    "\n",
    "    mult_input = Concatenate(axis = 1)(concat_list)\n",
    "    \n",
    "    # multiply absolutes\n",
    "    \n",
    "    n = mult_input[0].shape[-1]\n",
    "    m = mult_input[1].shape[-1]\n",
    "    # get initial products\n",
    "    products=[]\n",
    "    for i in range(mult_input.shape[-1]):\n",
    "        mul = Lambda(lambda x: x[:,0,i:i+1])(mult_input)\n",
    "        for j in range(mult_input.shape[-1]):\n",
    "            a = Lambda(lambda x: x[:,1,j:j+1])(mult_input)\n",
    "            concat = Concatenate()([a,mul])\n",
    "            prod = model_mul(concat)\n",
    "            prod =  Lambda(lambda x: K.expand_dims(K.cast(K.argmax(x),dtype ='float32')))(prod)\n",
    "            products.append(prod)\n",
    "            \n",
    "    # get individual rows\n",
    "    products = products[::-1]\n",
    "    row_values = []\n",
    "    prod_index = 0\n",
    "    for r in range(n):\n",
    "        for i in range(m+1):\n",
    "            if i==0:\n",
    "                sep = model_separator(products[prod_index])\n",
    "                ones_digit = Lambda(lambda x: x[:,1:])(sep)\n",
    "                carry = Lambda(lambda x: x[:,0:1])(sep)\n",
    "                row_values.append(ones_digit)\n",
    "                prod_index+=1\n",
    "                \n",
    "            elif i == m :\n",
    "                row_values.append(carry)\n",
    "            else:\n",
    "                concat = Concatenate()([products[prod_index],carry])\n",
    "                addition =  Dense(1,use_bias=False,kernel_initializer='ones')(concat)\n",
    "                sep = model_separator(addition)\n",
    "                ones_digit = Lambda(lambda x: x[:,1:])(sep)\n",
    "                carry = Lambda(lambda x: x[:,0:1])(sep)\n",
    "                row_values.append(ones_digit)\n",
    "                prod_index+=1\n",
    "                \n",
    "    final_row = []\n",
    "    current_ind = 0\n",
    "    for i in range(m+n):\n",
    "        if i == 0:\n",
    "            final_row.append(row_values[0])\n",
    "            sep = model_separator(row_values[0])\n",
    "            carry = Lambda(lambda x: x[:,0:1])(sep)\n",
    "            current_ind+=1\n",
    "        else:\n",
    "            to_add = []\n",
    "            to_add.append(row_values[current_ind])\n",
    "            to_add.append(carry)\n",
    "            next_ind = current_ind + m\n",
    "            while(next_ind < n * (m+1) and next_ind%(m+1)!=0):\n",
    "                to_add.append(row_values[next_ind])\n",
    "                next_ind+=m\n",
    "            if (next_ind < n * (m+1) and next_ind%(m+1)==0):\n",
    "                to_add.append(row_values[next_ind])\n",
    "                \n",
    "            concat = Concatenate()(to_add)\n",
    "            addition =  Dense(1,use_bias=False,kernel_initializer='ones')(concat)\n",
    "            sep = model_separator(addition)\n",
    "            ones_digit = Lambda(lambda x: x[:,1:])(sep)\n",
    "            carry = Lambda(lambda x: x[:,0:1])(sep)\n",
    "            final_row.append(ones_digit)\n",
    "            \n",
    "            if (current_ind + 1) % (m+1) !=0:\n",
    "                current_ind+=1\n",
    "            else:\n",
    "                current_ind+=m+1\n",
    "\n",
    "    \n",
    "    concat = Concatenate()(final_row[::-1])\n",
    "#     out = model_merge(concat)\n",
    "#     concat = Lambda(lambda x: K.expand_dims(x,1))(concat)\n",
    "    add_list = []\n",
    "    n = concat.shape[-1]\n",
    "    i = 0\n",
    "    while(n>=1):\n",
    "        temp = Lambda(lambda x: x[:,n-1:n])(concat)\n",
    "        temp = Dense(1,kernel_initializer=constant(value=10**i))(temp)\n",
    "        add_list.append(temp)\n",
    "        i = i+1\n",
    "        n = n-1\n",
    "        \n",
    "    concat = Concatenate()(add_list)\n",
    "    out = Dense(1,kernel_initializer='ones')(concat)\n",
    "    \n",
    "    # multiply sign with result \n",
    "    concat = Concatenate()([out,sign])\n",
    "#     out = model_final_mult(concat)\n",
    "    temp = Lambda(lambda x: x[:,0:1])(concat)\n",
    "    temp = model_separate_6(temp)\n",
    "    mul = Lambda(lambda x: x[:,1:2])(concat)\n",
    "    products = []\n",
    "    i = 0\n",
    "    j = temp.shape[-1]\n",
    "    for n in range(j,0,-1):\n",
    "        a = Lambda(lambda x: x[:,n-1:n])(temp)\n",
    "        concat = Concatenate()([a,mul])\n",
    "        prod = model_exp(concat)\n",
    "        prod =  Lambda(lambda x: K.round(x))(prod)\n",
    "        prod = Dense(1,kernel_initializer=constant(10**i))(prod)\n",
    "        products.append(prod)\n",
    "#         n = n - 1 \n",
    "        i = i + 1\n",
    "    \n",
    "    concat = Concatenate()(products)\n",
    "    out = Dense(1,kernel_initializer='ones')(concat)\n",
    "\n",
    "    return Model(inputs = input_data,outputs = out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_neg_mult = neg_mult((2,))\n",
    "model_neg_mult.compile(loss='MSE',optimizer = 'adam',metrics=['accuracy'])\n",
    "model_neg_mult.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 415,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-793  194]\n",
      " [ 839 -920]\n",
      " [ 291 -416]\n",
      " [-564 -217]\n",
      " [ 242 -857]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[-153842.],\n",
       "       [-771880.],\n",
       "       [-121056.],\n",
       "       [ 122388.],\n",
       "       [-207394.]], dtype=float32)"
      ]
     },
     "execution_count": 415,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(x_train[0:5])\n",
    "model_neg_mult.predict(x_train[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "def net_cross(inputs):\n",
    "    input_data = Input(shape = inputs)\n",
    "#     out = Flatten()(input_data)\n",
    "    flat_input = Reshape((6,))(input_data)\n",
    "    # separate difference vectors to give to multiplication model\n",
    "#     concat_list = []\n",
    "#     for i in range(6):\n",
    "#         temp = Lambda(lambda x: x[:,i:i+1])(out)\n",
    "#         temp = model_separate(temp)\n",
    "#         temp = Lambda(lambda x: K.expand_dims(x,1))(temp)\n",
    "#         concat_list.append(temp)\n",
    "\n",
    "#     out = Concatenate(axis = 1)(concat_list)\n",
    "    final_concat_list = []\n",
    "    for i1 in range(flat_input.shape[1]):\n",
    "        temp1 = Lambda(lambda x: x[:,i1:i1+1])(flat_input)\n",
    "        print('temp1 :',temp1.shape)\n",
    "        for j1 in range(flat_input.shape[1]):\n",
    "            if i1 == j1:\n",
    "                continue\n",
    "            temp2 = Lambda(lambda x: x[:,j1:j1+1])(flat_input)\n",
    "#             print('temp2 :',temp2.shape)\n",
    "            multiplication_input = Concatenate(axis = 1)([temp1,temp2])\n",
    "#             print(multiplication_input.shape)\n",
    "            # get the sign of the output\n",
    "            sign = Lambda(lambda x: K.expand_dims(K.cast(K.argmax(model_sign(x)),dtype ='float32')))(multiplication_input)\n",
    "            sign = Dense(1,kernel_initializer=constant(value=2.0))(sign)\n",
    "            var = Lambda(lambda x : K.ones((K.shape(multiplication_input)[0],1),dtype = 'float32'))(sign)\n",
    "            concat_list = Concatenate()([var,sign])\n",
    "            sign = model_sub(concat_list)\n",
    "\n",
    "            # get absolute values of the inputs\n",
    "            inp1 = Lambda(lambda x: x[:,0:1])(multiplication_input)\n",
    "            inp2 = Lambda(lambda x: x[:,1:2])(multiplication_input)\n",
    "            inp1 = model_abs(inp1)\n",
    "            inp2 = model_abs(inp2)\n",
    "\n",
    "            abs_input = Concatenate()([inp1,inp2])\n",
    "\n",
    "            # separate abs inputs to give to multiplication model\n",
    "            concat_list = []\n",
    "            for i in range(abs_input.shape[-1]):\n",
    "                temp = Lambda(lambda x: x[:,i:i+1])(abs_input)\n",
    "                temp = model_separate(temp)\n",
    "                temp = Lambda(lambda x: K.expand_dims(x,1))(temp)\n",
    "                concat_list.append(temp)\n",
    "\n",
    "            mult_input = Concatenate(axis = 1)(concat_list)\n",
    "\n",
    "            # multiply absolutes\n",
    "\n",
    "            n = mult_input[0].shape[-1]\n",
    "            m = mult_input[1].shape[-1]\n",
    "            # get initial products\n",
    "            products=[]\n",
    "            for i in range(mult_input.shape[-1]):\n",
    "                mul = Lambda(lambda x: x[:,0,i:i+1])(mult_input)\n",
    "                for j in range(mult_input.shape[-1]):\n",
    "                    a = Lambda(lambda x: x[:,1,j:j+1])(mult_input)\n",
    "                    concat = Concatenate()([a,mul])\n",
    "                    prod = model_mul(concat)\n",
    "                    prod =  Lambda(lambda x: K.expand_dims(K.cast(K.argmax(x),dtype ='float32')))(prod)\n",
    "                    products.append(prod)\n",
    "\n",
    "            # get individual rows\n",
    "            products = products[::-1]\n",
    "            row_values = []\n",
    "            prod_index = 0\n",
    "            for r in range(n):\n",
    "                for i in range(m+1):\n",
    "                    if i==0:\n",
    "                        sep = model_separator(products[prod_index])\n",
    "                        ones_digit = Lambda(lambda x: x[:,1:])(sep)\n",
    "                        carry = Lambda(lambda x: x[:,0:1])(sep)\n",
    "                        row_values.append(ones_digit)\n",
    "                        prod_index+=1\n",
    "\n",
    "                    elif i == m :\n",
    "                        row_values.append(carry)\n",
    "                    else:\n",
    "                        concat = Concatenate()([products[prod_index],carry])\n",
    "                        addition =  Dense(1,use_bias=False,kernel_initializer='ones')(concat)\n",
    "                        sep = model_separator(addition)\n",
    "                        ones_digit = Lambda(lambda x: x[:,1:])(sep)\n",
    "                        carry = Lambda(lambda x: x[:,0:1])(sep)\n",
    "                        row_values.append(ones_digit)\n",
    "                        prod_index+=1\n",
    "\n",
    "            final_row = []\n",
    "            current_ind = 0\n",
    "            for i in range(m+n):\n",
    "                if i == 0:\n",
    "                    final_row.append(row_values[0])\n",
    "                    sep = model_separator(row_values[0])\n",
    "                    carry = Lambda(lambda x: x[:,0:1])(sep)\n",
    "                    current_ind+=1\n",
    "                else:\n",
    "                    to_add = []\n",
    "                    to_add.append(row_values[current_ind])\n",
    "                    to_add.append(carry)\n",
    "                    next_ind = current_ind + m\n",
    "                    while(next_ind < n * (m+1) and next_ind%(m+1)!=0):\n",
    "                        to_add.append(row_values[next_ind])\n",
    "                        next_ind+=m\n",
    "                    if (next_ind < n * (m+1) and next_ind%(m+1)==0):\n",
    "                        to_add.append(row_values[next_ind])\n",
    "\n",
    "                    concat = Concatenate()(to_add)\n",
    "                    addition =  Dense(1,use_bias=False,kernel_initializer='ones')(concat)\n",
    "                    sep = model_separator(addition)\n",
    "                    ones_digit = Lambda(lambda x: x[:,1:])(sep)\n",
    "                    carry = Lambda(lambda x: x[:,0:1])(sep)\n",
    "                    final_row.append(ones_digit)\n",
    "\n",
    "                    if (current_ind + 1) % (m+1) !=0:\n",
    "                        current_ind+=1\n",
    "                    else:\n",
    "                        current_ind+=m+1\n",
    "\n",
    "\n",
    "            concat = Concatenate()(final_row[::-1])\n",
    "        #     out = model_merge(concat)\n",
    "        #     concat = Lambda(lambda x: K.expand_dims(x,1))(concat)\n",
    "            add_list = []\n",
    "            n = concat.shape[-1]\n",
    "            i = 0\n",
    "            while(n>=1):\n",
    "                temp = Lambda(lambda x: x[:,n-1:n])(concat)\n",
    "                temp = Dense(1,kernel_initializer=constant(value=10**i))(temp)\n",
    "                add_list.append(temp)\n",
    "                i = i+1\n",
    "                n = n-1\n",
    "\n",
    "            concat = Concatenate()(add_list)\n",
    "            out = Dense(1,kernel_initializer='ones')(concat)\n",
    "\n",
    "            # multiply sign with result \n",
    "            concat = Concatenate()([out,sign])\n",
    "        #     out = model_final_mult(concat)\n",
    "            temp = Lambda(lambda x: x[:,0:1])(concat)\n",
    "            temp = model_separate_6(temp)\n",
    "            mul = Lambda(lambda x: x[:,1:2])(concat)\n",
    "            products = []\n",
    "            i = 0\n",
    "            j = temp.shape[-1]\n",
    "            for n in range(j,0,-1):\n",
    "                a = Lambda(lambda x: x[:,n-1:n])(temp)\n",
    "                concat = Concatenate()([a,mul])\n",
    "                prod = model_exp(concat)\n",
    "                prod =  Lambda(lambda x: K.round(x))(prod)\n",
    "                prod = Dense(1,kernel_initializer=constant(10**i))(prod)\n",
    "                products.append(prod)\n",
    "        #         n = n - 1 \n",
    "                i = i + 1\n",
    "\n",
    "            concat = Concatenate()(products)\n",
    "            out = Dense(1,kernel_initializer='ones')(concat)\n",
    "            final_concat_list.append(out)\n",
    "    \n",
    "    out = Concatenate()(final_concat_list)\n",
    "    \n",
    "    out = Dense()\n",
    "    \n",
    "    return Model(inputs = input_data, outputs = out)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "temp1 : (?, 1)\n",
      "temp1 : (?, 1)\n",
      "temp1 : (?, 1)\n",
      "temp1 : (?, 1)\n",
      "temp1 : (?, 1)\n",
      "temp1 : (?, 1)\n",
      "(?, 30)\n"
     ]
    }
   ],
   "source": [
    "model_cross = net_cross((2,3))\n",
    "model_cross.compile(loss='MSE',optimizer = 'adam',metrics=['accuracy'])\n",
    "model_cross.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "def net_cross_old(inputs):\n",
    "    \n",
    "    input_data = Input(shape = inputs)\n",
    "    out =Reshape((6,))(input_data)\n",
    "\n",
    "    # Multiply components of difference vectors\n",
    "    concat_list = []\n",
    "    for i1 in range(out.shape[1]):\n",
    "        temp1 = Lambda(lambda x: x[:,i1:i1+1])(out)\n",
    "        for j1 in range(out.shape[1]):\n",
    "            if i1 == j1:\n",
    "                continue\n",
    "            temp2 = Lambda(lambda x: x[:,j1:j1+1])(out)\n",
    "            mult_input = Concatenate(axis = 1)([temp1,temp2])\n",
    "            print(mult_input.shape)\n",
    "            a = model_neg_mult(mult_input)\n",
    "            print(a.shape)\n",
    "            concat_list.append(a)\n",
    "# \n",
    "           \n",
    "    out = Concatenate()(concat_list)\n",
    "    print(out.shape)\n",
    "    return Model(inputs = input_data, outputs = out)    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "+ #### Model Initilization And Details"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(?, 2)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Dimensions must be equal, but are 0 and 1 for 'model_14_2/model_5/dense_7/MatMul' (op: 'MatMul') with input shapes: [?,0], [1,1].",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[1;32m~\\.conda\\envs\\neuralnets\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\u001b[0m in \u001b[0;36m_create_c_op\u001b[1;34m(graph, node_def, inputs, control_inputs)\u001b[0m\n\u001b[0;32m   1627\u001b[0m   \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1628\u001b[1;33m     \u001b[0mc_op\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mc_api\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_FinishOperation\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mop_desc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1629\u001b[0m   \u001b[1;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mInvalidArgumentError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mInvalidArgumentError\u001b[0m: Dimensions must be equal, but are 0 and 1 for 'model_14_2/model_5/dense_7/MatMul' (op: 'MatMul') with input shapes: [?,0], [1,1].",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-81-a6d5573f4ea9>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mmodel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnet_cross_old\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mloss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'MSE'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0moptimizer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'adam'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mmetrics\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;34m'accuracy'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;31m# model.summary()\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-80-db1cb5811b35>\u001b[0m in \u001b[0;36mnet_cross_old\u001b[1;34m(inputs)\u001b[0m\n\u001b[0;32m     14\u001b[0m             \u001b[0mmult_input\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mConcatenate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0maxis\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mtemp1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mtemp2\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     15\u001b[0m             \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmult_input\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 16\u001b[1;33m             \u001b[0ma\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel_neg_mult\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmult_input\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     17\u001b[0m             \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     18\u001b[0m             \u001b[0mconcat_list\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\neuralnets\\lib\\site-packages\\keras\\engine\\base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, inputs, **kwargs)\u001b[0m\n\u001b[0;32m    455\u001b[0m             \u001b[1;31m# Actually call the layer,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    456\u001b[0m             \u001b[1;31m# collecting output(s), mask(s), and shape(s).\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 457\u001b[1;33m             \u001b[0moutput\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcall\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    458\u001b[0m             \u001b[0moutput_mask\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcompute_mask\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mprevious_mask\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    459\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\neuralnets\\lib\\site-packages\\keras\\engine\\network.py\u001b[0m in \u001b[0;36mcall\u001b[1;34m(self, inputs, mask)\u001b[0m\n\u001b[0;32m    562\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_output_tensor_cache\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mcache_key\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    563\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 564\u001b[1;33m             \u001b[0moutput_tensors\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun_internal_graph\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmasks\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    565\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0moutput_tensors\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    566\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\neuralnets\\lib\\site-packages\\keras\\engine\\network.py\u001b[0m in \u001b[0;36mrun_internal_graph\u001b[1;34m(self, inputs, masks)\u001b[0m\n\u001b[0;32m    719\u001b[0m                                     \u001b[0mkwargs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'mask'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcomputed_mask\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    720\u001b[0m                             output_tensors = to_list(\n\u001b[1;32m--> 721\u001b[1;33m                                 layer.call(computed_tensor, **kwargs))\n\u001b[0m\u001b[0;32m    722\u001b[0m                             output_masks = layer.compute_mask(computed_tensor,\n\u001b[0;32m    723\u001b[0m                                                               computed_mask)\n",
      "\u001b[1;32m~\\.conda\\envs\\neuralnets\\lib\\site-packages\\keras\\engine\\network.py\u001b[0m in \u001b[0;36mcall\u001b[1;34m(self, inputs, mask)\u001b[0m\n\u001b[0;32m    562\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_output_tensor_cache\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mcache_key\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    563\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 564\u001b[1;33m             \u001b[0moutput_tensors\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun_internal_graph\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmasks\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    565\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0moutput_tensors\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    566\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\neuralnets\\lib\\site-packages\\keras\\engine\\network.py\u001b[0m in \u001b[0;36mrun_internal_graph\u001b[1;34m(self, inputs, masks)\u001b[0m\n\u001b[0;32m    719\u001b[0m                                     \u001b[0mkwargs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'mask'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcomputed_mask\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    720\u001b[0m                             output_tensors = to_list(\n\u001b[1;32m--> 721\u001b[1;33m                                 layer.call(computed_tensor, **kwargs))\n\u001b[0m\u001b[0;32m    722\u001b[0m                             output_masks = layer.compute_mask(computed_tensor,\n\u001b[0;32m    723\u001b[0m                                                               computed_mask)\n",
      "\u001b[1;32m~\\.conda\\envs\\neuralnets\\lib\\site-packages\\keras\\layers\\core.py\u001b[0m in \u001b[0;36mcall\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m    877\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    878\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mcall\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 879\u001b[1;33m         \u001b[0moutput\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mK\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkernel\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    880\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0muse_bias\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    881\u001b[0m             \u001b[0moutput\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mK\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbias_add\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdata_format\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'channels_last'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\neuralnets\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py\u001b[0m in \u001b[0;36mdot\u001b[1;34m(x, y)\u001b[0m\n\u001b[0;32m   1083\u001b[0m         \u001b[0mout\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msparse_tensor_dense_matmul\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1084\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1085\u001b[1;33m         \u001b[0mout\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmatmul\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1086\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mout\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1087\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\neuralnets\\lib\\site-packages\\tensorflow\\python\\ops\\math_ops.py\u001b[0m in \u001b[0;36mmatmul\u001b[1;34m(a, b, transpose_a, transpose_b, adjoint_a, adjoint_b, a_is_sparse, b_is_sparse, name)\u001b[0m\n\u001b[0;32m   2055\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2056\u001b[0m       return gen_math_ops.mat_mul(\n\u001b[1;32m-> 2057\u001b[1;33m           a, b, transpose_a=transpose_a, transpose_b=transpose_b, name=name)\n\u001b[0m\u001b[0;32m   2058\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2059\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\neuralnets\\lib\\site-packages\\tensorflow\\python\\ops\\gen_math_ops.py\u001b[0m in \u001b[0;36mmat_mul\u001b[1;34m(a, b, transpose_a, transpose_b, name)\u001b[0m\n\u001b[0;32m   4557\u001b[0m     _, _, _op = _op_def_lib._apply_op_helper(\n\u001b[0;32m   4558\u001b[0m         \u001b[1;34m\"MatMul\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0ma\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mb\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mb\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtranspose_a\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtranspose_a\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtranspose_b\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtranspose_b\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 4559\u001b[1;33m         name=name)\n\u001b[0m\u001b[0;32m   4560\u001b[0m     \u001b[0m_result\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_op\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4561\u001b[0m     \u001b[0m_inputs_flat\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_op\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\neuralnets\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py\u001b[0m in \u001b[0;36m_apply_op_helper\u001b[1;34m(self, op_type_name, name, **keywords)\u001b[0m\n\u001b[0;32m    785\u001b[0m         op = g.create_op(op_type_name, inputs, output_types, name=scope,\n\u001b[0;32m    786\u001b[0m                          \u001b[0minput_types\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minput_types\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mattrs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mattr_protos\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 787\u001b[1;33m                          op_def=op_def)\n\u001b[0m\u001b[0;32m    788\u001b[0m       \u001b[1;32mreturn\u001b[0m \u001b[0moutput_structure\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mop_def\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mis_stateful\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mop\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    789\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\neuralnets\\lib\\site-packages\\tensorflow\\python\\util\\deprecation.py\u001b[0m in \u001b[0;36mnew_func\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    486\u001b[0m                 \u001b[1;34m'in a future version'\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mdate\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;32melse\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;34m'after %s'\u001b[0m \u001b[1;33m%\u001b[0m \u001b[0mdate\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    487\u001b[0m                 instructions)\n\u001b[1;32m--> 488\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    489\u001b[0m     return tf_decorator.make_decorator(func, new_func, 'deprecated',\n\u001b[0;32m    490\u001b[0m                                        _add_deprecated_arg_notice_to_docstring(\n",
      "\u001b[1;32m~\\.conda\\envs\\neuralnets\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\u001b[0m in \u001b[0;36mcreate_op\u001b[1;34m(***failed resolving arguments***)\u001b[0m\n\u001b[0;32m   3272\u001b[0m           \u001b[0minput_types\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minput_types\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3273\u001b[0m           \u001b[0moriginal_op\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_default_original_op\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3274\u001b[1;33m           op_def=op_def)\n\u001b[0m\u001b[0;32m   3275\u001b[0m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_create_op_helper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mret\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcompute_device\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcompute_device\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3276\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mret\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\neuralnets\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, node_def, g, inputs, output_types, control_inputs, input_types, original_op, op_def)\u001b[0m\n\u001b[0;32m   1790\u001b[0m           op_def, inputs, node_def.attr)\n\u001b[0;32m   1791\u001b[0m       self._c_op = _create_c_op(self._graph, node_def, grouped_inputs,\n\u001b[1;32m-> 1792\u001b[1;33m                                 control_input_ops)\n\u001b[0m\u001b[0;32m   1793\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1794\u001b[0m     \u001b[1;31m# Initialize self._outputs.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\neuralnets\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\u001b[0m in \u001b[0;36m_create_c_op\u001b[1;34m(graph, node_def, inputs, control_inputs)\u001b[0m\n\u001b[0;32m   1629\u001b[0m   \u001b[1;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mInvalidArgumentError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1630\u001b[0m     \u001b[1;31m# Convert to ValueError for backwards compatibility.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1631\u001b[1;33m     \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1632\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1633\u001b[0m   \u001b[1;32mreturn\u001b[0m \u001b[0mc_op\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Dimensions must be equal, but are 0 and 1 for 'model_14_2/model_5/dense_7/MatMul' (op: 'MatMul') with input shapes: [?,0], [1,1]."
     ]
    }
   ],
   "source": [
    "model = net_cross_old((2,3))\n",
    "model.compile(loss = 'MSE',optimizer = 'adam',metrics = ['accuracy'])\n",
    "# model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = 'cross_product_17'\n",
    "\n",
    "if not os.path.exists('./'+model_name):\n",
    "    os.mkdir(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# checkpoint = ModelCheckpoint(model_name+'/'+model_name+'-{epoch:02d}-{val_loss:.2f}.h5', \n",
    "#                              monitor='val_loss', verbose=1, save_best_only=True, mode='auto')\n",
    "cvslogger = CSVLogger(model_name+'/logs.csv', separator=',', append=True)\n",
    "reducelr = ReduceLROnPlateau(monitor='val_loss', factor=0.2, patience=3, min_lr=0.000001)\n",
    "# tensorboard = LRTensorBoard(log_dir='./'+model_name, histogram_freq=0, write_graph=True, write_grads=1, \n",
    "#                             batch_size=batch_size, write_images=True)\n",
    "\n",
    "callbacks = [cvslogger, reducelr]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 10000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      " 9968/10000 [============================>.] - ETA: 0s - loss: 96997174868.6485 - acc: 0.5616"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-26-82fe55b3aa1c>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m fitted = model.fit(train_points, train_normals, validation_data = (test_points,test_normals),\n\u001b[1;32m----> 2\u001b[1;33m           batch_size=16, epochs=1 ,verbose=1)\n\u001b[0m",
      "\u001b[1;32m~\\.conda\\envs\\neuralnets\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[0;32m   1037\u001b[0m                                         \u001b[0minitial_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1038\u001b[0m                                         \u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1039\u001b[1;33m                                         validation_steps=validation_steps)\n\u001b[0m\u001b[0;32m   1040\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1041\u001b[0m     def evaluate(self, x=None, y=None,\n",
      "\u001b[1;32m~\\.conda\\envs\\neuralnets\\lib\\site-packages\\keras\\engine\\training_arrays.py\u001b[0m in \u001b[0;36mfit_loop\u001b[1;34m(model, f, ins, out_labels, batch_size, epochs, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch, steps_per_epoch, validation_steps)\u001b[0m\n\u001b[0;32m    210\u001b[0m                         val_outs = test_loop(model, val_f, val_ins,\n\u001b[0;32m    211\u001b[0m                                              \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 212\u001b[1;33m                                              verbose=0)\n\u001b[0m\u001b[0;32m    213\u001b[0m                         \u001b[0mval_outs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mval_outs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    214\u001b[0m                         \u001b[1;31m# Same labels assumed.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\neuralnets\\lib\\site-packages\\keras\\engine\\training_arrays.py\u001b[0m in \u001b[0;36mtest_loop\u001b[1;34m(model, f, ins, batch_size, verbose, steps)\u001b[0m\n\u001b[0;32m    390\u001b[0m                 \u001b[0mins_batch\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    391\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 392\u001b[1;33m             \u001b[0mbatch_outs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    393\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch_outs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    394\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0mbatch_index\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\neuralnets\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m   2713\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_legacy_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2714\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2715\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2716\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2717\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mpy_any\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mis_tensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\neuralnets\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py\u001b[0m in \u001b[0;36m_call\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m   2673\u001b[0m             \u001b[0mfetched\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun_metadata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2674\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2675\u001b[1;33m             \u001b[0mfetched\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2676\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mfetched\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2677\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\neuralnets\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1437\u001b[0m           ret = tf_session.TF_SessionRunCallable(\n\u001b[0;32m   1438\u001b[0m               \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstatus\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1439\u001b[1;33m               run_metadata_ptr)\n\u001b[0m\u001b[0;32m   1440\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1441\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "fitted = model.fit(train_points, train_normals, validation_data = (test_points,test_normals),\n",
    "          batch_size=16, epochs=1 ,verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "+ #### Test Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def func(x):\n",
    "    x = x.flat\n",
    "    ans = []\n",
    "    for i in range(6):\n",
    "        for j in range(6):\n",
    "            if i==j:\n",
    "                continue\n",
    "            ans.append(x[i] * x[j])\n",
    "    return ans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 433,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ True  True  True  True  True  True  True  True  True  True  True  True\n",
      " False  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True False  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True]\n"
     ]
    }
   ],
   "source": [
    "n = 6\n",
    "# out = model_neg_mult.evaluate(x_test,y_test)\n",
    "out = model_neg_mult.predict(x_test)\n",
    "# print(y_test[:5])\n",
    "# print(out.astype(int)[:5])\n",
    "print(np.squeeze(out.astype(int),-1) == y_test)\n",
    "# print(y_test.shape)\n",
    "\n",
    "# print('predicted answer: ', out[:,0])\n",
    "# print(np.equal(y_test,out[:,0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 5\n",
    "test = test_points[n:n+1,:,:]\n",
    "\n",
    "fig = plt.figure(figsize = (20,10))\n",
    "ax = fig.add_subplot(111, projection='3d')\n",
    "out = model.predict(test_points[0:10,:,:])\n",
    "# out_nor = normalize(out)\n",
    "\n",
    "origin = [0,0,0]\n",
    "# X,Y,Z = zip(origin,origin,origin,origin,origin,origin,origin)\n",
    "# U,V,W = zip(test_normals[n,:3],x1,x2,x3,x4,out_prop,out_nor[n,:])\n",
    "# ax.quiver(X,Y,Z,U,V,W,color = ['k','r','b','y','c','m','g'])\n",
    "X,Y,Z = zip(origin,origin)\n",
    "U,V,W = zip(test_normals[n,:]/np.linalg.norm(test_normals[n,:]),out[n,:]/np.linalg.norm(out[n,:]))\n",
    "ax.quiver(X,Y,Z,U,V,W,color = ['r','b'])\n",
    "ax.set_xlim([-1,1])\n",
    "ax.set_ylim([-1,1])\n",
    "ax.set_zlim([-1,1])\n",
    "ax.set_xlabel('x')\n",
    "ax.set_ylabel('y')\n",
    "ax.set_zlabel('z')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "+ #### Save Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
