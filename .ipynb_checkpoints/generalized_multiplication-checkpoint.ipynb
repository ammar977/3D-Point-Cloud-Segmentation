{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import NALU files\n",
    "import sys\n",
    "sys.path.insert(0, 'C:/Users/Ammar/Documents/CV LAB internship/Sproj/NALU_files')\n",
    "from nalu import NALU\n",
    "from nac import NAC\n",
    "# import Keras items\n",
    "from keras.models import Model\n",
    "from keras.layers import Dense,Lambda,Concatenate,Input,Activation,Layer,Dropout\n",
    "from keras import backend as K\n",
    "from keras.utils import to_categorical,plot_model\n",
    "from keras.initializers import constant\n",
    "\n",
    "# import other libs\n",
    "\n",
    "import numpy as np\n",
    "# from itertools import combinations_with_replacement,product\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow import floor as tf_floor\n",
    "from tensorflow.dtypes import as_string\n",
    "from tensorflow.strings import join,to_number\n",
    "from tensorflow import add"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = 'generalized_mult'\n",
    "EPOCHS = 2000\n",
    "BATCH_SIZE = 4\n",
    "num_digits = 3\n",
    "range_min = 0\n",
    "range_max = 999"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sep(x,num_digits):\n",
    "    x = np.array([int(i) for i in str(x)])\n",
    "    while (x.shape[0] < num_digits):\n",
    "        x = np.insert(x,0,0)\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sep2(x):\n",
    "    x = np.array([int(i) for i in str(x)])\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t (100, 2, 3)\n",
      "\t (100, 6)\n"
     ]
    }
   ],
   "source": [
    "# Dataset for Division\n",
    "x_train_a = np.random.randint(low = range_min,high = range_max,size =100)\n",
    "x_train_b = np.random.randint(low = range_min,high = range_max,size =100)\n",
    "y_train_a = x_train_a / x_train_b\n",
    "y_train_a = y_train_a.astype(np.int32)\n",
    "y_train = np.empty((100,num_digits*2),dtype = np.int32)\n",
    "\n",
    "x_train = np.empty((100,2,num_digits),dtype = np.int32)\n",
    "for i in range(100):\n",
    "    x_train[i,0] = sep(x_train_a[i],num_digits)\n",
    "    x_train[i,1] = sep(x_train_b[i],num_digits)\n",
    "    y_train[i] = sep(y_train_a[i],num_digits*2)\n",
    "\n",
    "print('\\t',x_train.shape)\n",
    "print('\\t',y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t (100, 2, 3)\n",
      "\t (100, 6)\n"
     ]
    }
   ],
   "source": [
    "x_train_a = np.random.randint(low = range_min,high = range_max,size =100)\n",
    "x_train_b = np.random.randint(low = range_min,high = range_max,size =100)\n",
    "\n",
    "x_train = np.empty((100,2,num_digits),dtype = np.int32)\n",
    "\n",
    "y_train_a = x_train_a * x_train_b\n",
    "y_train = np.empty((100,num_digits*2),dtype = np.int32)\n",
    "\n",
    "for i in range(100):\n",
    "    x_train[i,0] = sep(x_train_a[i],num_digits)\n",
    "    \n",
    "    x_train[i,1] = sep(x_train_b[i],num_digits)\n",
    "    y_train[i] = sep(y_train_a[i],num_digits*2)\n",
    "    \n",
    "print('\\t',x_train.shape)\n",
    "print('\\t',y_train.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def net(inputs):\n",
    "    input_data = Input(shape = inputs)\n",
    "    out = Dense(30,activation = 'relu',name='my_layer')(input_data)\n",
    "    out = Dense(82,activation='softmax')(out)\n",
    "    \n",
    "    return Model(inputs = input_data,outputs = out)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_mul = net((2,))\n",
    "model_mul.trainable = False\n",
    "model_mul.compile(loss = 'categorical_crossentropy',optimizer = 'Adam',metrics = ['accuracy'])\n",
    "# model_mul.summary()\n",
    "model_mul.load_weights('mul_0-9_classifier.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def separator(inputs):\n",
    "    input_data = Input(shape = inputs)\n",
    "    # addition = Dense(1,kernel_initializer='ones',use_bias=False)(input_data)\n",
    "    carry = Dense(1,use_bias=False,kernel_initializer=constant(value=0.1))(input_data)\n",
    "    carry = Lambda(lambda x: tf_floor(x))(carry)\n",
    "    \n",
    "    ones_digit = Dense(1,use_bias=False,kernel_initializer=constant(value=10))(carry)\n",
    "    temp = Concatenate()([ones_digit,input_data])\n",
    "    ones_digit = Dense(1,use_bias=False)(temp)\n",
    "    \n",
    "    out = Concatenate()([carry,ones_digit])\n",
    "    return Model(inputs = input_data,outputs = out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_separator = separator((1,))\n",
    "model_separator.layers[5].set_weights([np.array(([-1],[1]))])\n",
    "model_separator.trainable = False\n",
    "model_separator.compile(loss = 'MSE',optimizer = 'Adam',metrics = ['accuracy'])\n",
    "# model_separator.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "def net_mul(inputs):\n",
    "    input_data = Input(shape = inputs)\n",
    "    n = input_data[0].shape[-1]\n",
    "    m = input_data[1].shape[-1]\n",
    "    # get initial products\n",
    "    products=[]\n",
    "    for i in range(input_data.shape[-1]):\n",
    "        mul = Lambda(lambda x: x[:,0,i:i+1])(input_data)\n",
    "        for j in range(input_data.shape[-1]):\n",
    "            a = Lambda(lambda x: x[:,1,j:j+1])(input_data)\n",
    "            concat = Concatenate()([a,mul])\n",
    "            prod = model_mul(concat)\n",
    "            prod =  Lambda(lambda x: K.expand_dims(K.cast(K.argmax(x),dtype ='float32')))(prod)\n",
    "            products.append(prod)\n",
    "            \n",
    "    # get individual rows\n",
    "    products = products[::-1]\n",
    "    row_values = []\n",
    "    prod_index = 0\n",
    "    for r in range(n):\n",
    "        for i in range(m+1):\n",
    "            if i==0:\n",
    "                sep = model_separator(products[prod_index])\n",
    "                ones_digit = Lambda(lambda x: x[:,1:])(sep)\n",
    "                carry = Lambda(lambda x: x[:,0:1])(sep)\n",
    "                row_values.append(ones_digit)\n",
    "                prod_index+=1\n",
    "                \n",
    "            elif i == m :\n",
    "                row_values.append(carry)\n",
    "            else:\n",
    "                concat = Concatenate()([products[prod_index],carry])\n",
    "                addition =  Dense(1,use_bias=False,kernel_initializer='ones')(concat)\n",
    "                sep = model_separator(addition)\n",
    "                ones_digit = Lambda(lambda x: x[:,1:])(sep)\n",
    "                carry = Lambda(lambda x: x[:,0:1])(sep)\n",
    "                row_values.append(ones_digit)\n",
    "                prod_index+=1\n",
    "                \n",
    "    final_row = []\n",
    "    current_ind = 0\n",
    "    for i in range(m+n):\n",
    "        if i == 0:\n",
    "            final_row.append(row_values[0])\n",
    "            sep = model_separator(row_values[0])\n",
    "            carry = Lambda(lambda x: x[:,0:1])(sep)\n",
    "            current_ind+=1\n",
    "        else:\n",
    "            to_add = []\n",
    "            to_add.append(row_values[current_ind])\n",
    "            to_add.append(carry)\n",
    "            next_ind = current_ind + m\n",
    "            while(next_ind < n * (m+1) and next_ind%(m+1)!=0):\n",
    "                to_add.append(row_values[next_ind])\n",
    "                next_ind+=m\n",
    "            if (next_ind < n * (m+1) and next_ind%(m+1)==0):\n",
    "                to_add.append(row_values[next_ind])\n",
    "                \n",
    "            concat = Concatenate()(to_add)\n",
    "            addition =  Dense(1,use_bias=False,kernel_initializer='ones')(concat)\n",
    "            sep = model_separator(addition)\n",
    "            ones_digit = Lambda(lambda x: x[:,1:])(sep)\n",
    "            carry = Lambda(lambda x: x[:,0:1])(sep)\n",
    "            final_row.append(ones_digit)\n",
    "            \n",
    "            if (current_ind + 1) % (m+1) !=0:\n",
    "                current_ind+=1\n",
    "            else:\n",
    "                current_ind+=m+1\n",
    "\n",
    "    \n",
    "    concat = Concatenate()(final_row[::-1])\n",
    "    return Model(inputs = input_data,outputs =out)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "+ #### Model Initilization And Details"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_mult = net_mul((2,num_digits))\n",
    "model_mult.trainable=False\n",
    "model_mult.compile(loss = 'MSE',optimizer = 'Adam',metrics = ['accuracy'])\n",
    "# model_mult.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "def my_init(shape,dtype='float32'):\n",
    "    x = np.array(([1],[-1]),dtype = dtype)\n",
    "    print(x.shape)\n",
    "    return [x]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_neg(x):\n",
    "    return x[x >= 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def my_func(divisor):\n",
    "    print(divisor.shape)\n",
    "    length = divisor.shape[-1]\n",
    "    data = np.empty((10,2,length))\n",
    "    for i in range(10):\n",
    "        for j in range(length):\n",
    "            data[i,0,j] = 0\n",
    "            data[i,1,j] = divisor[0]\n",
    "\n",
    "        data[i,0,length-1] = i\n",
    "        data[i,1,length-1] = divisor[-1]\n",
    "\n",
    "    return data\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_data(num_digits):\n",
    "    data = np.zeros((10,num_digits))\n",
    "    for i in range(10):\n",
    "        for j in range(num_digits-1):\n",
    "            data[i,j] = 0\n",
    "        data[i,num_digits-1] = i\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "def net_div(inputs):\n",
    "    input_data = Input(shape = inputs)\n",
    "    quotient = []\n",
    "    \n",
    "    ind = input_data[1].shape[-1] # length of divisor\n",
    "    chunk = Lambda(lambda x: x[:,1,:ind])(input_data)\n",
    "    divisor = Lambda(lambda x: x[:,0,:])(input_data)\n",
    "    length = divisor.shape[-1]\n",
    "#     data = Input(shape=(10,length))\n",
    "    \n",
    "    \n",
    "    while(1):\n",
    "        temp = np.zeros((length,))\n",
    "        products = []\n",
    "        differences = []\n",
    "        for i in range(10):\n",
    "            for j in range(length-1):\n",
    "                temp[j] = 0\n",
    "            \n",
    "            temp[length-1] = i\n",
    "            temp1 = K.variable(temp)\n",
    "            data = Lambda(lambda x: K.stack(x,axis=0))([divisor[0],temp1])\n",
    "            data = Lambda(lambda x: K.expand_dims(x,0))(data)\n",
    "            print(data.shape)\n",
    "            \n",
    "            n = data[:,0].shape[-1]\n",
    "            m = data[:,1].shape[-1]\n",
    "            # get initial products\n",
    "            products=[]\n",
    "            for i in range(data.shape[-1]):\n",
    "                mul = Lambda(lambda x: x[:,0,i:i+1])(data)\n",
    "                for j in range(data.shape[-1]):\n",
    "                    a = Lambda(lambda x: x[:,1,j:j+1])(data)\n",
    "                    concat = Concatenate()([a,mul])\n",
    "                    prod = model_mul(concat)\n",
    "                    prod =  Lambda(lambda x: K.expand_dims(K.cast(K.argmax(x),dtype ='float32')))(prod)\n",
    "                    products.append(prod)\n",
    "\n",
    "            # get individual rows\n",
    "            products = products[::-1]\n",
    "            row_values = []\n",
    "            prod_index = 0\n",
    "            for r in range(n):\n",
    "                for i in range(m+1):\n",
    "                    if i==0:\n",
    "                        sep = model_separator(products[prod_index])\n",
    "                        ones_digit = Lambda(lambda x: x[:,1:])(sep)\n",
    "                        carry = Lambda(lambda x: x[:,0:1])(sep)\n",
    "                        row_values.append(ones_digit)\n",
    "                        prod_index+=1\n",
    "\n",
    "                    elif i == m :\n",
    "                        row_values.append(carry)\n",
    "                    else:\n",
    "                        concat = Concatenate()([products[prod_index],carry])\n",
    "                        addition =  Dense(1,use_bias=False,kernel_initializer='ones')(concat)\n",
    "                        sep = model_separator(addition)\n",
    "                        ones_digit = Lambda(lambda x: x[:,1:])(sep)\n",
    "                        carry = Lambda(lambda x: x[:,0:1])(sep)\n",
    "                        row_values.append(ones_digit)\n",
    "                        prod_index+=1\n",
    "\n",
    "            final_row = []\n",
    "            current_ind = 0\n",
    "            for i in range(m+n):\n",
    "                if i == 0:\n",
    "                    final_row.append(row_values[0])\n",
    "                    sep = model_separator(row_values[0])\n",
    "                    carry = Lambda(lambda x: x[:,0:1])(sep)\n",
    "                    current_ind+=1\n",
    "                else:\n",
    "                    to_add = []\n",
    "                    to_add.append(row_values[current_ind])\n",
    "                    to_add.append(carry)\n",
    "                    next_ind = current_ind + m\n",
    "                    while(next_ind < n * (m+1) and next_ind%(m+1)!=0):\n",
    "                        to_add.append(row_values[next_ind])\n",
    "                        next_ind+=m\n",
    "                    if (next_ind < n * (m+1) and next_ind%(m+1)==0):\n",
    "                        to_add.append(row_values[next_ind])\n",
    "\n",
    "                    concat = Concatenate()(to_add)\n",
    "                    addition =  Dense(1,use_bias=False,kernel_initializer='ones')(concat)\n",
    "                    sep = model_separator(addition)\n",
    "                    ones_digit = Lambda(lambda x: x[:,1:])(sep)\n",
    "                    carry = Lambda(lambda x: x[:,0:1])(sep)\n",
    "                    final_row.append(ones_digit)\n",
    "\n",
    "                    if (current_ind + 1) % (m+1) !=0:\n",
    "                        current_ind+=1\n",
    "                    else:\n",
    "                        current_ind+=m+1\n",
    "\n",
    "\n",
    "            concat = Concatenate()(final_row[::-1])\n",
    "                \n",
    "            \n",
    "#             ans = model_mult(data)\n",
    "            ans = concat\n",
    "            print(\"mult output shape\",ans.shape)\n",
    "            products.append(ans)\n",
    "            temp = Lambda(lambda x: as_string(x))(ans)\n",
    "            print(temp.shape,temp.dtype)\n",
    "            ans = Lambda(lambda x: to_number(join([temp[0,0],temp[0,1],temp[0,2],temp[0,3],temp[0,4],temp[0,5]])))(temp)\n",
    "            ans1 = K.expand_dims(ans)\n",
    "            print(ans1.shape,ans1.dtype)\n",
    "            \n",
    "            chunk1 = Lambda(lambda x: as_string(x))(chunk)\n",
    "            chunk1 = Lambda(lambda x: K.expand_dims(to_number(join([chunk1[0,0],chunk1[0,1],chunk1[0,2]]))))(chunk1)\n",
    "            concat = Concatenate()([chunk1,ans1])\n",
    "            concat = K.expand_dims(concat)\n",
    "            print(\"input to subtraction\",concat.shape)\n",
    "            subtraction = Dense(1,use_bias=False,kernel_initializer=my_init)(concat)\n",
    "            differences.append(subtraction)\n",
    "\n",
    "        min_index =  Lambda(lambda x: K.expand_dims(K.cast(K.argmin(remove_neg(x)),dtype ='float32')))(differences)\n",
    "        minimum = Lambda(lambda x: np.min(remove_neg(x)))(differences)\n",
    "        quotient.append(min_index)\n",
    "\n",
    "        # next chunk\n",
    "        if ind < input_data[1].shape[-1] :\n",
    "\n",
    "            chunk = Dense(1,use_bias=False,kernel_initializer=constant(10))(minimum)\n",
    "            next_digit = Lambda(lambda x: x[:,ind,ind+1])(input_data)\n",
    "            concat = Concatenate()([chunk,next_digit])\n",
    "            chunk = Dense(1,use_bias=False,kernel_initializer='ones')(concat)\n",
    "            ind+=1\n",
    "        else:\n",
    "            break\n",
    "\n",
    "    concat = Concatenate()([quotient])\n",
    "    return Model(inputs = input_data,outputs = concat)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 2, 3)\n",
      "mult output shape (1, 6)\n",
      "(1, 6) <dtype: 'string'>\n",
      "(1,) <dtype: 'float32'>\n",
      "input to subtraction (2, 1)\n",
      "(2, 1)\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "Expected float32, got array([[ 1.],\n       [-1.]], dtype=float32) of type 'ndarray' instead.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-122-f7b8d5ad6c2a>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mmodel_div\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnet_div\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mnum_digits\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mmodel_div\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrainable\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mmodel_div\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mloss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'MSE'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0moptimizer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'Adam'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mmetrics\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;34m'accuracy'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;31m# model.summary()\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-121-93e98a109a27>\u001b[0m in \u001b[0;36mnet_div\u001b[1;34m(inputs)\u001b[0m\n\u001b[0;32m    111\u001b[0m             \u001b[0mconcat\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mK\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexpand_dims\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mconcat\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    112\u001b[0m             \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"input to subtraction\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mconcat\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 113\u001b[1;33m             \u001b[0msubtraction\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mDense\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0muse_bias\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mkernel_initializer\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmy_init\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mconcat\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    114\u001b[0m             \u001b[0mdifferences\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msubtraction\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    115\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\neuralnets\\lib\\site-packages\\keras\\engine\\base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, inputs, **kwargs)\u001b[0m\n\u001b[0;32m    429\u001b[0m                                          \u001b[1;34m'You can build it manually via: '\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    430\u001b[0m                                          '`layer.build(batch_input_shape)`')\n\u001b[1;32m--> 431\u001b[1;33m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbuild\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0munpack_singleton\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput_shapes\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    432\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbuilt\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    433\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\neuralnets\\lib\\site-packages\\keras\\layers\\core.py\u001b[0m in \u001b[0;36mbuild\u001b[1;34m(self, input_shape)\u001b[0m\n\u001b[0;32m    864\u001b[0m                                       \u001b[0mname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'kernel'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    865\u001b[0m                                       \u001b[0mregularizer\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkernel_regularizer\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 866\u001b[1;33m                                       constraint=self.kernel_constraint)\n\u001b[0m\u001b[0;32m    867\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0muse_bias\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    868\u001b[0m             self.bias = self.add_weight(shape=(self.units,),\n",
      "\u001b[1;32m~\\.conda\\envs\\neuralnets\\lib\\site-packages\\keras\\legacy\\interfaces.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     89\u001b[0m                 warnings.warn('Update your `' + object_name + '` call to the ' +\n\u001b[0;32m     90\u001b[0m                               'Keras 2 API: ' + signature, stacklevel=2)\n\u001b[1;32m---> 91\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     92\u001b[0m         \u001b[0mwrapper\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_original_function\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     93\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\neuralnets\\lib\\site-packages\\keras\\engine\\base_layer.py\u001b[0m in \u001b[0;36madd_weight\u001b[1;34m(self, name, shape, dtype, initializer, regularizer, trainable, constraint)\u001b[0m\n\u001b[0;32m    250\u001b[0m                             \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    251\u001b[0m                             \u001b[0mname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 252\u001b[1;33m                             constraint=constraint)\n\u001b[0m\u001b[0;32m    253\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mregularizer\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    254\u001b[0m             \u001b[1;32mwith\u001b[0m \u001b[0mK\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mname_scope\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'weight_regularizer'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\neuralnets\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py\u001b[0m in \u001b[0;36mvariable\u001b[1;34m(value, dtype, name, constraint)\u001b[0m\n\u001b[0;32m    400\u001b[0m         \u001b[0mv\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_uses_learning_phase\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    401\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mv\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 402\u001b[1;33m     \u001b[0mv\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mVariable\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mas_dtype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    403\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    404\u001b[0m         \u001b[0mv\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_keras_shape\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\neuralnets\\lib\\site-packages\\tensorflow\\python\\ops\\variables.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(cls, *args, **kwargs)\u001b[0m\n\u001b[0;32m    181\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcls\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    182\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mcls\u001b[0m \u001b[1;32mis\u001b[0m \u001b[0mVariableV1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 183\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mcls\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_variable_v1_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    184\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0mcls\u001b[0m \u001b[1;32mis\u001b[0m \u001b[0mVariable\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    185\u001b[0m       \u001b[1;32mreturn\u001b[0m \u001b[0mcls\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_variable_v2_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\neuralnets\\lib\\site-packages\\tensorflow\\python\\ops\\variables.py\u001b[0m in \u001b[0;36m_variable_v1_call\u001b[1;34m(cls, initial_value, trainable, collections, validate_shape, caching_device, name, variable_def, dtype, expected_shape, import_scope, constraint, use_resource, synchronization, aggregation)\u001b[0m\n\u001b[0;32m    144\u001b[0m         \u001b[0muse_resource\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0muse_resource\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    145\u001b[0m         \u001b[0msynchronization\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msynchronization\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 146\u001b[1;33m         aggregation=aggregation)\n\u001b[0m\u001b[0;32m    147\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    148\u001b[0m   def _variable_v2_call(cls,\n",
      "\u001b[1;32m~\\.conda\\envs\\neuralnets\\lib\\site-packages\\tensorflow\\python\\ops\\variables.py\u001b[0m in \u001b[0;36m<lambda>\u001b[1;34m(**kwargs)\u001b[0m\n\u001b[0;32m    123\u001b[0m                         aggregation=VariableAggregation.NONE):\n\u001b[0;32m    124\u001b[0m     \u001b[1;34m\"\"\"Call on Variable class. Useful to force the signature.\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 125\u001b[1;33m     \u001b[0mprevious_getter\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mlambda\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mdefault_variable_creator\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    126\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mgetter\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_default_graph\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_variable_creator_stack\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    127\u001b[0m       \u001b[0mprevious_getter\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_make_getter\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgetter\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mprevious_getter\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\neuralnets\\lib\\site-packages\\tensorflow\\python\\ops\\variable_scope.py\u001b[0m in \u001b[0;36mdefault_variable_creator\u001b[1;34m(next_creator, **kwargs)\u001b[0m\n\u001b[0;32m   2442\u001b[0m         \u001b[0mcaching_device\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcaching_device\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2443\u001b[0m         \u001b[0mconstraint\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mconstraint\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvariable_def\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mvariable_def\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2444\u001b[1;33m         expected_shape=expected_shape, import_scope=import_scope)\n\u001b[0m\u001b[0;32m   2445\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2446\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\neuralnets\\lib\\site-packages\\tensorflow\\python\\ops\\variables.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(cls, *args, **kwargs)\u001b[0m\n\u001b[0;32m    185\u001b[0m       \u001b[1;32mreturn\u001b[0m \u001b[0mcls\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_variable_v2_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    186\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 187\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mVariableMetaclass\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcls\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__call__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    188\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    189\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\neuralnets\\lib\\site-packages\\tensorflow\\python\\ops\\variables.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, initial_value, trainable, collections, validate_shape, caching_device, name, variable_def, dtype, expected_shape, import_scope, constraint)\u001b[0m\n\u001b[0;32m   1327\u001b[0m           \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1328\u001b[0m           \u001b[0mexpected_shape\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mexpected_shape\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1329\u001b[1;33m           constraint=constraint)\n\u001b[0m\u001b[0;32m   1330\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1331\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m__repr__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\neuralnets\\lib\\site-packages\\tensorflow\\python\\ops\\variables.py\u001b[0m in \u001b[0;36m_init_from_args\u001b[1;34m(self, initial_value, trainable, collections, validate_shape, caching_device, name, dtype, expected_shape, constraint)\u001b[0m\n\u001b[0;32m   1447\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1448\u001b[0m           self._initial_value = ops.convert_to_tensor(\n\u001b[1;32m-> 1449\u001b[1;33m               initial_value, name=\"initial_value\", dtype=dtype)\n\u001b[0m\u001b[0;32m   1450\u001b[0m           \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1451\u001b[0m           \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_initial_value\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mop\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_control_flow_context\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\neuralnets\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\u001b[0m in \u001b[0;36mconvert_to_tensor\u001b[1;34m(value, dtype, name, preferred_dtype)\u001b[0m\n\u001b[0;32m   1048\u001b[0m       \u001b[0mname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1049\u001b[0m       \u001b[0mpreferred_dtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mpreferred_dtype\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1050\u001b[1;33m       as_ref=False)\n\u001b[0m\u001b[0;32m   1051\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1052\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\neuralnets\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\u001b[0m in \u001b[0;36minternal_convert_to_tensor\u001b[1;34m(value, dtype, name, as_ref, preferred_dtype, ctx)\u001b[0m\n\u001b[0;32m   1144\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1145\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mret\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1146\u001b[1;33m       \u001b[0mret\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mconversion_func\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mas_ref\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mas_ref\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1147\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1148\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mret\u001b[0m \u001b[1;32mis\u001b[0m \u001b[0mNotImplemented\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\neuralnets\\lib\\site-packages\\tensorflow\\python\\framework\\constant_op.py\u001b[0m in \u001b[0;36m_constant_tensor_conversion_function\u001b[1;34m(v, dtype, name, as_ref)\u001b[0m\n\u001b[0;32m    227\u001b[0m                                          as_ref=False):\n\u001b[0;32m    228\u001b[0m   \u001b[0m_\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mas_ref\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 229\u001b[1;33m   \u001b[1;32mreturn\u001b[0m \u001b[0mconstant\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mv\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    230\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    231\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\neuralnets\\lib\\site-packages\\tensorflow\\python\\framework\\constant_op.py\u001b[0m in \u001b[0;36mconstant\u001b[1;34m(value, dtype, shape, name, verify_shape)\u001b[0m\n\u001b[0;32m    206\u001b[0m   tensor_value.tensor.CopyFrom(\n\u001b[0;32m    207\u001b[0m       tensor_util.make_tensor_proto(\n\u001b[1;32m--> 208\u001b[1;33m           value, dtype=dtype, shape=shape, verify_shape=verify_shape))\n\u001b[0m\u001b[0;32m    209\u001b[0m   \u001b[0mdtype_value\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mattr_value_pb2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mAttrValue\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtensor_value\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    210\u001b[0m   const_tensor = g.create_op(\n",
      "\u001b[1;32m~\\.conda\\envs\\neuralnets\\lib\\site-packages\\tensorflow\\python\\framework\\tensor_util.py\u001b[0m in \u001b[0;36mmake_tensor_proto\u001b[1;34m(values, dtype, shape, verify_shape)\u001b[0m\n\u001b[0;32m    440\u001b[0m       \u001b[0mnparray\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mempty\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mnp_dt\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    441\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 442\u001b[1;33m       \u001b[0m_AssertCompatible\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    443\u001b[0m       \u001b[0mnparray\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mnp_dt\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    444\u001b[0m       \u001b[1;31m# check to them.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\neuralnets\\lib\\site-packages\\tensorflow\\python\\framework\\tensor_util.py\u001b[0m in \u001b[0;36m_AssertCompatible\u001b[1;34m(values, dtype)\u001b[0m\n\u001b[0;32m    351\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    352\u001b[0m       raise TypeError(\"Expected %s, got %s of type '%s' instead.\" %\n\u001b[1;32m--> 353\u001b[1;33m                       (dtype.name, repr(mismatch), type(mismatch).__name__))\n\u001b[0m\u001b[0;32m    354\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    355\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: Expected float32, got array([[ 1.],\n       [-1.]], dtype=float32) of type 'ndarray' instead."
     ]
    }
   ],
   "source": [
    "model_div = net_div((2,num_digits))\n",
    "model_div.trainable=False\n",
    "model_div.compile(loss = 'MSE',optimizer = 'Adam',metrics = ['accuracy'])\n",
    "# model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "+ #### Test Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 2, 3)\n",
      "\n",
      " \t [5 5 4]  *  [7 6 2]  =  [4 2 2 1 4 8]\n",
      "\t predicted:  [4. 2. 2. 1. 4. 8.]\n"
     ]
    }
   ],
   "source": [
    "out = model_mult.predict(x_train[0:1])\n",
    "print(x_train[0:1].shape)\n",
    "for i in range(out.shape[0]):\n",
    "    print ('\\n \\t',x_train[i,0],' * ',x_train[i,1],' = ', y_train[i])\n",
    "    print('\\t predicted: ',out[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "+ #### Save Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot_model(model,to_file = 'final.png',show_shapes=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
