{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 10\n",
    "range_min = 0\n",
    "range_max = 9999999999\n",
    "batch_size = 4 \n",
    "num_classes = 2\n",
    "num_train_samples = 100\n",
    "num_test_samples = 100\n",
    "num_digits = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(100, 3)\n",
      "(100,)\n"
     ]
    }
   ],
   "source": [
    "temp = np.random.rand(num_train_samples).astype(np.float64) * range_max\n",
    "temp = np.floor(temp)\n",
    "x_train = np.empty((num_train_samples,3)).astype(np.float64)\n",
    "x_train[:,0] = temp\n",
    "x_train[:num_train_samples // 2,1] = 1.0  \n",
    "x_train[num_train_samples // 2:,1] = -1.0\n",
    "x_train[:,2] = num_digits\n",
    "np.random.shuffle(x_train)\n",
    "y_train = x_train[:,0] * x_train[:,1]\n",
    "print(x_train.shape)\n",
    "print(y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "high is out of bounds for int32",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-19-a2b5864488b5>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mtemp\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrandint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlow\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mrange_min\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mhigh\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mrange_max\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0msize\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mnum_train_samples\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mx_train\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mempty\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnum_train_samples\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mx_train\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtemp\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mx_train\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mnum_train_samples\u001b[0m \u001b[1;33m//\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m1.0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mx_train\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mnum_train_samples\u001b[0m \u001b[1;33m//\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m-\u001b[0m\u001b[1;36m1.0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mmtrand.pyx\u001b[0m in \u001b[0;36mmtrand.RandomState.randint\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: high is out of bounds for int32"
     ]
    }
   ],
   "source": [
    "temp = np.random.randint(low=range_min,high = range_max+1,size = (num_train_samples,))\n",
    "x_train = np.empty((num_train_samples,3))\n",
    "x_train[:,0] = temp\n",
    "x_train[:num_train_samples // 2,1] = 1.0  \n",
    "x_train[num_train_samples // 2:,1] = -1.0\n",
    "x_train[:,2] = num_digits\n",
    "np.random.shuffle(x_train)\n",
    "y_train = x_train[:,0] * x_train[:,1]\n",
    "print(x_train.shape)\n",
    "print(y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = torch.from_numpy(x_train).type(torch.float64)\n",
    "train_labels = torch.from_numpy(y_train).type(torch.float64)\n",
    "# test_data = torch.from_numpy(x_test).type(torch.FloatTensor)\n",
    "# test_labels = torch.from_numpy(y_test).type(torch.LongTensor)\n",
    "torch.set_printoptions(precision = 15)\n",
    "torch.set_default_dtype(torch.float64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This model subtracts two numbers\n",
    "class Net_sub(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net_sub,self).__init__()\n",
    "        self.fc1 = nn.Linear(2,1,bias=False)\n",
    "        self.fc1.weight.data = torch.tensor([[1,-1]]).type(torch.float64)\n",
    "    \n",
    "    def forward(self,x):\n",
    "        x = self.fc1(x)\n",
    "        return x\n",
    "    \n",
    "    def predict(self,x):\n",
    "        return self.forward(x).type(torch.float64)\n",
    "    \n",
    "# model_sub = torch.load('model_sub').double()\n",
    "# model_sub = torch.load('model_sub').type(torch.float64)\n",
    "model_sub = Net_sub().type(torch.float64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This model will separate a number into digits\n",
    "# input: 2 inputs - (number,num_digits)\n",
    "# output: separated digits (num_digits,)  \n",
    "\n",
    "class Net_separate(nn.Module):\n",
    "    def __init__(self,model_sub):\n",
    "        super(Net_separate,self).__init__()\n",
    "        \n",
    "        self.divide_by_10 = nn.Linear(1,1,bias=False).type(torch.float64)\n",
    "        self.divide_by_10.weight.data = torch.tensor([[0.1]]).type(torch.float64)\n",
    "\n",
    "        self.multiply_by_10 = nn.Linear(1,1,bias=False)\n",
    "        self.multiply_by_10.weight.data = torch.tensor([[10]]).type(torch.float64)\n",
    "        \n",
    "        self.model_sub = model_sub\n",
    "    \n",
    "    def forward(self,x):\n",
    "        input_number = x[:,0].unsqueeze(-1)\n",
    "        num_digits = x[:,1].unsqueeze(-1)\n",
    "        concat = []\n",
    "        data = input_number\n",
    "        for i in range(num_digits[0].type(torch.IntTensor)):\n",
    "            temp_data = self.divide_by_10(data)\n",
    "#             print(temp_data)\n",
    "            temp_data = temp_data.floor()\n",
    "            temp = self.multiply_by_10(temp_data)\n",
    "            concat_temp = torch.cat((data,temp),1)\n",
    "            digit = self.model_sub.predict(concat_temp)\n",
    "            \n",
    "            concat.insert(0,digit)\n",
    "            data = temp_data\n",
    "        \n",
    "        out = torch.cat(concat,1)\n",
    "        return out\n",
    "    \n",
    "    def predict(self,x):\n",
    "        return self.forward(x).type(torch.float64)\n",
    "    \n",
    "# model_separate = torch.load('model_separate').double()  \n",
    "# model_separate = torch.load('model_separate').type(torch.float64)\n",
    "model_separate = Net_separate(model_sub).type(torch.float64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this model mulltiplies a single digit number with a sign (1,-1)\n",
    "# input: 2 numbers (2,)\n",
    "# output: single number \n",
    "class Net_mul_sign_0_9(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net_mul_sign_0_9,self).__init__()\n",
    "        self.fc1 = nn.Linear(2,10)\n",
    "        self.fc2 = nn.Linear(10,1)\n",
    "    \n",
    "    def forward(self,x):\n",
    "        x = F.softsign(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "    \n",
    "    def predict(self,x):\n",
    "        out = self.forward(x)\n",
    "        return torch.round(out).type(torch.float64)\n",
    "\n",
    "# model_mul_sign_0_9 = torch.load('model_mul_sign_0_9').double()\n",
    "model_mul_sign_0_9 = torch.load('model_mul_sign_0_9').type(torch.float64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this model mulltiplies a number with a sign (1,-1)\n",
    "# input: 3 numbers (3,) - [number,sign,num_digits]\n",
    "# output: single number \n",
    "class Net_mul_sign_abs(nn.Module):\n",
    "    def __init__(self,model_separate,model_mul_sign_0_9):\n",
    "        super(Net_mul_sign_abs,self).__init__()\n",
    "        self.model_separate = model_separate\n",
    "        self.model_mul_sign_0_9 = model_mul_sign_0_9\n",
    "        self.multiply_2 = nn.Linear(1,1,bias = False)\n",
    "        self.multiply_2.weight.data = torch.tensor([[2.0]]).type(torch.float64)\n",
    "        self.layers = []\n",
    "    \n",
    "    def forward(self,x):\n",
    "        number = x[:,0].unsqueeze(-1)\n",
    "        sign = x[:,1].unsqueeze(-1)\n",
    "        num_digits = x[:,2].unsqueeze(-1)\n",
    "        \n",
    "        output_digits = self.multiply_2(num_digits)\n",
    "        concat = torch.cat((number,output_digits),1)\n",
    "        sep = self.model_separate.predict(concat)\n",
    "#         print(sep)\n",
    "        products = []\n",
    "        i = 0\n",
    "        j = sep.shape[-1]\n",
    "        for n in range(j,0,-1):\n",
    "            temp = sep[:,n-1:n]\n",
    "            concat = torch.cat((temp,sign),1)\n",
    "            prod = self.model_mul_sign_0_9.predict(concat)\n",
    "            self.layers.append(nn.Linear(1,1,bias=False))\n",
    "            self.layers[-1].weight.data = torch.tensor([[10.0**i]]).type(torch.float64)\n",
    "            prod = self.layers[-1](prod)\n",
    "            products.append(prod)\n",
    "            i+=1\n",
    "        \n",
    "        concat = torch.cat(products,1)\n",
    "        self.layers.append(nn.Linear(1,1,bias=False))\n",
    "        self.layers[-1].weight.data = np.repeat(torch.tensor([[1.0]]),len(products),axis = -1).type(torch.float64)\n",
    "        out = self.layers[-1](concat)\n",
    "        return out\n",
    "    \n",
    "    def predict(self,x):\n",
    "        out = self.forward(x)\n",
    "        return out.type(torch.float64)\n",
    "    \n",
    "# model_mul_sign_abs = torch.load('model_mul_sign_abs').double()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = Net_mul_sign_abs(model_separate,model_mul_sign_0_9).type(torch.float64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 7.016714045000000e+09, -1.000000000000000e+00,  1.000000000000000e+01]])\n",
      "tensor([-7.016714045000000e+09])\n",
      "tensor([[7.016714045000000e+08]], grad_fn=<MmBackward>)\n",
      "tensor([[70167140.400000005960464]], grad_fn=<MmBackward>)\n",
      "tensor([[7016714.]], grad_fn=<MmBackward>)\n",
      "tensor([[701671.400000000023283]], grad_fn=<MmBackward>)\n",
      "tensor([[70167.100000000005821]], grad_fn=<MmBackward>)\n",
      "tensor([[7016.700000000000728]], grad_fn=<MmBackward>)\n",
      "tensor([[701.600000000000023]], grad_fn=<MmBackward>)\n",
      "tensor([[70.100000000000009]], grad_fn=<MmBackward>)\n",
      "tensor([[7.]], grad_fn=<MmBackward>)\n",
      "tensor([[0.700000000000000]], grad_fn=<MmBackward>)\n",
      "tensor([[0.]], grad_fn=<MmBackward>)\n",
      "tensor([[0.]], grad_fn=<MmBackward>)\n",
      "tensor([[0.]], grad_fn=<MmBackward>)\n",
      "tensor([[0.]], grad_fn=<MmBackward>)\n",
      "tensor([[0.]], grad_fn=<MmBackward>)\n",
      "tensor([[0.]], grad_fn=<MmBackward>)\n",
      "tensor([[0.]], grad_fn=<MmBackward>)\n",
      "tensor([[0.]], grad_fn=<MmBackward>)\n",
      "tensor([[0.]], grad_fn=<MmBackward>)\n",
      "tensor([[0.]], grad_fn=<MmBackward>)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[-7.016714045000000e+09]], grad_fn=<MmBackward>)"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(train_data[0:1])\n",
    "print(train_labels[0:1])\n",
    "net.forward(train_data[0:1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[7.016714045000000e+08],\n",
      "        [1.848785309000000e+08],\n",
      "        [7.175172950000000e+08],\n",
      "        [6.063519540000000e+08],\n",
      "        [5.702586941000000e+08],\n",
      "        [4.544885421000000e+08],\n",
      "        [6.812792462000000e+08],\n",
      "        [5.288996730000000e+07],\n",
      "        [2.738975166000000e+08],\n",
      "        [1.030470925000000e+08],\n",
      "        [2.346167237000000e+08],\n",
      "        [6.386227750000000e+07],\n",
      "        [7.504543222000000e+08],\n",
      "        [4.644322012000000e+08],\n",
      "        [3.809736000000000e+06],\n",
      "        [3.120372273000000e+08],\n",
      "        [4.747838579000000e+08],\n",
      "        [7.037941298000001e+08],\n",
      "        [4.108513707000000e+08],\n",
      "        [9.629269127000000e+08],\n",
      "        [3.236391900000000e+06],\n",
      "        [7.920251713000001e+08],\n",
      "        [8.776859565000000e+08],\n",
      "        [1.797074262000000e+08],\n",
      "        [6.311430970000000e+07],\n",
      "        [4.506420689000000e+08],\n",
      "        [6.798314456000000e+08],\n",
      "        [6.037156435000000e+08],\n",
      "        [9.646628444000001e+08],\n",
      "        [2.574740781000000e+08],\n",
      "        [2.846431922000000e+08],\n",
      "        [1.045585782000000e+08],\n",
      "        [9.078141280000000e+08],\n",
      "        [2.399534917000000e+08],\n",
      "        [4.650825895000000e+08],\n",
      "        [5.340218960000000e+07],\n",
      "        [8.069197233000001e+08],\n",
      "        [5.090555127000000e+08],\n",
      "        [4.069934070000000e+08],\n",
      "        [5.495485540000001e+07],\n",
      "        [6.829714047000000e+08],\n",
      "        [5.323614022000000e+08],\n",
      "        [6.290205292000000e+08],\n",
      "        [4.290138446000000e+08],\n",
      "        [7.922167239000001e+08],\n",
      "        [1.110974877000000e+08],\n",
      "        [6.236044724000000e+08],\n",
      "        [5.783830833000001e+08],\n",
      "        [6.895350308000001e+08],\n",
      "        [7.047621827000000e+08],\n",
      "        [8.571141646000000e+08],\n",
      "        [2.788917768000000e+08],\n",
      "        [3.127254773000000e+08],\n",
      "        [4.934089546000000e+08],\n",
      "        [5.502174849000000e+08],\n",
      "        [1.257161655000000e+08],\n",
      "        [6.028627458000001e+08],\n",
      "        [5.788998137000000e+08],\n",
      "        [4.071885104000000e+08],\n",
      "        [7.693027811000000e+08],\n",
      "        [6.696559362000000e+08],\n",
      "        [3.614188706000000e+08],\n",
      "        [2.207058418000000e+08],\n",
      "        [5.101619993000000e+08],\n",
      "        [4.968594072000000e+08],\n",
      "        [9.668422099000001e+08],\n",
      "        [2.884998239000000e+08],\n",
      "        [8.949787710000001e+07],\n",
      "        [7.726162574000001e+08],\n",
      "        [4.159270748000000e+08],\n",
      "        [1.974891308000000e+08],\n",
      "        [1.928717739000000e+08],\n",
      "        [1.911919585000000e+08],\n",
      "        [7.707885400000000e+06],\n",
      "        [4.636827600000000e+08],\n",
      "        [3.432560037000000e+08],\n",
      "        [8.447188232000000e+08],\n",
      "        [4.067319701000000e+08],\n",
      "        [5.592828131000000e+08],\n",
      "        [1.766135272000000e+08],\n",
      "        [8.380079600000001e+06],\n",
      "        [9.996627973000001e+08],\n",
      "        [7.057970570000000e+08],\n",
      "        [7.048974250000000e+07],\n",
      "        [3.192824939000000e+08],\n",
      "        [4.090686034000000e+08],\n",
      "        [8.430351800000000e+07],\n",
      "        [5.056138327000000e+08],\n",
      "        [6.636350231000000e+08],\n",
      "        [2.008431998000000e+08],\n",
      "        [1.800890352000000e+08],\n",
      "        [9.182463857000000e+08],\n",
      "        [9.822980597000000e+08],\n",
      "        [9.960399505000000e+08],\n",
      "        [4.118078034000000e+08],\n",
      "        [2.564277596000000e+08],\n",
      "        [5.884702838000001e+08],\n",
      "        [6.211390888000001e+08],\n",
      "        [2.280450400000000e+06],\n",
      "        [3.074227420000000e+07]], grad_fn=<MmBackward>)\n",
      "tensor([[70167140.400000005960464],\n",
      "        [18487853.000000000000000],\n",
      "        [71751729.500000000000000],\n",
      "        [60635195.400000005960464],\n",
      "        [57025869.400000005960464],\n",
      "        [45448854.200000002980232],\n",
      "        [68127924.600000008940697],\n",
      "        [ 5288996.700000000186265],\n",
      "        [27389751.600000001490116],\n",
      "        [10304709.200000001117587],\n",
      "        [23461672.300000000745058],\n",
      "        [ 6386227.700000000186265],\n",
      "        [75045432.200000002980232],\n",
      "        [46443220.100000001490116],\n",
      "        [  380973.600000000034925],\n",
      "        [31203722.700000002980232],\n",
      "        [47478385.700000002980232],\n",
      "        [70379412.900000005960464],\n",
      "        [41085137.000000000000000],\n",
      "        [96292691.200000002980232],\n",
      "        [  323639.100000000034925],\n",
      "        [79202517.100000008940697],\n",
      "        [87768595.600000008940697],\n",
      "        [17970742.600000001490116],\n",
      "        [ 6311430.900000000372529],\n",
      "        [45064206.800000004470348],\n",
      "        [67983144.500000000000000],\n",
      "        [60371564.300000004470348],\n",
      "        [96466284.400000005960464],\n",
      "        [25747407.800000000745058],\n",
      "        [28464319.200000002980232],\n",
      "        [10455857.800000000745058],\n",
      "        [90781412.800000011920929],\n",
      "        [23995349.100000001490116],\n",
      "        [46508258.900000005960464],\n",
      "        [ 5340218.900000000372529],\n",
      "        [80691972.300000011920929],\n",
      "        [50905551.200000002980232],\n",
      "        [40699340.700000002980232],\n",
      "        [ 5495485.500000000000000],\n",
      "        [68297140.400000005960464],\n",
      "        [53236140.200000002980232],\n",
      "        [62902052.900000005960464],\n",
      "        [42901384.400000005960464],\n",
      "        [79221672.299999997019768],\n",
      "        [11109748.700000001117587],\n",
      "        [62360447.200000002980232],\n",
      "        [57838308.300000004470348],\n",
      "        [68953503.000000000000000],\n",
      "        [70476218.200000002980232],\n",
      "        [85711416.400000005960464],\n",
      "        [27889177.600000001490116],\n",
      "        [31272547.700000002980232],\n",
      "        [49340895.400000005960464],\n",
      "        [55021748.400000005960464],\n",
      "        [12571616.500000000000000],\n",
      "        [60286274.500000000000000],\n",
      "        [57889981.300000004470348],\n",
      "        [40718851.000000000000000],\n",
      "        [76930278.100000008940697],\n",
      "        [66965593.600000001490116],\n",
      "        [36141887.000000000000000],\n",
      "        [22070584.100000001490116],\n",
      "        [51016199.900000005960464],\n",
      "        [49685940.700000002980232],\n",
      "        [96684220.900000005960464],\n",
      "        [28849982.300000000745058],\n",
      "        [ 8949787.700000001117587],\n",
      "        [77261625.700000002980232],\n",
      "        [41592707.400000005960464],\n",
      "        [19748913.000000000000000],\n",
      "        [19287177.300000000745058],\n",
      "        [19119195.800000000745058],\n",
      "        [  770788.500000000000000],\n",
      "        [46368276.000000000000000],\n",
      "        [34325600.300000004470348],\n",
      "        [84471882.300000011920929],\n",
      "        [40673197.000000000000000],\n",
      "        [55928281.300000004470348],\n",
      "        [17661352.699999999254942],\n",
      "        [  838007.900000000023283],\n",
      "        [99966279.700000002980232],\n",
      "        [70579705.700000002980232],\n",
      "        [ 7048974.200000000186265],\n",
      "        [31928249.300000000745058],\n",
      "        [40906860.300000004470348],\n",
      "        [ 8430351.800000000745058],\n",
      "        [50561383.200000002980232],\n",
      "        [66363502.300000004470348],\n",
      "        [20084319.900000002235174],\n",
      "        [18008903.500000000000000],\n",
      "        [91824638.500000000000000],\n",
      "        [98229805.900000005960464],\n",
      "        [99603995.000000000000000],\n",
      "        [41180780.300000004470348],\n",
      "        [25642775.900000002235174],\n",
      "        [58847028.300000004470348],\n",
      "        [62113908.800000004470348],\n",
      "        [  228045.000000000000000],\n",
      "        [ 3074227.400000000372529]], grad_fn=<MmBackward>)\n",
      "tensor([[7016714.000000000000000],\n",
      "        [1848785.300000000046566],\n",
      "        [7175172.900000000372529],\n",
      "        [6063519.500000000000000],\n",
      "        [5702586.900000000372529],\n",
      "        [4544885.400000000372529],\n",
      "        [6812792.400000000372529],\n",
      "        [ 528899.599999999976717],\n",
      "        [2738975.100000000093132],\n",
      "        [1030470.900000000023283],\n",
      "        [2346167.200000000186265],\n",
      "        [ 638622.700000000069849],\n",
      "        [7504543.200000000186265],\n",
      "        [4644322.000000000000000],\n",
      "        [  38097.300000000002910],\n",
      "        [3120372.200000000186265],\n",
      "        [4747838.500000000000000],\n",
      "        [7037941.200000000186265],\n",
      "        [4108513.700000000186265],\n",
      "        [9629269.099999999627471],\n",
      "        [  32363.900000000001455],\n",
      "        [7920251.700000000186265],\n",
      "        [8776859.500000000000000],\n",
      "        [1797074.200000000186265],\n",
      "        [ 631143.000000000000000],\n",
      "        [4506420.600000000558794],\n",
      "        [6798314.400000000372529],\n",
      "        [6037156.400000000372529],\n",
      "        [9646628.400000000372529],\n",
      "        [2574740.700000000186265],\n",
      "        [2846431.900000000372529],\n",
      "        [1045585.700000000069849],\n",
      "        [9078141.200000001117587],\n",
      "        [2399534.899999999906868],\n",
      "        [4650825.799999999813735],\n",
      "        [ 534021.800000000046566],\n",
      "        [8069197.200000000186265],\n",
      "        [5090555.100000000558794],\n",
      "        [4069934.000000000000000],\n",
      "        [ 549548.500000000000000],\n",
      "        [6829714.000000000000000],\n",
      "        [5323614.000000000000000],\n",
      "        [6290205.200000000186265],\n",
      "        [4290138.400000000372529],\n",
      "        [7922167.200000000186265],\n",
      "        [1110974.800000000046566],\n",
      "        [6236044.700000000186265],\n",
      "        [5783830.800000000745058],\n",
      "        [6895350.300000000745058],\n",
      "        [7047621.800000000745058],\n",
      "        [8571141.599999999627471],\n",
      "        [2788917.700000000186265],\n",
      "        [3127254.700000000186265],\n",
      "        [4934089.500000000000000],\n",
      "        [5502174.800000000745058],\n",
      "        [1257161.600000000093132],\n",
      "        [6028627.400000000372529],\n",
      "        [5788998.100000000558794],\n",
      "        [4071885.100000000093132],\n",
      "        [7693027.800000000745058],\n",
      "        [6696559.300000000745058],\n",
      "        [3614188.700000000186265],\n",
      "        [2207058.399999999906868],\n",
      "        [5101619.900000000372529],\n",
      "        [4968594.000000000000000],\n",
      "        [9668422.000000000000000],\n",
      "        [2884998.200000000186265],\n",
      "        [ 894978.700000000069849],\n",
      "        [7726162.500000000000000],\n",
      "        [4159270.700000000186265],\n",
      "        [1974891.300000000046566],\n",
      "        [1928717.700000000186265],\n",
      "        [1911919.500000000000000],\n",
      "        [  77078.800000000002910],\n",
      "        [4636827.600000000558794],\n",
      "        [3432560.000000000000000],\n",
      "        [8447188.200000001117587],\n",
      "        [4067319.700000000186265],\n",
      "        [5592828.100000000558794],\n",
      "        [1766135.200000000186265],\n",
      "        [  83800.700000000011642],\n",
      "        [9996627.900000000372529],\n",
      "        [7057970.500000000000000],\n",
      "        [ 704897.400000000023283],\n",
      "        [3192824.900000000372529],\n",
      "        [4090686.000000000000000],\n",
      "        [ 843035.100000000093132],\n",
      "        [5056138.300000000745058],\n",
      "        [6636350.200000000186265],\n",
      "        [2008431.900000000139698],\n",
      "        [1800890.300000000046566],\n",
      "        [9182463.800000000745058],\n",
      "        [9822980.500000000000000],\n",
      "        [9960399.500000000000000],\n",
      "        [4118078.000000000000000],\n",
      "        [2564277.500000000000000],\n",
      "        [5884702.800000000745058],\n",
      "        [6211390.800000000745058],\n",
      "        [  22804.500000000000000],\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        [ 307422.700000000011642]], grad_fn=<MmBackward>)\n",
      "tensor([[701671.400000000023283],\n",
      "        [184878.500000000000000],\n",
      "        [717517.200000000069849],\n",
      "        [606351.900000000023283],\n",
      "        [570258.599999999976717],\n",
      "        [454488.500000000000000],\n",
      "        [681279.200000000069849],\n",
      "        [ 52889.900000000001455],\n",
      "        [273897.500000000000000],\n",
      "        [103047.000000000000000],\n",
      "        [234616.700000000011642],\n",
      "        [ 63862.200000000004366],\n",
      "        [750454.300000000046566],\n",
      "        [464432.200000000011642],\n",
      "        [  3809.700000000000273],\n",
      "        [312037.200000000011642],\n",
      "        [474783.800000000046566],\n",
      "        [703794.100000000093132],\n",
      "        [410851.300000000046566],\n",
      "        [962926.900000000023283],\n",
      "        [  3236.300000000000182],\n",
      "        [792025.100000000093132],\n",
      "        [877685.900000000023283],\n",
      "        [179707.400000000023283],\n",
      "        [ 63114.300000000002910],\n",
      "        [450642.000000000000000],\n",
      "        [679831.400000000023283],\n",
      "        [603715.599999999976717],\n",
      "        [964662.800000000046566],\n",
      "        [257474.000000000000000],\n",
      "        [284643.100000000034925],\n",
      "        [104558.500000000000000],\n",
      "        [907814.100000000093132],\n",
      "        [239953.400000000023283],\n",
      "        [465082.500000000000000],\n",
      "        [ 53402.100000000005821],\n",
      "        [806919.700000000069849],\n",
      "        [509055.500000000000000],\n",
      "        [406993.400000000023283],\n",
      "        [ 54954.800000000002910],\n",
      "        [682971.400000000023283],\n",
      "        [532361.400000000023283],\n",
      "        [629020.500000000000000],\n",
      "        [429013.800000000046566],\n",
      "        [792216.700000000069849],\n",
      "        [111097.400000000008731],\n",
      "        [623604.400000000023283],\n",
      "        [578383.000000000000000],\n",
      "        [689535.000000000000000],\n",
      "        [704762.100000000093132],\n",
      "        [857114.100000000093132],\n",
      "        [278891.700000000011642],\n",
      "        [312725.400000000023283],\n",
      "        [493408.900000000023283],\n",
      "        [550217.400000000023283],\n",
      "        [125716.100000000005821],\n",
      "        [602862.700000000069849],\n",
      "        [578899.800000000046566],\n",
      "        [407188.500000000000000],\n",
      "        [769302.700000000069849],\n",
      "        [669655.900000000023283],\n",
      "        [361418.800000000046566],\n",
      "        [220705.800000000017462],\n",
      "        [510161.900000000023283],\n",
      "        [496859.400000000023283],\n",
      "        [966842.200000000069849],\n",
      "        [288499.799999999988358],\n",
      "        [ 89497.800000000002910],\n",
      "        [772616.200000000069849],\n",
      "        [415927.000000000000000],\n",
      "        [197489.100000000005821],\n",
      "        [192871.700000000011642],\n",
      "        [191191.900000000023283],\n",
      "        [  7707.800000000000182],\n",
      "        [463682.700000000011642],\n",
      "        [343256.000000000000000],\n",
      "        [844718.800000000046566],\n",
      "        [406731.900000000023283],\n",
      "        [559282.800000000046566],\n",
      "        [176613.500000000000000],\n",
      "        [  8380.000000000000000],\n",
      "        [999662.700000000069849],\n",
      "        [705797.000000000000000],\n",
      "        [ 70489.699999999997090],\n",
      "        [319282.400000000023283],\n",
      "        [409068.600000000034925],\n",
      "        [ 84303.500000000000000],\n",
      "        [505613.800000000046566],\n",
      "        [663635.000000000000000],\n",
      "        [200843.100000000005821],\n",
      "        [180089.000000000000000],\n",
      "        [918246.300000000046566],\n",
      "        [982298.000000000000000],\n",
      "        [996039.900000000023283],\n",
      "        [411807.800000000046566],\n",
      "        [256427.700000000011642],\n",
      "        [588470.200000000069849],\n",
      "        [621139.000000000000000],\n",
      "        [  2280.400000000000091],\n",
      "        [ 30742.200000000000728]], grad_fn=<MmBackward>)\n",
      "tensor([[70167.100000000005821],\n",
      "        [18487.799999999999272],\n",
      "        [71751.699999999997090],\n",
      "        [60635.100000000005821],\n",
      "        [57025.800000000002910],\n",
      "        [45448.800000000002910],\n",
      "        [68127.900000000008731],\n",
      "        [ 5288.900000000000546],\n",
      "        [27389.700000000000728],\n",
      "        [10304.700000000000728],\n",
      "        [23461.600000000002183],\n",
      "        [ 6386.200000000000728],\n",
      "        [75045.400000000008731],\n",
      "        [46443.200000000004366],\n",
      "        [  380.900000000000034],\n",
      "        [31203.700000000000728],\n",
      "        [47478.300000000002910],\n",
      "        [70379.400000000008731],\n",
      "        [41085.100000000005821],\n",
      "        [96292.600000000005821],\n",
      "        [  323.600000000000023],\n",
      "        [79202.500000000000000],\n",
      "        [87768.500000000000000],\n",
      "        [17970.700000000000728],\n",
      "        [ 6311.400000000000546],\n",
      "        [45064.200000000004366],\n",
      "        [67983.100000000005821],\n",
      "        [60371.500000000000000],\n",
      "        [96466.200000000011642],\n",
      "        [25747.400000000001455],\n",
      "        [28464.300000000002910],\n",
      "        [10455.800000000001091],\n",
      "        [90781.400000000008731],\n",
      "        [23995.300000000002910],\n",
      "        [46508.200000000004366],\n",
      "        [ 5340.200000000000728],\n",
      "        [80691.900000000008731],\n",
      "        [50905.500000000000000],\n",
      "        [40699.300000000002910],\n",
      "        [ 5495.400000000000546],\n",
      "        [68297.100000000005821],\n",
      "        [53236.100000000005821],\n",
      "        [62902.000000000000000],\n",
      "        [42901.300000000002910],\n",
      "        [79221.600000000005821],\n",
      "        [11109.700000000000728],\n",
      "        [62360.400000000001455],\n",
      "        [57838.300000000002910],\n",
      "        [68953.500000000000000],\n",
      "        [70476.199999999997090],\n",
      "        [85711.400000000008731],\n",
      "        [27889.100000000002183],\n",
      "        [31272.500000000000000],\n",
      "        [49340.800000000002910],\n",
      "        [55021.700000000004366],\n",
      "        [12571.600000000000364],\n",
      "        [60286.200000000004366],\n",
      "        [57889.900000000001455],\n",
      "        [40718.800000000002910],\n",
      "        [76930.199999999997090],\n",
      "        [66965.500000000000000],\n",
      "        [36141.800000000002910],\n",
      "        [22070.500000000000000],\n",
      "        [51016.100000000005821],\n",
      "        [49685.900000000001455],\n",
      "        [96684.200000000011642],\n",
      "        [28849.900000000001455],\n",
      "        [ 8949.700000000000728],\n",
      "        [77261.600000000005821],\n",
      "        [41592.700000000004366],\n",
      "        [19748.900000000001455],\n",
      "        [19287.100000000002183],\n",
      "        [19119.100000000002183],\n",
      "        [  770.700000000000045],\n",
      "        [46368.200000000004366],\n",
      "        [34325.599999999998545],\n",
      "        [84471.800000000002910],\n",
      "        [40673.100000000005821],\n",
      "        [55928.200000000004366],\n",
      "        [17661.299999999999272],\n",
      "        [  838.000000000000000],\n",
      "        [99966.200000000011642],\n",
      "        [70579.699999999997090],\n",
      "        [ 7048.900000000000546],\n",
      "        [31928.200000000000728],\n",
      "        [40906.800000000002910],\n",
      "        [ 8430.300000000001091],\n",
      "        [50561.300000000002910],\n",
      "        [66363.500000000000000],\n",
      "        [20084.300000000002910],\n",
      "        [18008.900000000001455],\n",
      "        [91824.600000000005821],\n",
      "        [98229.800000000002910],\n",
      "        [99603.900000000008731],\n",
      "        [41180.700000000004366],\n",
      "        [25642.700000000000728],\n",
      "        [58847.000000000000000],\n",
      "        [62113.900000000001455],\n",
      "        [  228.000000000000000],\n",
      "        [ 3074.200000000000273]], grad_fn=<MmBackward>)\n",
      "tensor([[7016.700000000000728],\n",
      "        [1848.700000000000045],\n",
      "        [7175.100000000000364],\n",
      "        [6063.500000000000000],\n",
      "        [5702.500000000000000],\n",
      "        [4544.800000000000182],\n",
      "        [6812.700000000000728],\n",
      "        [ 528.800000000000068],\n",
      "        [2738.900000000000091],\n",
      "        [1030.400000000000091],\n",
      "        [2346.099999999999909],\n",
      "        [ 638.600000000000023],\n",
      "        [7504.500000000000000],\n",
      "        [4644.300000000000182],\n",
      "        [  38.000000000000000],\n",
      "        [3120.300000000000182],\n",
      "        [4747.800000000000182],\n",
      "        [7037.900000000000546],\n",
      "        [4108.500000000000000],\n",
      "        [9629.200000000000728],\n",
      "        [  32.300000000000004],\n",
      "        [7920.200000000000728],\n",
      "        [8776.800000000001091],\n",
      "        [1797.000000000000000],\n",
      "        [ 631.100000000000023],\n",
      "        [4506.400000000000546],\n",
      "        [6798.300000000000182],\n",
      "        [6037.100000000000364],\n",
      "        [9646.600000000000364],\n",
      "        [2574.700000000000273],\n",
      "        [2846.400000000000091],\n",
      "        [1045.500000000000000],\n",
      "        [9078.100000000000364],\n",
      "        [2399.500000000000000],\n",
      "        [4650.800000000000182],\n",
      "        [ 534.000000000000000],\n",
      "        [8069.100000000000364],\n",
      "        [5090.500000000000000],\n",
      "        [4069.900000000000091],\n",
      "        [ 549.500000000000000],\n",
      "        [6829.700000000000728],\n",
      "        [5323.600000000000364],\n",
      "        [6290.200000000000728],\n",
      "        [4290.100000000000364],\n",
      "        [7922.100000000000364],\n",
      "        [1110.900000000000091],\n",
      "        [6236.000000000000000],\n",
      "        [5783.800000000000182],\n",
      "        [6895.300000000000182],\n",
      "        [7047.600000000000364],\n",
      "        [8571.100000000000364],\n",
      "        [2788.900000000000091],\n",
      "        [3127.200000000000273],\n",
      "        [4934.000000000000000],\n",
      "        [5502.100000000000364],\n",
      "        [1257.100000000000136],\n",
      "        [6028.600000000000364],\n",
      "        [5788.900000000000546],\n",
      "        [4071.800000000000182],\n",
      "        [7693.000000000000000],\n",
      "        [6696.500000000000000],\n",
      "        [3614.100000000000364],\n",
      "        [2207.000000000000000],\n",
      "        [5101.600000000000364],\n",
      "        [4968.500000000000000],\n",
      "        [9668.399999999999636],\n",
      "        [2884.900000000000091],\n",
      "        [ 894.900000000000091],\n",
      "        [7726.100000000000364],\n",
      "        [4159.199999999999818],\n",
      "        [1974.800000000000182],\n",
      "        [1928.700000000000045],\n",
      "        [1911.900000000000091],\n",
      "        [  77.000000000000000],\n",
      "        [4636.800000000000182],\n",
      "        [3432.500000000000000],\n",
      "        [8447.100000000000364],\n",
      "        [4067.300000000000182],\n",
      "        [5592.800000000000182],\n",
      "        [1766.100000000000136],\n",
      "        [  83.800000000000011],\n",
      "        [9996.600000000000364],\n",
      "        [7057.900000000000546],\n",
      "        [ 704.800000000000068],\n",
      "        [3192.800000000000182],\n",
      "        [4090.600000000000364],\n",
      "        [ 843.000000000000000],\n",
      "        [5056.100000000000364],\n",
      "        [6636.300000000000182],\n",
      "        [2008.400000000000091],\n",
      "        [1800.800000000000182],\n",
      "        [9182.399999999999636],\n",
      "        [9822.899999999999636],\n",
      "        [9960.300000000001091],\n",
      "        [4118.000000000000000],\n",
      "        [2564.200000000000273],\n",
      "        [5884.700000000000728],\n",
      "        [6211.300000000000182],\n",
      "        [  22.800000000000001],\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        [ 307.400000000000034]], grad_fn=<MmBackward>)\n",
      "tensor([[701.600000000000023],\n",
      "        [184.800000000000011],\n",
      "        [717.500000000000000],\n",
      "        [606.300000000000068],\n",
      "        [570.200000000000045],\n",
      "        [454.400000000000034],\n",
      "        [681.200000000000045],\n",
      "        [ 52.800000000000004],\n",
      "        [273.800000000000011],\n",
      "        [103.000000000000000],\n",
      "        [234.600000000000023],\n",
      "        [ 63.800000000000004],\n",
      "        [750.400000000000091],\n",
      "        [464.400000000000034],\n",
      "        [  3.800000000000000],\n",
      "        [312.000000000000000],\n",
      "        [474.700000000000045],\n",
      "        [703.700000000000045],\n",
      "        [410.800000000000011],\n",
      "        [962.900000000000091],\n",
      "        [  3.200000000000000],\n",
      "        [792.000000000000000],\n",
      "        [877.600000000000023],\n",
      "        [179.700000000000017],\n",
      "        [ 63.100000000000001],\n",
      "        [450.600000000000023],\n",
      "        [679.800000000000068],\n",
      "        [603.700000000000045],\n",
      "        [964.600000000000023],\n",
      "        [257.400000000000034],\n",
      "        [284.600000000000023],\n",
      "        [104.500000000000000],\n",
      "        [907.800000000000068],\n",
      "        [239.900000000000006],\n",
      "        [465.000000000000000],\n",
      "        [ 53.400000000000006],\n",
      "        [806.900000000000091],\n",
      "        [509.000000000000000],\n",
      "        [406.900000000000034],\n",
      "        [ 54.900000000000006],\n",
      "        [682.900000000000091],\n",
      "        [532.300000000000068],\n",
      "        [629.000000000000000],\n",
      "        [429.000000000000000],\n",
      "        [792.200000000000045],\n",
      "        [111.000000000000000],\n",
      "        [623.600000000000023],\n",
      "        [578.300000000000068],\n",
      "        [689.500000000000000],\n",
      "        [704.700000000000045],\n",
      "        [857.100000000000023],\n",
      "        [278.800000000000011],\n",
      "        [312.700000000000045],\n",
      "        [493.400000000000034],\n",
      "        [550.200000000000045],\n",
      "        [125.700000000000003],\n",
      "        [602.800000000000068],\n",
      "        [578.800000000000068],\n",
      "        [407.100000000000023],\n",
      "        [769.300000000000068],\n",
      "        [669.600000000000023],\n",
      "        [361.400000000000034],\n",
      "        [220.700000000000017],\n",
      "        [510.100000000000023],\n",
      "        [496.800000000000011],\n",
      "        [966.800000000000068],\n",
      "        [288.400000000000034],\n",
      "        [ 89.400000000000006],\n",
      "        [772.600000000000023],\n",
      "        [415.900000000000034],\n",
      "        [197.400000000000006],\n",
      "        [192.800000000000011],\n",
      "        [191.100000000000023],\n",
      "        [  7.700000000000000],\n",
      "        [463.600000000000023],\n",
      "        [343.200000000000045],\n",
      "        [844.700000000000045],\n",
      "        [406.700000000000045],\n",
      "        [559.200000000000045],\n",
      "        [176.600000000000023],\n",
      "        [  8.300000000000001],\n",
      "        [999.600000000000023],\n",
      "        [705.700000000000045],\n",
      "        [ 70.400000000000006],\n",
      "        [319.200000000000045],\n",
      "        [409.000000000000000],\n",
      "        [ 84.300000000000011],\n",
      "        [505.600000000000023],\n",
      "        [663.600000000000023],\n",
      "        [200.800000000000011],\n",
      "        [180.000000000000000],\n",
      "        [918.200000000000045],\n",
      "        [982.200000000000045],\n",
      "        [996.000000000000000],\n",
      "        [411.800000000000011],\n",
      "        [256.400000000000034],\n",
      "        [588.399999999999977],\n",
      "        [621.100000000000023],\n",
      "        [  2.200000000000000],\n",
      "        [ 30.700000000000003]], grad_fn=<MmBackward>)\n",
      "tensor([[70.100000000000009],\n",
      "        [18.400000000000002],\n",
      "        [71.700000000000003],\n",
      "        [60.600000000000001],\n",
      "        [57.000000000000000],\n",
      "        [45.400000000000006],\n",
      "        [68.100000000000009],\n",
      "        [ 5.200000000000000],\n",
      "        [27.300000000000001],\n",
      "        [10.300000000000001],\n",
      "        [23.400000000000002],\n",
      "        [ 6.300000000000001],\n",
      "        [75.000000000000000],\n",
      "        [46.400000000000006],\n",
      "        [ 0.300000000000000],\n",
      "        [31.200000000000003],\n",
      "        [47.400000000000006],\n",
      "        [70.299999999999997],\n",
      "        [41.000000000000000],\n",
      "        [96.200000000000003],\n",
      "        [ 0.300000000000000],\n",
      "        [79.200000000000003],\n",
      "        [87.700000000000003],\n",
      "        [17.900000000000002],\n",
      "        [ 6.300000000000001],\n",
      "        [45.000000000000000],\n",
      "        [67.900000000000006],\n",
      "        [60.300000000000004],\n",
      "        [96.400000000000006],\n",
      "        [25.700000000000003],\n",
      "        [28.400000000000002],\n",
      "        [10.400000000000000],\n",
      "        [90.700000000000003],\n",
      "        [23.900000000000002],\n",
      "        [46.500000000000000],\n",
      "        [ 5.300000000000001],\n",
      "        [80.600000000000009],\n",
      "        [50.900000000000006],\n",
      "        [40.600000000000001],\n",
      "        [ 5.400000000000000],\n",
      "        [68.200000000000003],\n",
      "        [53.200000000000003],\n",
      "        [62.900000000000006],\n",
      "        [42.900000000000006],\n",
      "        [79.200000000000003],\n",
      "        [11.100000000000001],\n",
      "        [62.300000000000004],\n",
      "        [57.800000000000004],\n",
      "        [68.900000000000006],\n",
      "        [70.400000000000006],\n",
      "        [85.700000000000003],\n",
      "        [27.800000000000001],\n",
      "        [31.200000000000003],\n",
      "        [49.300000000000004],\n",
      "        [55.000000000000000],\n",
      "        [12.500000000000000],\n",
      "        [60.200000000000003],\n",
      "        [57.800000000000004],\n",
      "        [40.700000000000003],\n",
      "        [76.900000000000006],\n",
      "        [66.900000000000006],\n",
      "        [36.100000000000001],\n",
      "        [22.000000000000000],\n",
      "        [51.000000000000000],\n",
      "        [49.600000000000001],\n",
      "        [96.600000000000009],\n",
      "        [28.800000000000001],\n",
      "        [ 8.900000000000000],\n",
      "        [77.200000000000003],\n",
      "        [41.500000000000000],\n",
      "        [19.700000000000003],\n",
      "        [19.200000000000003],\n",
      "        [19.100000000000001],\n",
      "        [ 0.700000000000000],\n",
      "        [46.300000000000004],\n",
      "        [34.300000000000004],\n",
      "        [84.400000000000006],\n",
      "        [40.600000000000001],\n",
      "        [55.900000000000006],\n",
      "        [17.600000000000001],\n",
      "        [ 0.800000000000000],\n",
      "        [99.900000000000006],\n",
      "        [70.500000000000000],\n",
      "        [ 7.000000000000000],\n",
      "        [31.900000000000002],\n",
      "        [40.900000000000006],\n",
      "        [ 8.400000000000000],\n",
      "        [50.500000000000000],\n",
      "        [66.299999999999997],\n",
      "        [20.000000000000000],\n",
      "        [18.000000000000000],\n",
      "        [91.800000000000011],\n",
      "        [98.200000000000003],\n",
      "        [99.600000000000009],\n",
      "        [41.100000000000001],\n",
      "        [25.600000000000001],\n",
      "        [58.800000000000004],\n",
      "        [62.100000000000001],\n",
      "        [ 0.200000000000000],\n",
      "        [ 3.000000000000000]], grad_fn=<MmBackward>)\n",
      "tensor([[7.000000000000000],\n",
      "        [1.800000000000000],\n",
      "        [7.100000000000001],\n",
      "        [6.000000000000000],\n",
      "        [5.700000000000000],\n",
      "        [4.500000000000000],\n",
      "        [6.800000000000001],\n",
      "        [0.500000000000000],\n",
      "        [2.700000000000000],\n",
      "        [1.000000000000000],\n",
      "        [2.300000000000000],\n",
      "        [0.600000000000000],\n",
      "        [7.500000000000000],\n",
      "        [4.600000000000001],\n",
      "        [0.000000000000000],\n",
      "        [3.100000000000000],\n",
      "        [4.700000000000000],\n",
      "        [7.000000000000000],\n",
      "        [4.100000000000001],\n",
      "        [9.600000000000001],\n",
      "        [0.000000000000000],\n",
      "        [7.900000000000000],\n",
      "        [8.700000000000001],\n",
      "        [1.700000000000000],\n",
      "        [0.600000000000000],\n",
      "        [4.500000000000000],\n",
      "        [6.700000000000000],\n",
      "        [6.000000000000000],\n",
      "        [9.600000000000001],\n",
      "        [2.500000000000000],\n",
      "        [2.800000000000000],\n",
      "        [1.000000000000000],\n",
      "        [9.000000000000000],\n",
      "        [2.300000000000000],\n",
      "        [4.600000000000001],\n",
      "        [0.500000000000000],\n",
      "        [8.000000000000000],\n",
      "        [5.000000000000000],\n",
      "        [4.000000000000000],\n",
      "        [0.500000000000000],\n",
      "        [6.800000000000001],\n",
      "        [5.300000000000001],\n",
      "        [6.200000000000000],\n",
      "        [4.200000000000000],\n",
      "        [7.900000000000000],\n",
      "        [1.100000000000000],\n",
      "        [6.200000000000000],\n",
      "        [5.700000000000000],\n",
      "        [6.800000000000001],\n",
      "        [7.000000000000000],\n",
      "        [8.500000000000000],\n",
      "        [2.700000000000000],\n",
      "        [3.100000000000000],\n",
      "        [4.900000000000000],\n",
      "        [5.500000000000000],\n",
      "        [1.200000000000000],\n",
      "        [6.000000000000000],\n",
      "        [5.700000000000000],\n",
      "        [4.000000000000000],\n",
      "        [7.600000000000001],\n",
      "        [6.600000000000001],\n",
      "        [3.600000000000000],\n",
      "        [2.200000000000000],\n",
      "        [5.100000000000001],\n",
      "        [4.900000000000000],\n",
      "        [9.600000000000001],\n",
      "        [2.800000000000000],\n",
      "        [0.800000000000000],\n",
      "        [7.700000000000000],\n",
      "        [4.100000000000001],\n",
      "        [1.900000000000000],\n",
      "        [1.900000000000000],\n",
      "        [1.900000000000000],\n",
      "        [0.000000000000000],\n",
      "        [4.600000000000001],\n",
      "        [3.400000000000000],\n",
      "        [8.400000000000000],\n",
      "        [4.000000000000000],\n",
      "        [5.500000000000000],\n",
      "        [1.700000000000000],\n",
      "        [0.000000000000000],\n",
      "        [9.900000000000000],\n",
      "        [7.000000000000000],\n",
      "        [0.700000000000000],\n",
      "        [3.100000000000000],\n",
      "        [4.000000000000000],\n",
      "        [0.800000000000000],\n",
      "        [5.000000000000000],\n",
      "        [6.600000000000001],\n",
      "        [2.000000000000000],\n",
      "        [1.800000000000000],\n",
      "        [9.100000000000000],\n",
      "        [9.800000000000001],\n",
      "        [9.900000000000000],\n",
      "        [4.100000000000001],\n",
      "        [2.500000000000000],\n",
      "        [5.800000000000001],\n",
      "        [6.200000000000000],\n",
      "        [0.000000000000000],\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        [0.300000000000000]], grad_fn=<MmBackward>)\n",
      "tensor([[0.700000000000000],\n",
      "        [0.100000000000000],\n",
      "        [0.700000000000000],\n",
      "        [0.600000000000000],\n",
      "        [0.500000000000000],\n",
      "        [0.400000000000000],\n",
      "        [0.600000000000000],\n",
      "        [0.000000000000000],\n",
      "        [0.200000000000000],\n",
      "        [0.100000000000000],\n",
      "        [0.200000000000000],\n",
      "        [0.000000000000000],\n",
      "        [0.700000000000000],\n",
      "        [0.400000000000000],\n",
      "        [0.000000000000000],\n",
      "        [0.300000000000000],\n",
      "        [0.400000000000000],\n",
      "        [0.700000000000000],\n",
      "        [0.400000000000000],\n",
      "        [0.900000000000000],\n",
      "        [0.000000000000000],\n",
      "        [0.700000000000000],\n",
      "        [0.800000000000000],\n",
      "        [0.100000000000000],\n",
      "        [0.000000000000000],\n",
      "        [0.400000000000000],\n",
      "        [0.600000000000000],\n",
      "        [0.600000000000000],\n",
      "        [0.900000000000000],\n",
      "        [0.200000000000000],\n",
      "        [0.200000000000000],\n",
      "        [0.100000000000000],\n",
      "        [0.900000000000000],\n",
      "        [0.200000000000000],\n",
      "        [0.400000000000000],\n",
      "        [0.000000000000000],\n",
      "        [0.800000000000000],\n",
      "        [0.500000000000000],\n",
      "        [0.400000000000000],\n",
      "        [0.000000000000000],\n",
      "        [0.600000000000000],\n",
      "        [0.500000000000000],\n",
      "        [0.600000000000000],\n",
      "        [0.400000000000000],\n",
      "        [0.700000000000000],\n",
      "        [0.100000000000000],\n",
      "        [0.600000000000000],\n",
      "        [0.500000000000000],\n",
      "        [0.600000000000000],\n",
      "        [0.700000000000000],\n",
      "        [0.800000000000000],\n",
      "        [0.200000000000000],\n",
      "        [0.300000000000000],\n",
      "        [0.400000000000000],\n",
      "        [0.500000000000000],\n",
      "        [0.100000000000000],\n",
      "        [0.600000000000000],\n",
      "        [0.500000000000000],\n",
      "        [0.400000000000000],\n",
      "        [0.700000000000000],\n",
      "        [0.600000000000000],\n",
      "        [0.300000000000000],\n",
      "        [0.200000000000000],\n",
      "        [0.500000000000000],\n",
      "        [0.400000000000000],\n",
      "        [0.900000000000000],\n",
      "        [0.200000000000000],\n",
      "        [0.000000000000000],\n",
      "        [0.700000000000000],\n",
      "        [0.400000000000000],\n",
      "        [0.100000000000000],\n",
      "        [0.100000000000000],\n",
      "        [0.100000000000000],\n",
      "        [0.000000000000000],\n",
      "        [0.400000000000000],\n",
      "        [0.300000000000000],\n",
      "        [0.800000000000000],\n",
      "        [0.400000000000000],\n",
      "        [0.500000000000000],\n",
      "        [0.100000000000000],\n",
      "        [0.000000000000000],\n",
      "        [0.900000000000000],\n",
      "        [0.700000000000000],\n",
      "        [0.000000000000000],\n",
      "        [0.300000000000000],\n",
      "        [0.400000000000000],\n",
      "        [0.000000000000000],\n",
      "        [0.500000000000000],\n",
      "        [0.600000000000000],\n",
      "        [0.200000000000000],\n",
      "        [0.100000000000000],\n",
      "        [0.900000000000000],\n",
      "        [0.900000000000000],\n",
      "        [0.900000000000000],\n",
      "        [0.400000000000000],\n",
      "        [0.200000000000000],\n",
      "        [0.500000000000000],\n",
      "        [0.600000000000000],\n",
      "        [0.000000000000000],\n",
      "        [0.000000000000000]], grad_fn=<MmBackward>)\n",
      "tensor([[0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.]], grad_fn=<MmBackward>)\n",
      "tensor([[0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.]], grad_fn=<MmBackward>)\n",
      "tensor([[0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.]], grad_fn=<MmBackward>)\n",
      "tensor([[0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        [0.]], grad_fn=<MmBackward>)\n",
      "tensor([[0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.]], grad_fn=<MmBackward>)\n",
      "tensor([[0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.]], grad_fn=<MmBackward>)\n",
      "tensor([[0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.]], grad_fn=<MmBackward>)\n",
      "tensor([[0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.]], grad_fn=<MmBackward>)\n",
      "tensor([[0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.]], grad_fn=<MmBackward>)\n",
      "tensor([[0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        [0.]], grad_fn=<MmBackward>)\n",
      "100\n"
     ]
    }
   ],
   "source": [
    "torch.set_printoptions(precision=15)\n",
    "out = net.predict(train_data)\n",
    "temp = train_labels.numpy()\n",
    "out = out.detach().numpy()\n",
    "correct = 0\n",
    "for i in range(out.shape[0]):\n",
    "    if out[i] == temp[i]:\n",
    "        correct+=1\n",
    "    else:\n",
    "        print('wrong example :',i)\n",
    "        print(train_data[i])\n",
    "        print(temp[i])\n",
    "        print(out[i])\n",
    "print(correct)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ammar\\.conda\\envs\\neuralnets\\lib\\site-packages\\torch\\serialization.py:256: UserWarning: Couldn't retrieve source code for container of type Net_mul_sign_abs. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
      "C:\\Users\\Ammar\\.conda\\envs\\neuralnets\\lib\\site-packages\\torch\\serialization.py:256: UserWarning: Couldn't retrieve source code for container of type Net_separate. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
      "C:\\Users\\Ammar\\.conda\\envs\\neuralnets\\lib\\site-packages\\torch\\serialization.py:256: UserWarning: Couldn't retrieve source code for container of type Net_sub. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
      "C:\\Users\\Ammar\\.conda\\envs\\neuralnets\\lib\\site-packages\\torch\\serialization.py:256: UserWarning: Couldn't retrieve source code for container of type Net_mul_sign_0_9. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n"
     ]
    }
   ],
   "source": [
    "torch.save(net,'model_mul_sign_abs')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net,self).__init__()\n",
    "        self.fc1 = nn.Linear(1,1,bias=False)\n",
    "        self.fc1.weight.data = torch.tensor([[0.1]]).type(torch.float64)\n",
    "    \n",
    "    def forward(self,x):\n",
    "        x = self.fc1(x)\n",
    "        return x\n",
    "    \n",
    "model = Net().type(torch.float64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[9939754.400000000372529]], grad_fn=<MmBackward>)\n"
     ]
    }
   ],
   "source": [
    "input_data = np.array([[99397544]])\n",
    "input_data = torch.from_numpy(input_data).type(torch.float64)\n",
    "print(model.forward(input_data))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
