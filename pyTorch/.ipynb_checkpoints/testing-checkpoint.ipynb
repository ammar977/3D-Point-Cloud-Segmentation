{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.set_printoptions(precision = 10)\n",
    "torch.set_default_dtype(torch.float64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This model adds two numbers\n",
    "class Net_add(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net_add,self).__init__()\n",
    "        self.fc1 = nn.Linear(2,1,bias=False)\n",
    "        self.fc1.weight.data = torch.tensor([[1.0,1.0]]).type(torch.float64)\n",
    "    \n",
    "    def forward(self,x):\n",
    "        x = self.fc1(x)\n",
    "        return x\n",
    "    \n",
    "    def predict(self,x):\n",
    "        return self.forward(x).type(torch.float64)\n",
    "\n",
    "# model_add = torch.load('model_add').double()\n",
    "model_add = Net_add().type(torch.float64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This model subtracts two numbers\n",
    "class Net_sub(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net_sub,self).__init__()\n",
    "        self.fc1 = nn.Linear(2,1,bias=False)\n",
    "        self.fc1.weight.data = torch.tensor([[1,-1]]).type(torch.float64)\n",
    "    \n",
    "    def forward(self,x):\n",
    "        x = self.fc1(x)\n",
    "        return x\n",
    "    \n",
    "    def predict(self,x):\n",
    "        return self.forward(x).type(torch.float64)\n",
    "    \n",
    "# model_sub = torch.load('model_sub').double()\n",
    "# model_sub = torch.load('model_sub').type(torch.float64)\n",
    "model_sub = Net_sub().type(torch.float64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net,self).__init__()\n",
    "        self.fc1 = nn.Linear(2,30)\n",
    "        self.fc2 = nn.Linear(30,82)\n",
    "    \n",
    "    def forward(self,x):\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.softmax(self.fc2(x))\n",
    "        return x\n",
    "    \n",
    "    def predict(self,x):\n",
    "        pred = self.forward(x)\n",
    "        _,out = torch.max(pred,1)\n",
    "        return out.type(torch.float64)\n",
    "\n",
    "model_mul_0_9 = torch.load('mul_0_9').type(torch.float64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This model will give the absolute of a number\n",
    "# input: 1 number\n",
    "# output: absolute of that number \n",
    "\n",
    "class Net_abs(nn.Module):\n",
    "    def __init__(self,model_add,model_sub):\n",
    "        super(Net_abs,self).__init__()\n",
    "        \n",
    "        self.model_add = model_add\n",
    "        self.model_sub = model_sub\n",
    "        self.maxpool1d = nn.MaxPool1d(2)\n",
    "\n",
    "    \n",
    "    def forward(self,x):\n",
    "        concat = torch.cat((x,x),1)\n",
    "        add = self.model_add.predict(concat)\n",
    "        sub = self.model_sub.predict(concat)\n",
    "        \n",
    "        concat = torch.cat((add,sub),1).unsqueeze(0)\n",
    "        out = self.maxpool1d(concat).squeeze(0)\n",
    "        \n",
    "        concat = torch.cat((out,x),1)\n",
    "        out = model_sub.predict(concat)\n",
    "        \n",
    "        return out\n",
    "    \n",
    "    def predict(self,x):\n",
    "        return self.forward(x).type(torch.float64)\n",
    "    \n",
    "# model_abs = torch.load('model_abs').type(torch.float64)\n",
    "model_abs = Net_abs(model_add,model_sub).type(torch.float64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This model will separate a number into digits\n",
    "# input: 2 inputs - (number,num_digits)\n",
    "# output: separated digits (num_digits,)  \n",
    "\n",
    "class Net_separate(nn.Module):\n",
    "    def __init__(self,model_sub):\n",
    "        super(Net_separate,self).__init__()\n",
    "        \n",
    "        self.divide_by_10 = nn.Linear(1,1,bias=False).type(torch.float64)\n",
    "        self.divide_by_10.weight.data = torch.tensor([[0.1]]).type(torch.float64)\n",
    "\n",
    "        self.multiply_by_10 = nn.Linear(1,1,bias=False)\n",
    "        self.multiply_by_10.weight.data = torch.tensor([[10]]).type(torch.float64)\n",
    "        \n",
    "        self.model_sub = model_sub\n",
    "    \n",
    "    def forward(self,x):\n",
    "        input_number = x[:,0].unsqueeze(-1)\n",
    "        num_digits = x[:,1].unsqueeze(-1)\n",
    "        concat = []\n",
    "        data = input_number\n",
    "        for i in range(num_digits[0].type(torch.IntTensor)):\n",
    "            temp_data = self.divide_by_10(data)\n",
    "            temp_data = temp_data.floor()\n",
    "            temp = self.multiply_by_10(temp_data)\n",
    "            concat_temp = torch.cat((data,temp),1)\n",
    "            digit = self.model_sub.predict(concat_temp)\n",
    "            \n",
    "            concat.insert(0,digit)\n",
    "            data = temp_data\n",
    "        \n",
    "        out = torch.cat(concat,1)\n",
    "        return out\n",
    "    \n",
    "    def predict(self,x):\n",
    "        return self.forward(x).type(torch.float64)\n",
    "    \n",
    "# model_separate = torch.load('model_separate').double()  \n",
    "# model_separate = torch.load('model_separate').type(torch.float64)\n",
    "model_separate = Net_separate(model_sub).type(torch.float64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This model will give the product of two absolute numbers\n",
    "# input: 2 separated numbers : (2,num_digits)\n",
    "# output: product \n",
    "\n",
    "class Net_multiply_abs(nn.Module):\n",
    "    def __init__(self,model_mul_0_9,model_add,model_separate):\n",
    "        super(Net_multiply_abs,self).__init__()\n",
    "        \n",
    "        self.model_add = model_add\n",
    "        self.model_separate = model_separate\n",
    "        self.model_mul_0_9 = model_mul_0_9\n",
    "        \n",
    "        self.final_row_add_layers = []\n",
    "    \n",
    "    def forward(self,x):\n",
    "        n = x.shape[-1]\n",
    "        m = x.shape[-1]\n",
    "        \n",
    "        # get initial products\n",
    "        products = []\n",
    "        for i in range(x.shape[-1]):\n",
    "            mul = x[:,0,i:i+1]\n",
    "            for j in range(x.shape[-1]):\n",
    "                temp = x[:,1,j:j+1]\n",
    "                concat = torch.cat((temp,mul),1)\n",
    "                prod = self.model_mul_0_9.predict(concat)\n",
    "                products.insert(0,prod)\n",
    "                \n",
    "        # get individual rows\n",
    "        row_values = []\n",
    "        prod_index = 0\n",
    "        two = torch.from_numpy(np.repeat(np.array([2.0],ndmin = 2),x.shape[0],axis = 0)).type(torch.float64)\n",
    "        for r in range(n):\n",
    "            for i in range(m+1):\n",
    "                if i==0:\n",
    "                    temp = torch.cat((products[prod_index].unsqueeze(-1),two),1)\n",
    "                    sep = self.model_separate.predict(temp)\n",
    "                    carry = sep[:,0:1]\n",
    "                    ones_digit = sep[:,1:]\n",
    "                    row_values.append(ones_digit)\n",
    "                    prod_index+=1\n",
    "                    \n",
    "                elif i==m:\n",
    "                    row_values.append(carry)\n",
    "                else:\n",
    "                    concat = torch.cat((products[prod_index].unsqueeze(-1),carry),1)\n",
    "                    add = self.model_add(concat)\n",
    "                    concat = torch.cat((add,two),1)\n",
    "                    sep = self.model_separate.predict(concat)\n",
    "                    carry = sep[:,0:1]\n",
    "                    ones_digit = sep[:,1:]\n",
    "                    row_values.append(ones_digit)\n",
    "                    prod_index+=1\n",
    "        \n",
    "        final_row = []\n",
    "        current_ind = 0 \n",
    "        for i in range(m+n):\n",
    "            if i ==0:\n",
    "                final_row.insert(0,row_values[0])\n",
    "                temp = torch.cat((row_values[0],two),1)\n",
    "                sep = self.model_separate.predict(temp)\n",
    "                carry = sep[:,0:1]\n",
    "                current_ind+=1\n",
    "            else:\n",
    "                to_add = []\n",
    "                ones = []\n",
    "                to_add.append(row_values[current_ind])\n",
    "                ones.append(1)\n",
    "                to_add.append(carry)\n",
    "                ones.append(1)\n",
    "                \n",
    "                next_ind = current_ind + m\n",
    "                while(next_ind < n*(m+1) and next_ind%(m+1)!=0):\n",
    "                    to_add.append(row_values[next_ind])\n",
    "                    ones.append(1)\n",
    "                    next_ind+=m\n",
    "                if(next_ind < n * (m+1) and next_ind%(m+1)==0):\n",
    "                    to_add.append(row_values[next_ind])\n",
    "                    ones.append(1)\n",
    "\n",
    "                self.final_row_add_layers.append(nn.Linear(len(to_add),1,bias=False))\n",
    "                self.final_row_add_layers[-1].weight.data = torch.tensor([ones]).type(torch.float64)\n",
    "                concat = torch.cat(to_add,-1)\n",
    "                add = self.final_row_add_layers[-1](concat)\n",
    "                \n",
    "                temp = torch.cat((add,two),1)\n",
    "                sep = self.model_separate.predict(temp)\n",
    "                carry = sep[:,0:1]\n",
    "                ones_digit = sep[:,1:]\n",
    "                final_row.insert(0,ones_digit)\n",
    "                \n",
    "                if (current_ind + 1) % (m+1) !=0:\n",
    "                    current_ind+=1\n",
    "                else:\n",
    "                    current_ind+=m+1\n",
    "                \n",
    "                \n",
    "        out = torch.cat(final_row,-1)\n",
    "        return out\n",
    "    \n",
    "    def predict(self,x):\n",
    "        return self.forward(x).type(torch.float64)\n",
    "    \n",
    "# model_multiply_abs = torch.load('model_multiply_abs').double()\n",
    "model_multiply_abs = Net_multiply_abs(model_mul_0_9,model_add,model_separate).type(torch.float64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This model will join a list of digits to a number\n",
    "# input: 1 input - (num_digits,)\n",
    "# output: 1   \n",
    "\n",
    "class Net_merge(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net_merge,self).__init__()\n",
    "        self.layers = []\n",
    "        \n",
    "    def forward(self,x):\n",
    "        n = x.shape[-1]\n",
    "        i = 0 \n",
    "        add_list = []\n",
    "        ones = []\n",
    "        while(n>=1):\n",
    "            temp = x[:,n-1:n]\n",
    "            self.layers.append(nn.Linear(1,1,bias=False))\n",
    "            self.layers[-1].weight.data = torch.tensor([[10**i]]).type(torch.float64)\n",
    "            out = self.layers[-1](temp)\n",
    "            i +=1\n",
    "            n-=1\n",
    "            add_list.append(out)\n",
    "            ones.append(1.0)\n",
    "        \n",
    "        self.layers.append(nn.Linear(x.shape[-1],1,bias=False))\n",
    "        self.layers[-1].weight.data = torch.tensor([ones]).type(torch.float64)\n",
    "        concat = torch.cat(add_list,-1)\n",
    "        out = self.layers[-1](concat)\n",
    "        return out\n",
    "    \n",
    "    def predict(self,x):\n",
    "        return self.forward(x).type(torch.float64)\n",
    "\n",
    "# model_merge = torch.load('model_merge').double()\n",
    "model_merge = Net_merge().type(torch.float64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this model mulltiplies a single digit number with a sign (1,-1)\n",
    "# input: 2 numbers (2,)\n",
    "# output: single number \n",
    "class Net_mul_sign_0_9(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net_mul_sign_0_9,self).__init__()\n",
    "        self.fc1 = nn.Linear(2,10)\n",
    "        self.fc2 = nn.Linear(10,1)\n",
    "    \n",
    "    def forward(self,x):\n",
    "        x = F.softsign(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "    \n",
    "    def predict(self,x):\n",
    "        out = self.forward(x)\n",
    "        return torch.round(out).type(torch.float64)\n",
    "\n",
    "model_mul_sign_0_9 = torch.load('model_mul_sign_0_9').type(torch.float64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this model mulltiplies a number with a sign (1,-1)\n",
    "# input: 3 numbers (3,) - [number,sign,num_digits]\n",
    "# output: single number \n",
    "class Net_mul_sign_abs(nn.Module):\n",
    "    def __init__(self,model_separate,model_mul_sign_0_9):\n",
    "        super(Net_mul_sign_abs,self).__init__()\n",
    "        self.model_separate = model_separate\n",
    "        self.model_mul_sign_0_9 = model_mul_sign_0_9\n",
    "        self.multiply_2 = nn.Linear(1,1,bias = False)\n",
    "        self.multiply_2.weight.data = torch.tensor([[2.0]]).type(torch.float64)\n",
    "        self.layers = []\n",
    "    \n",
    "    def forward(self,x):\n",
    "        number = x[:,0].unsqueeze(-1)\n",
    "        sign = x[:,1].unsqueeze(-1)\n",
    "        num_digits = x[:,2].unsqueeze(-1)\n",
    "        \n",
    "        output_digits = self.multiply_2(num_digits)\n",
    "        concat = torch.cat((number,output_digits),1)\n",
    "        sep = self.model_separate.predict(concat)\n",
    "        products = []\n",
    "        i = 0\n",
    "        j = sep.shape[-1]\n",
    "        for n in range(j,0,-1):\n",
    "            temp = sep[:,n-1:n]\n",
    "            concat = torch.cat((temp,sign),1)\n",
    "            prod = self.model_mul_sign_0_9.predict(concat)\n",
    "            self.layers.append(nn.Linear(1,1,bias=False))\n",
    "            self.layers[-1].weight.data = torch.tensor([[10**i]]).type(torch.float64)\n",
    "            prod = self.layers[-1](prod)\n",
    "            products.append(prod)\n",
    "            i+=1\n",
    "        \n",
    "        concat = torch.cat(products,1)\n",
    "        self.layers.append(nn.Linear(1,1,bias=False))\n",
    "        self.layers[-1].weight.data = np.repeat(torch.tensor([[1.0]]),len(products),axis = -1).type(torch.float64)\n",
    "        out = self.layers[-1](concat)\n",
    "        return out\n",
    "    \n",
    "    def predict(self,x):\n",
    "        out = self.forward(x)\n",
    "        return out.type(torch.float64)\n",
    "    \n",
    "model_mul_sign_abs = Net_mul_sign_abs(model_separate,model_mul_sign_0_9).type(torch.float64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net_separate_sign(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net_separate_sign,self).__init__()\n",
    "        self.fc1 = nn.Linear(1,1,bias=False)\n",
    "        self.fc1.weight.data = torch.tensor([[1.01]]).type(torch.float64)\n",
    "        \n",
    "    def forward(self,x):\n",
    "        out = F.softsign(self.fc1(x))\n",
    "        return out\n",
    "    \n",
    "    def predict(self,x):\n",
    "        return self.forward(x).round().type(torch.float64)\n",
    "\n",
    "model_separate_sign = Net_separate_sign().type(torch.float64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net_mul_signs(nn.Module):\n",
    "    def __init__(self,model_add,model_sub,model_abs):\n",
    "        super(Net_mul_signs,self).__init__()\n",
    "        self.model_add = model_add\n",
    "        self.model_abs = model_abs\n",
    "        self.model_sub = model_sub\n",
    "        \n",
    "    def forward(self,x):\n",
    "        out = self.model_add.predict(x)\n",
    "        out = self.model_abs.predict(out)\n",
    "        \n",
    "        ones = torch.ones(out.shape).type(torch.float64)\n",
    "        out = torch.cat((out,ones),1)\n",
    "        out = self.model_sub.predict(out)\n",
    "        \n",
    "    \n",
    "        return out\n",
    "    \n",
    "    def predict(self,x):\n",
    "        return self.forward(x).type(torch.float64)\n",
    "\n",
    "model_mul_signs = Net_mul_signs(model_add,model_sub,model_abs).type(torch.float64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this model mulltiplies two numbers\n",
    "# input: 3 numbers (3,) - [number,number,num_digits]\n",
    "# output: single number \n",
    "class Net_multiply(nn.Module):\n",
    "    def __init__(self,model_separate_sign,model_mul_signs,model_abs,model_separate,model_multiply_abs,model_merge,model_mul_sign_abs):\n",
    "        super(Net_multiply,self).__init__()\n",
    "        self.model_separate_sign = model_separate_sign\n",
    "        self.model_mul_signs = model_mul_signs\n",
    "        self.model_abs = model_abs\n",
    "        self.model_separate = model_separate\n",
    "        self.model_multiply_abs = model_multiply_abs\n",
    "        self.model_merge = model_merge\n",
    "        self.model_mul_sign_abs = model_mul_sign_abs\n",
    "    \n",
    "    def forward(self,x):\n",
    "        numbers = x[:,:2]\n",
    "        num_digits = x[:,2:]\n",
    "        \n",
    "        # get sign\n",
    "        sign1 = self.model_separate_sign.predict(x[:,0:1])\n",
    "        sign2 = self.model_separate_sign.predict(x[:,1:2])\n",
    "        concat = torch.cat((sign1,sign2),1)\n",
    "        sign = self.model_mul_signs.predict(concat)\n",
    "        \n",
    "        # get absolutes\n",
    "        abs_inp1 = self.model_abs.predict(x[:,0:1])\n",
    "        abs_inp2 = self.model_abs.predict(x[:,1:2])\n",
    "        \n",
    "        # separate absolutes\n",
    "        concat = torch.cat((abs_inp1,num_digits),1)\n",
    "        sep_1 = self.model_separate.predict(concat).unsqueeze(1)\n",
    "        concat = torch.cat((abs_inp2,num_digits),1)\n",
    "        sep_2 = self.model_separate.predict(concat).unsqueeze(1)\n",
    "        \n",
    "        # multiply absolutes\n",
    "        concat = torch.cat((sep_1,sep_2),1)\n",
    "        abs_prod = self.model_multiply_abs(concat)\n",
    "        \n",
    "        # merge absolute product\n",
    "        merged_abs_prod = self.model_merge(abs_prod)\n",
    "        # multiply sign and absolute product\n",
    "        concat = torch.cat((merged_abs_prod,sign,num_digits),1)\n",
    "        out = self.model_mul_sign_abs.predict(concat)\n",
    "        \n",
    "        return out\n",
    "    \n",
    "    def predict(self,x):\n",
    "        out = self.forward(x)\n",
    "        return out.type(torch.float64)\n",
    "    \n",
    "model_multiply = Net_multiply(model_separate_sign,model_mul_signs,model_abs,model_separate,model_multiply_abs,model_merge,model_mul_sign_abs).type(torch.float64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this model mulltiplies two numbers\n",
    "# input: 4 numbers (3,) - [divisor,divididend,length of divisor,len of dividend]\n",
    "# output: single number \n",
    "class Net_divide(nn.Module):\n",
    "    def __init__(self,model_multiply,model_separate,model_sub,model_merge,model_add,model_separate_sign,model_mul_signs,model_abs,model_mul_sign_abs):\n",
    "        super(Net_divide,self).__init__()\n",
    "        self.model_multiply = model_multiply\n",
    "        self.model_separate = model_separate\n",
    "        self.model_sub = model_sub\n",
    "        self.model_merge = model_merge\n",
    "        self.model_add = model_add\n",
    "        self.model_separate_sign = model_separate_sign\n",
    "        self.model_mul_signs = model_mul_signs\n",
    "        self.model_abs = model_abs\n",
    "        self.model_mul_sign_abs = model_mul_sign_abs\n",
    "        \n",
    "        self.maxpool1d = nn.MaxPool1d(2)\n",
    "        self.fc1 = nn.Linear(1,1,bias=False)\n",
    "        self.fc1.weight.data = torch.tensor([[-1.0]]).type(torch.float64)\n",
    "        self.maxpool1d_2 = nn.MaxPool1d(10)\n",
    "        self.fc2 = nn.Linear(1,1,bias=False)\n",
    "        self.fc2.weight.data =  torch.tensor([[10]]).type(torch.float64)\n",
    "    \n",
    "    def forward(self,x):\n",
    "        divisor = x[:,0:1]\n",
    "        dividend = x[:,1:2]\n",
    "        length_of_divisor = x[:,2:3]\n",
    "        length_of_dividend = x[:,3:]\n",
    "        \n",
    "        # get sign\n",
    "        sign1 = self.model_separate_sign.predict(divisor)\n",
    "        sign2 = self.model_separate_sign.predict(dividend)\n",
    "        concat = torch.cat((sign1,sign2),1)\n",
    "        sign = self.model_mul_signs.predict(concat)\n",
    "        \n",
    "        \n",
    "        divisor = self.model_abs.predict(divisor)\n",
    "        dividend = self.model_abs.predict(dividend)\n",
    "        \n",
    "        X = []\n",
    "        for i in range (0,10):\n",
    "            temp = np.repeat(torch.tensor([[i]]),x.shape[0],axis = 0).type(torch.float64)\n",
    "            concat = torch.cat((temp,divisor,length_of_divisor),1)\n",
    "            answer = self.model_multiply.predict(concat)\n",
    "            X.append(answer)\n",
    "        \n",
    "        n = length_of_divisor.type(torch.IntTensor)\n",
    "        concat = torch.cat((dividend,length_of_dividend),1)\n",
    "        sep_dividend = self.model_separate.predict(concat)\n",
    "        quotient = [0]\n",
    "        remainder = torch.tensor([[0]]).type(torch.float64)\n",
    "        i = 0\n",
    "        ind_start = 0\n",
    "        ind_end = 1\n",
    "        while(i < length_of_dividend[0].type(torch.IntTensor) ) :\n",
    "            chunk = sep_dividend[:,ind_start:ind_end]\n",
    "            num_digits_chunk = torch.tensor([chunk.shape[-1]]).unsqueeze(-1).type(torch.float64)\n",
    "            chunk = self.model_merge.predict(chunk)\n",
    "            temp = self.fc2(remainder)\n",
    "            concat = torch.cat((temp,chunk),1)\n",
    "            chunk = self.model_add.predict(concat)\n",
    "            sub = []\n",
    "            for j in range(len(X)):\n",
    "                concat = torch.cat((chunk,X[j]),1)\n",
    "                temp = self.model_sub.predict(concat)\n",
    "                sub.append(temp)\n",
    "            \n",
    "            sub_prods = []\n",
    "            ones = torch.ones(length_of_divisor.shape)\n",
    "            concat = torch.cat((length_of_divisor,ones),1)\n",
    "            num_digits_temp = self.model_add.predict(concat)\n",
    "            for j in range(len(sub)):\n",
    "                concat = torch.cat((sub[j],sub[-1],num_digits_temp),1)\n",
    "                temp = self.model_multiply.predict(concat)\n",
    "                sub_prods.append(temp)\n",
    "            \n",
    "            max_pools = []\n",
    "            for j in range(len(sub)):\n",
    "                concat = torch.cat((sub[j],sub_prods[j]),1).unsqueeze(0)\n",
    "                temp = self.maxpool1d(concat).squeeze(0)\n",
    "                temp = self.fc1(temp)\n",
    "                max_pools.append(temp)\n",
    "                \n",
    "            max_pools = torch.tensor([max_pools])\n",
    "            _,q = torch.max(max_pools,1)\n",
    "            quotient.append(q)\n",
    "            \n",
    "            remainder = self.maxpool1d_2(max_pools.unsqueeze(0)).squeeze(0)\n",
    "            remainder = self.fc1(remainder)\n",
    "            ind_start = ind_end\n",
    "            ind_end = ind_start+1\n",
    "            \n",
    "            i+=1\n",
    "            \n",
    "        out = torch.tensor(quotient).type(torch.float64).unsqueeze(0)\n",
    "        q = self.model_merge.predict(out)\n",
    "        temp = torch.tensor([[out.shape[-1]]]).type(torch.float64)\n",
    "        concat = torch.cat((q,sign,temp),1)\n",
    "        out = self.model_mul_sign_abs.predict(concat)\n",
    "        out = torch.cat((out,remainder),1)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_divide = Net_divide(model_multiply,model_separate,model_sub,model_merge,model_add,model_separate_sign,model_mul_signs,model_abs,model_mul_sign_abs).type(torch.float64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[tensor(100., dtype=torch.float32), tensor(100., dtype=torch.float32), tensor(100., dtype=torch.float32), tensor(100., dtype=torch.float32), tensor(100., dtype=torch.float32), tensor(100., dtype=torch.float32)]\n"
     ]
    }
   ],
   "source": [
    "# test addition test files\n",
    "folder_path = '../EqnMaster-master/data/'\n",
    "grand_total_addition = 0\n",
    "\n",
    "file_names = ['2dig_test.p','3dig_test.p','4dig_test.p','5dig_test.p','6dig_test.p','7dig_test.p']\n",
    "accuracies_addition = []\n",
    "for file in file_names:\n",
    "    data = np.load(folder_path + file)\n",
    "    total=0\n",
    "    x1 = []\n",
    "    x2 = []\n",
    "    y = []\n",
    "    for tuple_obj in data:\n",
    "        total+=1\n",
    "        x = tuple_obj[0].split('+')\n",
    "        x1.append(int(x[0]))\n",
    "        x2.append(int(x[1]))\n",
    "        y.append(int(tuple_obj[1]))\n",
    "    \n",
    "    input_data = np.empty(shape=(total,2))\n",
    "    input_data[:,0] = x1\n",
    "    input_data[:,1] = x2\n",
    "    input_data = torch.from_numpy(input_data).type(torch.float64)\n",
    "    input_labels = torch.from_numpy(np.array(y)).type(torch.float64).unsqueeze(-1)\n",
    "    \n",
    "    \n",
    "    out = model_add.predict(input_data)\n",
    "    acc = (out==input_labels).float().sum() * 100.0 / out.shape[0]\n",
    "    accuracies_addition.append(acc)\n",
    "    grand_total_addition +=total\n",
    "\n",
    "print(accuracies_addition)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[tensor(100., dtype=torch.float32), tensor(100., dtype=torch.float32), tensor(100., dtype=torch.float32), tensor(100., dtype=torch.float32), tensor(100., dtype=torch.float32), tensor(100., dtype=torch.float32)]\n"
     ]
    }
   ],
   "source": [
    "# test addition dev files\n",
    "folder_path = '../EqnMaster-master/data/'\n",
    "grand_total_addition_dev = 0\n",
    "\n",
    "file_names = ['2dig_dev.p','3dig_dev.p','4dig_dev.p','5dig_dev.p','6dig_dev.p','7dig_dev.p']\n",
    "accuracies_addition_dev = []\n",
    "for file in file_names:\n",
    "    data = np.load(folder_path + file)\n",
    "    total=0\n",
    "    x1 = []\n",
    "    x2 = []\n",
    "    y = []\n",
    "    for tuple_obj in data:\n",
    "        total+=1\n",
    "        x = tuple_obj[0].split('+')\n",
    "        x1.append(int(x[0]))\n",
    "        x2.append(int(x[1]))\n",
    "        y.append(int(tuple_obj[1]))\n",
    "    \n",
    "    input_data = np.empty(shape=(total,2))\n",
    "    input_data[:,0] = x1\n",
    "    input_data[:,1] = x2\n",
    "    input_data = torch.from_numpy(input_data).type(torch.float64)\n",
    "    input_labels = torch.from_numpy(np.array(y)).type(torch.float64).unsqueeze(-1)\n",
    "    \n",
    "    \n",
    "    out = model_add.predict(input_data)\n",
    "    acc = (out==input_labels).float().sum() * 100.0 / out.shape[0]\n",
    "    accuracies_addition_dev.append(acc)\n",
    "    grand_total_addition_dev +=total\n",
    "\n",
    "print(accuracies_addition_dev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[tensor(100., dtype=torch.float32), tensor(100., dtype=torch.float32), tensor(100., dtype=torch.float32), tensor(100., dtype=torch.float32), tensor(100., dtype=torch.float32)]\n"
     ]
    }
   ],
   "source": [
    "# test subtraction test files\n",
    "folder_path = '../EqnMaster-master/data/'\n",
    "grand_total_subtraction = 0\n",
    "file_names = ['subtr_test.p','4subtr_test.p','5subtr_test.p','6subtr_test.p','7subtr_test.p']\n",
    "accuracies_subtraction = []\n",
    "for file in file_names:\n",
    "    data = np.load(folder_path + file)\n",
    "    total=0\n",
    "    x1 = []\n",
    "    x2 = []\n",
    "    y = []\n",
    "    for tuple_obj in data:\n",
    "        total+=1\n",
    "        x = tuple_obj[0].split('-')\n",
    "        x1.append(int(x[0]))\n",
    "        x2.append(int(x[1]))\n",
    "        y.append(int(tuple_obj[1]))\n",
    "    \n",
    "    input_data = np.empty(shape=(total,2))\n",
    "    input_data[:,0] = x1\n",
    "    input_data[:,1] = x2\n",
    "    input_data = torch.from_numpy(input_data).type(torch.float64)\n",
    "    input_labels = torch.from_numpy(np.array(y)).type(torch.float64).unsqueeze(-1)\n",
    "    \n",
    "    \n",
    "    out = model_sub.predict(input_data)\n",
    "    acc = (out==input_labels).float().sum() * 100.0 / out.shape[0]\n",
    "    accuracies_subtraction.append(acc)\n",
    "    grand_total_subtraction +=total\n",
    "    \n",
    "print(accuracies_subtraction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[tensor(100., dtype=torch.float32), tensor(100., dtype=torch.float32), tensor(100., dtype=torch.float32), tensor(100., dtype=torch.float32), tensor(100., dtype=torch.float32)]\n"
     ]
    }
   ],
   "source": [
    "# test subtraction dev files\n",
    "folder_path = '../EqnMaster-master/data/'\n",
    "grand_total_subtraction_dev = 0\n",
    "file_names = ['subtr_dev.p','4subtr_dev.p','5subtr_dev.p','6subtr_dev.p','7subtr_dev.p']\n",
    "accuracies_subtraction_dev = []\n",
    "for file in file_names:\n",
    "    data = np.load(folder_path + file)\n",
    "    total=0\n",
    "    x1 = []\n",
    "    x2 = []\n",
    "    y = []\n",
    "    for tuple_obj in data:\n",
    "        total+=1\n",
    "        x = tuple_obj[0].split('-')\n",
    "        x1.append(int(x[0]))\n",
    "        x2.append(int(x[1]))\n",
    "        y.append(int(tuple_obj[1]))\n",
    "    \n",
    "    input_data = np.empty(shape=(total,2))\n",
    "    input_data[:,0] = x1\n",
    "    input_data[:,1] = x2\n",
    "    input_data = torch.from_numpy(input_data).type(torch.float64)\n",
    "    input_labels = torch.from_numpy(np.array(y)).type(torch.float64).unsqueeze(-1)\n",
    "    \n",
    "    \n",
    "    out = model_sub.predict(input_data)\n",
    "    acc = (out==input_labels).float().sum() * 100.0 / out.shape[0]\n",
    "    accuracies_subtraction_dev.append(acc)\n",
    "    grand_total_subtraction_dev +=total\n",
    "\n",
    "print(accuracies_subtraction_dev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ammar\\.conda\\envs\\neuralnets\\lib\\site-packages\\ipykernel_launcher.py:9: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  if __name__ == '__main__':\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[tensor(100., dtype=torch.float32), tensor(100., dtype=torch.float32)]\n"
     ]
    }
   ],
   "source": [
    "# test multiplication\n",
    "folder_path = '../EqnMaster-master/data/'\n",
    "grand_total_multiplication = 0\n",
    "file_names = ['mult_test.p','bigmult_test.p']\n",
    "accuracies_multiplication = []\n",
    "for file in file_names:\n",
    "    data = np.load(folder_path + file)\n",
    "    total=0\n",
    "    x1 = []\n",
    "    x2 = []\n",
    "    y = []\n",
    "    for tuple_obj in data:\n",
    "        total+=1\n",
    "        x = tuple_obj[0].split('*')\n",
    "        x1.append(int(x[0]))\n",
    "        x2.append(int(x[1]))\n",
    "        y.append(int(tuple_obj[1]))\n",
    "    \n",
    "    input_data = np.empty(shape=(total,3))\n",
    "    input_data[:,0] = x1\n",
    "    input_data[:,1] = x2\n",
    "    input_data[:,2] = 3\n",
    "    input_data = torch.from_numpy(input_data).type(torch.float64)\n",
    "    input_labels = torch.from_numpy(np.array(y)).type(torch.float64).unsqueeze(-1)\n",
    "    \n",
    "    out = model_multiply.predict(input_data)\n",
    "    acc = (out==input_labels).float().sum() * 100.0 / out.shape[0]\n",
    "    accuracies_multiplication.append(acc)\n",
    "    grand_total_multiplication +=total\n",
    "    \n",
    "print(accuracies_multiplication)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ammar\\.conda\\envs\\neuralnets\\lib\\site-packages\\ipykernel_launcher.py:9: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  if __name__ == '__main__':\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[tensor(100., dtype=torch.float32), tensor(100., dtype=torch.float32)]\n"
     ]
    }
   ],
   "source": [
    "# test multiplication\n",
    "folder_path = '../EqnMaster-master/data/'\n",
    "grand_total_multiplication_dev = 0\n",
    "file_names = ['mult_dev.p','bigmult_dev.p']\n",
    "accuracies_multiplication_dev = []\n",
    "for file in file_names:\n",
    "    data = np.load(folder_path + file)\n",
    "    total=0\n",
    "    x1 = []\n",
    "    x2 = []\n",
    "    y = []\n",
    "    for tuple_obj in data:\n",
    "        total+=1\n",
    "        x = tuple_obj[0].split('*')\n",
    "        x1.append(int(x[0]))\n",
    "        x2.append(int(x[1]))\n",
    "        y.append(int(tuple_obj[1]))\n",
    "    \n",
    "    input_data = np.empty(shape=(total,3))\n",
    "    input_data[:,0] = x1\n",
    "    input_data[:,1] = x2\n",
    "    input_data[:,2] = 3\n",
    "    input_data = torch.from_numpy(input_data).type(torch.float64)\n",
    "    input_labels = torch.from_numpy(np.array(y)).type(torch.float64).unsqueeze(-1)\n",
    "    \n",
    "    out = model_multiply.predict(input_data)\n",
    "    acc = (out==input_labels).float().sum() * 100.0 / out.shape[0]\n",
    "    accuracies_multiplication_dev.append(acc)\n",
    "    grand_total_multiplication_dev +=total\n",
    "    \n",
    "print(accuracies_multiplication_dev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ammar\\.conda\\envs\\neuralnets\\lib\\site-packages\\ipykernel_launcher.py:9: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  if __name__ == '__main__':\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[tensor(100., dtype=torch.float32), tensor(100., dtype=torch.float32), tensor(100., dtype=torch.float32), tensor(100., dtype=torch.float32)]\n"
     ]
    }
   ],
   "source": [
    "# test multiplication\n",
    "folder_path = 'Dataset/'\n",
    "grand_total_multiplication_ours = 0\n",
    "file_names = ['data_mult_4_digits.npy','data_mult_5_digits.npy','data_mult_6_digits.npy','data_mult_7_digits.npy']\n",
    "file_names_labels = ['labels_mult_4_digits.npy','labels_mult_5_digits.npy','labels_mult_6_digits.npy','labels_mult_7_digits.npy']\n",
    "accuracies_multiplication_ours = []\n",
    "i = 0\n",
    "for file in file_names:\n",
    "    \n",
    "    input_data = np.load(folder_path + file)\n",
    "    input_labels = np.load(folder_path + file_names_labels[i])\n",
    "    input_data = torch.from_numpy(input_data).type(torch.float64)\n",
    "    input_labels = torch.from_numpy(input_labels).type(torch.float64)\n",
    "    \n",
    "    \n",
    "    out = model_multiply.predict(input_data)\n",
    "    acc = (out==input_labels).float().sum() * 100.0 / out.shape[0]\n",
    "    accuracies_multiplication_ours.append(acc)\n",
    "    grand_total_multiplication_ours += input_data.shape[0]\n",
    "    i+=1\n",
    "\n",
    "print(accuracies_multiplication_ours)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # test Division\n",
    "# folder_path = 'Dataset/'\n",
    "# grand_total_division = 0\n",
    "# accuracies_division = []\n",
    "# file_names = ['data_div_2_digits.npy','data_div_3_digits.npy','data_div_4_digits.npy','data_div_5_digits.npy','data_div_6_digits.npy','data_div_7_digits.npy']\n",
    "# file_names_labels = ['labels_div_2_digits.npy','labels_div_3_digits.npy','labels_div_4_digits.npy','labels_div_5_digits.npy','labels_div_6_digits.npy','labels_div_7_digits.npy']\n",
    "\n",
    "# i = 0\n",
    "# for file in file_names:\n",
    "    \n",
    "#     input_data = np.load(folder_path + file)\n",
    "#     input_labels = np.load(folder_path + file_names_labels[i])\n",
    "#     input_data = torch.from_numpy(input_data).type(torch.float64)\n",
    "#     input_labels = torch.from_numpy(input_labels).type(torch.float64)\n",
    "    \n",
    "#     correct = 0\n",
    "#     for j in range(input_data.shape[0]):\n",
    "#         out = model_divide.forward(input_data[j].unsqueeze(0))\n",
    "#         out = out.detach().numpy()\n",
    "#         temp = input_labels[j].unsqueeze(0).numpy()\n",
    "#         if out[0,0] == temp[0,0] and out[0,1] == temp[0,1]:\n",
    "#             correct+=1\n",
    "#         else:\n",
    "#             print(input_data[j])\n",
    "#             print(out,temp)\n",
    "    \n",
    "#     acc = correct * 100.0 / input_data.shape[0]\n",
    "#     accuracies_division.append(acc)\n",
    "#     grand_total_division += input_data.shape[0]\n",
    "#     i+=1\n",
    "    \n",
    "# accuracies_division"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
