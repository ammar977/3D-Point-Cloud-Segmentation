{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 10\n",
    "range_min = -9\n",
    "range_max = 9\n",
    "batch_size = 4 \n",
    "num_digits = 1\n",
    "num_train_samples = 100\n",
    "num_test_samples = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp = np.random.randint(low = range_min,high = range_max+1,size = (num_train_samples,2),dtype = np.int64)\n",
    "x_train = np.empty(shape = [num_train_samples,4])\n",
    "x_train[:,:2] = temp\n",
    "x_train[:,2] = [len(str(abs(x))) for x in temp[:,0]]\n",
    "x_train[:,3] = [len(str(abs(x))) for x in temp[:,1]]\n",
    "x_train[x_train[:,0] == 0] = np.random.randint(low=range_min,high=range_max+1)\n",
    "y_train = np.empty(shape = [num_train_samples,2])\n",
    "y_train[:,0] = np.array((np.abs(x_train[:,1]) / np.abs(x_train[:,0])))\n",
    "y_train[:,1] = np.array(np.abs(x_train[:,1]) % np.abs(x_train[:,0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = torch.from_numpy(x_train).type(torch.DoubleTensor)\n",
    "train_labels = torch.from_numpy(y_train).type(torch.LongTensor)\n",
    "# test_data = torch.from_numpy(x_test).type(torch.FloatTensor)\n",
    "# test_labels = torch.from_numpy(y_test).type(torch.LongTensor)\n",
    "torch.set_printoptions(precision = 10)\n",
    "torch.set_default_dtype(torch.float64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This model adds two numbers\n",
    "class Net_add(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net_add,self).__init__()\n",
    "        self.fc1 = nn.Linear(2,1,bias=False)\n",
    "        self.fc1.weight.data = torch.tensor([[1.0,1.0]]).type(torch.float64)\n",
    "    \n",
    "    def forward(self,x):\n",
    "        x = self.fc1(x)\n",
    "        return x\n",
    "    \n",
    "    def predict(self,x):\n",
    "        return self.forward(x).type(torch.float64)\n",
    "\n",
    "# model_add = torch.load('model_add').double()\n",
    "model_add = Net_add().type(torch.float64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This model subtracts two numbers\n",
    "class Net_sub(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net_sub,self).__init__()\n",
    "        self.fc1 = nn.Linear(2,1,bias=False)\n",
    "        self.fc1.weight.data = torch.tensor([[1,-1]]).type(torch.float64)\n",
    "    \n",
    "    def forward(self,x):\n",
    "        x = self.fc1(x)\n",
    "        return x\n",
    "    \n",
    "    def predict(self,x):\n",
    "        return self.forward(x).type(torch.float64)\n",
    "    \n",
    "# model_sub = torch.load('model_sub').double()\n",
    "# model_sub = torch.load('model_sub').type(torch.float64)\n",
    "model_sub = Net_sub().type(torch.float64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net,self).__init__()\n",
    "        self.fc1 = nn.Linear(2,30)\n",
    "        self.fc2 = nn.Linear(30,82)\n",
    "    \n",
    "    def forward(self,x):\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.softmax(self.fc2(x))\n",
    "        return x\n",
    "    \n",
    "    def predict(self,x):\n",
    "        pred = self.forward(x)\n",
    "        _,out = torch.max(pred,1)\n",
    "        return out.type(torch.float64)\n",
    "\n",
    "model_mul_0_9 = torch.load('mul_0_9').type(torch.float64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This model will give the absolute of a number\n",
    "# input: 1 number\n",
    "# output: absolute of that number \n",
    "\n",
    "class Net_abs(nn.Module):\n",
    "    def __init__(self,model_add,model_sub):\n",
    "        super(Net_abs,self).__init__()\n",
    "        \n",
    "        self.model_add = model_add\n",
    "        self.model_sub = model_sub\n",
    "        self.maxpool1d = nn.MaxPool1d(2)\n",
    "\n",
    "    \n",
    "    def forward(self,x):\n",
    "        concat = torch.cat((x,x),1)\n",
    "        add = self.model_add.predict(concat)\n",
    "        sub = self.model_sub.predict(concat)\n",
    "        \n",
    "        concat = torch.cat((add,sub),1).unsqueeze(0)\n",
    "        out = self.maxpool1d(concat).squeeze(0)\n",
    "        \n",
    "        concat = torch.cat((out,x),1)\n",
    "        out = model_sub.predict(concat)\n",
    "        \n",
    "        return out\n",
    "    \n",
    "    def predict(self,x):\n",
    "        return self.forward(x).type(torch.float64)\n",
    "    \n",
    "# model_abs = torch.load('model_abs').type(torch.float64)\n",
    "model_abs = Net_abs(model_add,model_sub).type(torch.float64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This model will separate a number into digits\n",
    "# input: 2 inputs - (number,num_digits)\n",
    "# output: separated digits (num_digits,)  \n",
    "\n",
    "class Net_separate(nn.Module):\n",
    "    def __init__(self,model_sub):\n",
    "        super(Net_separate,self).__init__()\n",
    "        \n",
    "        self.divide_by_10 = nn.Linear(1,1,bias=False).type(torch.float64)\n",
    "        self.divide_by_10.weight.data = torch.tensor([[0.1]]).type(torch.float64)\n",
    "\n",
    "        self.multiply_by_10 = nn.Linear(1,1,bias=False)\n",
    "        self.multiply_by_10.weight.data = torch.tensor([[10]]).type(torch.float64)\n",
    "        \n",
    "        self.model_sub = model_sub\n",
    "    \n",
    "    def forward(self,x):\n",
    "        input_number = x[:,0].unsqueeze(-1)\n",
    "        num_digits = x[:,1].unsqueeze(-1)\n",
    "        concat = []\n",
    "        data = input_number\n",
    "        for i in range(num_digits[0].type(torch.IntTensor)):\n",
    "            temp_data = self.divide_by_10(data)\n",
    "            temp_data = temp_data.floor()\n",
    "            temp = self.multiply_by_10(temp_data)\n",
    "            concat_temp = torch.cat((data,temp),1)\n",
    "            digit = self.model_sub.predict(concat_temp)\n",
    "            \n",
    "            concat.insert(0,digit)\n",
    "            data = temp_data\n",
    "        \n",
    "        out = torch.cat(concat,1)\n",
    "        return out\n",
    "    \n",
    "    def predict(self,x):\n",
    "        return self.forward(x).type(torch.float64)\n",
    "    \n",
    "# model_separate = torch.load('model_separate').double()  \n",
    "# model_separate = torch.load('model_separate').type(torch.float64)\n",
    "model_separate = Net_separate(model_sub).type(torch.float64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This model will give the product of two absolute numbers\n",
    "# input: 2 separated numbers : (2,num_digits)\n",
    "# output: product \n",
    "\n",
    "class Net_multiply_abs(nn.Module):\n",
    "    def __init__(self,model_mul_0_9,model_add,model_separate):\n",
    "        super(Net_multiply_abs,self).__init__()\n",
    "        \n",
    "        self.model_add = model_add\n",
    "        self.model_separate = model_separate\n",
    "        self.model_mul_0_9 = model_mul_0_9\n",
    "        \n",
    "        self.final_row_add_layers = []\n",
    "    \n",
    "    def forward(self,x):\n",
    "        n = x.shape[-1]\n",
    "        m = x.shape[-1]\n",
    "        \n",
    "        # get initial products\n",
    "        products = []\n",
    "        for i in range(x.shape[-1]):\n",
    "            mul = x[:,0,i:i+1]\n",
    "            for j in range(x.shape[-1]):\n",
    "                temp = x[:,1,j:j+1]\n",
    "                concat = torch.cat((temp,mul),1)\n",
    "                prod = self.model_mul_0_9.predict(concat)\n",
    "                products.insert(0,prod)\n",
    "                \n",
    "        # get individual rows\n",
    "        row_values = []\n",
    "        prod_index = 0\n",
    "        two = torch.from_numpy(np.repeat(np.array([2.0],ndmin = 2),x.shape[0],axis = 0)).type(torch.float64)\n",
    "        for r in range(n):\n",
    "            for i in range(m+1):\n",
    "                if i==0:\n",
    "                    temp = torch.cat((products[prod_index].unsqueeze(-1),two),1)\n",
    "                    sep = self.model_separate.predict(temp)\n",
    "                    carry = sep[:,0:1]\n",
    "                    ones_digit = sep[:,1:]\n",
    "                    row_values.append(ones_digit)\n",
    "                    prod_index+=1\n",
    "                    \n",
    "                elif i==m:\n",
    "                    row_values.append(carry)\n",
    "                else:\n",
    "                    concat = torch.cat((products[prod_index].unsqueeze(-1),carry),1)\n",
    "                    add = self.model_add(concat)\n",
    "                    concat = torch.cat((add,two),1)\n",
    "                    sep = self.model_separate.predict(concat)\n",
    "                    carry = sep[:,0:1]\n",
    "                    ones_digit = sep[:,1:]\n",
    "                    row_values.append(ones_digit)\n",
    "                    prod_index+=1\n",
    "        \n",
    "        final_row = []\n",
    "        current_ind = 0 \n",
    "        for i in range(m+n):\n",
    "            if i ==0:\n",
    "                final_row.insert(0,row_values[0])\n",
    "                temp = torch.cat((row_values[0],two),1)\n",
    "                sep = self.model_separate.predict(temp)\n",
    "                carry = sep[:,0:1]\n",
    "                current_ind+=1\n",
    "            else:\n",
    "                to_add = []\n",
    "                ones = []\n",
    "                to_add.append(row_values[current_ind])\n",
    "                ones.append(1)\n",
    "                to_add.append(carry)\n",
    "                ones.append(1)\n",
    "                \n",
    "                next_ind = current_ind + m\n",
    "                while(next_ind < n*(m+1) and next_ind%(m+1)!=0):\n",
    "                    to_add.append(row_values[next_ind])\n",
    "                    ones.append(1)\n",
    "                    next_ind+=m\n",
    "                if(next_ind < n * (m+1) and next_ind%(m+1)==0):\n",
    "                    to_add.append(row_values[next_ind])\n",
    "                    ones.append(1)\n",
    "\n",
    "                self.final_row_add_layers.append(nn.Linear(len(to_add),1,bias=False))\n",
    "                self.final_row_add_layers[-1].weight.data = torch.tensor([ones]).type(torch.float64)\n",
    "                concat = torch.cat(to_add,-1)\n",
    "                add = self.final_row_add_layers[-1](concat)\n",
    "                \n",
    "                temp = torch.cat((add,two),1)\n",
    "                sep = self.model_separate.predict(temp)\n",
    "                carry = sep[:,0:1]\n",
    "                ones_digit = sep[:,1:]\n",
    "                final_row.insert(0,ones_digit)\n",
    "                \n",
    "                if (current_ind + 1) % (m+1) !=0:\n",
    "                    current_ind+=1\n",
    "                else:\n",
    "                    current_ind+=m+1\n",
    "                \n",
    "                \n",
    "        out = torch.cat(final_row,-1)\n",
    "        return out\n",
    "    \n",
    "    def predict(self,x):\n",
    "        return self.forward(x).type(torch.float64)\n",
    "    \n",
    "# model_multiply_abs = torch.load('model_multiply_abs').double()\n",
    "model_multiply_abs = Net_multiply_abs(model_mul_0_9,model_add,model_separate).type(torch.float64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This model will join a list of digits to a number\n",
    "# input: 1 input - (num_digits,)\n",
    "# output: 1   \n",
    "\n",
    "class Net_merge(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net_merge,self).__init__()\n",
    "        self.layers = []\n",
    "        \n",
    "    def forward(self,x):\n",
    "        n = x.shape[-1]\n",
    "        i = 0 \n",
    "        add_list = []\n",
    "        ones = []\n",
    "        while(n>=1):\n",
    "            temp = x[:,n-1:n]\n",
    "            self.layers.append(nn.Linear(1,1,bias=False))\n",
    "            self.layers[-1].weight.data = torch.tensor([[10**i]]).type(torch.float64)\n",
    "            out = self.layers[-1](temp)\n",
    "            i +=1\n",
    "            n-=1\n",
    "            add_list.append(out)\n",
    "            ones.append(1.0)\n",
    "        \n",
    "        self.layers.append(nn.Linear(x.shape[-1],1,bias=False))\n",
    "        self.layers[-1].weight.data = torch.tensor([ones]).type(torch.float64)\n",
    "        concat = torch.cat(add_list,-1)\n",
    "        out = self.layers[-1](concat)\n",
    "        return out\n",
    "    \n",
    "    def predict(self,x):\n",
    "        return self.forward(x).type(torch.float64)\n",
    "\n",
    "# model_merge = torch.load('model_merge').double()\n",
    "model_merge = Net_merge().type(torch.float64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this model mulltiplies a single digit number with a sign (1,-1)\n",
    "# input: 2 numbers (2,)\n",
    "# output: single number \n",
    "class Net_mul_sign_0_9(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net_mul_sign_0_9,self).__init__()\n",
    "        self.fc1 = nn.Linear(2,10)\n",
    "        self.fc2 = nn.Linear(10,1)\n",
    "    \n",
    "    def forward(self,x):\n",
    "        x = F.softsign(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "    \n",
    "    def predict(self,x):\n",
    "        out = self.forward(x)\n",
    "        return torch.round(out).type(torch.float64)\n",
    "\n",
    "model_mul_sign_0_9 = torch.load('model_mul_sign_0_9').type(torch.float64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this model mulltiplies a number with a sign (1,-1)\n",
    "# input: 3 numbers (3,) - [number,sign,num_digits]\n",
    "# output: single number \n",
    "class Net_mul_sign_abs(nn.Module):\n",
    "    def __init__(self,model_separate,model_mul_sign_0_9):\n",
    "        super(Net_mul_sign_abs,self).__init__()\n",
    "        self.model_separate = model_separate\n",
    "        self.model_mul_sign_0_9 = model_mul_sign_0_9\n",
    "        self.multiply_2 = nn.Linear(1,1,bias = False)\n",
    "        self.multiply_2.weight.data = torch.tensor([[2.0]]).type(torch.float64)\n",
    "        self.layers = []\n",
    "    \n",
    "    def forward(self,x):\n",
    "        number = x[:,0].unsqueeze(-1)\n",
    "        sign = x[:,1].unsqueeze(-1)\n",
    "        num_digits = x[:,2].unsqueeze(-1)\n",
    "        \n",
    "        output_digits = self.multiply_2(num_digits)\n",
    "        concat = torch.cat((number,output_digits),1)\n",
    "        sep = self.model_separate.predict(concat)\n",
    "        products = []\n",
    "        i = 0\n",
    "        j = sep.shape[-1]\n",
    "        for n in range(j,0,-1):\n",
    "            temp = sep[:,n-1:n]\n",
    "            concat = torch.cat((temp,sign),1)\n",
    "            prod = self.model_mul_sign_0_9.predict(concat)\n",
    "            self.layers.append(nn.Linear(1,1,bias=False))\n",
    "            self.layers[-1].weight.data = torch.tensor([[10**i]]).type(torch.float64)\n",
    "            prod = self.layers[-1](prod)\n",
    "            products.append(prod)\n",
    "            i+=1\n",
    "        \n",
    "        concat = torch.cat(products,1)\n",
    "        self.layers.append(nn.Linear(1,1,bias=False))\n",
    "        self.layers[-1].weight.data = np.repeat(torch.tensor([[1.0]]),len(products),axis = -1).type(torch.float64)\n",
    "        out = self.layers[-1](concat)\n",
    "        return out\n",
    "    \n",
    "    def predict(self,x):\n",
    "        out = self.forward(x)\n",
    "        return out.type(torch.float64)\n",
    "    \n",
    "model_mul_sign_abs = Net_mul_sign_abs(model_separate,model_mul_sign_0_9).type(torch.float64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net_separate_sign(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net_separate_sign,self).__init__()\n",
    "        self.fc1 = nn.Linear(1,1,bias=False)\n",
    "        self.fc1.weight.data = torch.tensor([[1.01]]).type(torch.float64)\n",
    "        \n",
    "    def forward(self,x):\n",
    "        out = F.softsign(self.fc1(x))\n",
    "        return out\n",
    "    \n",
    "    def predict(self,x):\n",
    "        return self.forward(x).round().type(torch.float64)\n",
    "\n",
    "model_separate_sign = Net_separate_sign().type(torch.float64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net_mul_signs(nn.Module):\n",
    "    def __init__(self,model_add,model_sub,model_abs):\n",
    "        super(Net_mul_signs,self).__init__()\n",
    "        self.model_add = model_add\n",
    "        self.model_abs = model_abs\n",
    "        self.model_sub = model_sub\n",
    "        \n",
    "    def forward(self,x):\n",
    "        out = self.model_add.predict(x)\n",
    "        out = self.model_abs.predict(out)\n",
    "        \n",
    "        ones = torch.ones(out.shape).type(torch.float64)\n",
    "        out = torch.cat((out,ones),1)\n",
    "        out = self.model_sub.predict(out)\n",
    "        \n",
    "    \n",
    "        return out\n",
    "    \n",
    "    def predict(self,x):\n",
    "        return self.forward(x).type(torch.float64)\n",
    "\n",
    "model_mul_signs = Net_mul_signs(model_add,model_sub,model_abs).type(torch.float64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this model mulltiplies two numbers\n",
    "# input: 3 numbers (3,) - [number,number,num_digits]\n",
    "# output: single number \n",
    "class Net_multiply(nn.Module):\n",
    "    def __init__(self,model_separate_sign,model_mul_signs,model_abs,model_separate,model_multiply_abs,model_merge,model_mul_sign_abs):\n",
    "        super(Net_multiply,self).__init__()\n",
    "        self.model_separate_sign = model_separate_sign\n",
    "        self.model_mul_signs = model_mul_signs\n",
    "        self.model_abs = model_abs\n",
    "        self.model_separate = model_separate\n",
    "        self.model_multiply_abs = model_multiply_abs\n",
    "        self.model_merge = model_merge\n",
    "        self.model_mul_sign_abs = model_mul_sign_abs\n",
    "    \n",
    "    def forward(self,x):\n",
    "        numbers = x[:,:2]\n",
    "        num_digits = x[:,2:]\n",
    "        \n",
    "        # get sign\n",
    "        sign1 = self.model_separate_sign.predict(x[:,0:1])\n",
    "        sign2 = self.model_separate_sign.predict(x[:,1:2])\n",
    "        concat = torch.cat((sign1,sign2),1)\n",
    "        sign = self.model_mul_signs.predict(concat)\n",
    "        \n",
    "        # get absolutes\n",
    "        abs_inp1 = self.model_abs.predict(x[:,0:1])\n",
    "        abs_inp2 = self.model_abs.predict(x[:,1:2])\n",
    "        \n",
    "        # separate absolutes\n",
    "        concat = torch.cat((abs_inp1,num_digits),1)\n",
    "        sep_1 = self.model_separate.predict(concat).unsqueeze(1)\n",
    "        concat = torch.cat((abs_inp2,num_digits),1)\n",
    "        sep_2 = self.model_separate.predict(concat).unsqueeze(1)\n",
    "        \n",
    "        # multiply absolutes\n",
    "        concat = torch.cat((sep_1,sep_2),1)\n",
    "        abs_prod = self.model_multiply_abs(concat)\n",
    "        \n",
    "        # merge absolute product\n",
    "        merged_abs_prod = self.model_merge(abs_prod)\n",
    "        # multiply sign and absolute product\n",
    "        concat = torch.cat((merged_abs_prod,sign,num_digits),1)\n",
    "        out = self.model_mul_sign_abs.predict(concat)\n",
    "        \n",
    "        return out\n",
    "    \n",
    "    def predict(self,x):\n",
    "        out = self.forward(x)\n",
    "        return out.type(torch.float64)\n",
    "    \n",
    "model_multiply = Net_multiply(model_separate_sign,model_mul_signs,model_abs,model_separate,model_multiply_abs,model_merge,model_mul_sign_abs).type(torch.float64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this model mulltiplies two numbers\n",
    "# input: 3 numbers (3,) - [number,number,num_digits]\n",
    "# output: single number \n",
    "class Net_divide(nn.Module):\n",
    "    def __init__(self,model_multiply,model_separate,model_sub,model_merge,model_add,model_separate_sign,model_mul_signs,model_abs,model_mul_sign_abs):\n",
    "        super(Net_divide,self).__init__()\n",
    "        self.model_multiply = model_multiply\n",
    "        self.model_separate = model_separate\n",
    "        self.model_sub = model_sub\n",
    "        self.model_merge = model_merge\n",
    "        self.model_add = model_add\n",
    "        self.model_separate_sign = model_separate_sign\n",
    "        self.model_mul_signs = model_mul_signs\n",
    "        self.model_abs = model_abs\n",
    "        self.model_mul_sign_abs = model_mul_sign_abs\n",
    "        \n",
    "        self.maxpool1d = nn.MaxPool1d(2)\n",
    "        self.fc1 = nn.Linear(1,1,bias=False)\n",
    "        self.fc1.weight.data = torch.tensor([[-1.0]]).type(torch.float64)\n",
    "        self.maxpool1d_2 = nn.MaxPool1d(10)\n",
    "        self.fc2 = nn.Linear(1,1,bias=False)\n",
    "        self.fc2.weight.data =  torch.tensor([[10]]).type(torch.float64)\n",
    "    \n",
    "    def forward(self,x):\n",
    "        divisor = x[:,0:1]\n",
    "        dividend = x[:,1:2]\n",
    "        length_of_divisor = x[:,2:3]\n",
    "        length_of_dividend = x[:,3:]\n",
    "        \n",
    "        # get sign\n",
    "        sign1 = self.model_separate_sign.predict(divisor)\n",
    "        sign2 = self.model_separate_sign.predict(dividend)\n",
    "        concat = torch.cat((sign1,sign2),1)\n",
    "        sign = self.model_mul_signs.predict(concat)\n",
    "        \n",
    "        \n",
    "        divisor = self.model_abs.predict(divisor)\n",
    "        dividend = self.model_abs.predict(dividend)\n",
    "        \n",
    "        X = []\n",
    "        for i in range (0,10):\n",
    "            temp = np.repeat(torch.tensor([[i]]),x.shape[0],axis = 0).type(torch.float64)\n",
    "            concat = torch.cat((temp,divisor,length_of_divisor),1)\n",
    "            answer = self.model_multiply.predict(concat)\n",
    "            X.append(answer)\n",
    "        \n",
    "        n = length_of_divisor.type(torch.IntTensor)\n",
    "        concat = torch.cat((dividend,length_of_dividend),1)\n",
    "        sep_dividend = self.model_separate.predict(concat)\n",
    "        quotient = [0]\n",
    "        remainder = torch.tensor([[0]]).type(torch.float64)\n",
    "        i = 0\n",
    "        ind_start = 0\n",
    "        ind_end = 1\n",
    "        while(i < length_of_dividend[0].type(torch.IntTensor) ) :\n",
    "            chunk = sep_dividend[:,ind_start:ind_end]\n",
    "            num_digits_chunk = torch.tensor([chunk.shape[-1]]).unsqueeze(-1).type(torch.float64)\n",
    "            chunk = self.model_merge.predict(chunk)\n",
    "            temp = self.fc2(remainder)\n",
    "            concat = torch.cat((temp,chunk),1)\n",
    "            chunk = self.model_add.predict(concat)\n",
    "            sub = []\n",
    "            for j in range(len(X)):\n",
    "                concat = torch.cat((chunk,X[j]),1)\n",
    "                temp = self.model_sub.predict(concat)\n",
    "                sub.append(temp)\n",
    "            sub_prods = []\n",
    "            ones = torch.ones(length_of_divisor.shape)\n",
    "            concat = torch.cat((length_of_divisor,ones),1)\n",
    "            num_digits_temp = self.model_add.predict(concat)\n",
    "            for j in range(len(sub)):\n",
    "                concat = torch.cat((sub[j],sub[-1],num_digits_temp),1)\n",
    "                temp = self.model_multiply.predict(concat)\n",
    "                sub_prods.append(temp)\n",
    "            \n",
    "            max_pools = []\n",
    "            for j in range(len(sub)):\n",
    "                concat = torch.cat((sub[j],sub_prods[j]),1).unsqueeze(0)\n",
    "                temp = self.maxpool1d(concat).squeeze(0)\n",
    "                temp = self.fc1(temp)\n",
    "                max_pools.append(temp)\n",
    "                \n",
    "            max_pools = torch.tensor([max_pools])\n",
    "            _,q = torch.max(max_pools,1)\n",
    "            quotient.append(q)\n",
    "            \n",
    "            remainder = self.maxpool1d_2(max_pools.unsqueeze(0)).squeeze(0)\n",
    "            remainder = self.fc1(remainder)\n",
    "            ind_start = ind_end\n",
    "            ind_end = ind_start+1\n",
    "            \n",
    "            i+=1\n",
    "            \n",
    "        out = torch.tensor(quotient).type(torch.float64).unsqueeze(0)\n",
    "        q = self.model_merge.predict(out)\n",
    "        temp = torch.tensor([[out.shape[-1]]]).type(torch.float64)\n",
    "        concat = torch.cat((q,sign,temp),1)\n",
    "        out = self.model_mul_sign_abs.predict(concat)\n",
    "        out = torch.cat((out,remainder),1)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-1.,  8.,  1.,  1.]])\n",
      "tensor([[8, 0]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ammar\\.conda\\envs\\neuralnets\\lib\\site-packages\\ipykernel_launcher.py:9: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  if __name__ == '__main__':\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[-8.,  0.]], grad_fn=<CatBackward>)"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_divide = Net_divide(model_multiply,model_separate,model_sub,model_merge,model_add,model_separate_sign,model_mul_signs,model_abs,model_mul_sign_abs).type(torch.float64)\n",
    "# d = torch.tensor([[ 9, 98,  1,  2]]).type(torch.float64)\n",
    "n = 13\n",
    "print(train_data[n:n+1,:])\n",
    "print(train_labels[n:n+1])\n",
    "model_divide.forward(train_data[n:n+1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ammar\\.conda\\envs\\neuralnets\\lib\\site-packages\\ipykernel_launcher.py:9: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  if __name__ == '__main__':\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "correct\n",
      "correct\n",
      "correct\n",
      "correct\n",
      "correct\n",
      "correct\n",
      "correct\n",
      "wrong example : 8\n",
      "correct\n",
      "correct\n",
      "correct\n",
      "correct\n",
      "correct\n",
      "wrong example : 14\n",
      "correct\n",
      "correct\n",
      "correct\n",
      "correct\n",
      "correct\n",
      "correct\n",
      "wrong example : 21\n",
      "wrong example : 22\n",
      "correct\n",
      "correct\n",
      "wrong example : 25\n",
      "correct\n",
      "wrong example : 27\n",
      "correct\n",
      "correct\n",
      "correct\n",
      "correct\n",
      "correct\n",
      "correct\n",
      "correct\n",
      "correct\n",
      "wrong example : 36\n",
      "correct\n",
      "correct\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-122-7ed2cb0e647f>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mj\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mtrain_data\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m     \u001b[0mout\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel_divide\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_data\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mj\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mj\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m     \u001b[0mtemp\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain_labels\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mj\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munsqueeze\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m     \u001b[0mout\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mout\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdetach\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[0mcorrect\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-105-2c43931ec72c>\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m     42\u001b[0m             \u001b[0mtemp\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrepeat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0maxis\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfloat64\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     43\u001b[0m             \u001b[0mconcat\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtemp\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mdivisor\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mlength_of_divisor\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 44\u001b[1;33m             \u001b[0manswer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodel_multiply\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mconcat\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     45\u001b[0m             \u001b[0mX\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0manswer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     46\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-16-73336a682ac4>\u001b[0m in \u001b[0;36mpredict\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m     46\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     47\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 48\u001b[1;33m         \u001b[0mout\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     49\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mout\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfloat64\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     50\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-16-73336a682ac4>\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m     38\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     39\u001b[0m         \u001b[1;31m# merge absolute product\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 40\u001b[1;33m         \u001b[0mmerged_abs_prod\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodel_merge\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mabs_prod\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     41\u001b[0m         \u001b[1;31m# multiply sign and absolute product\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     42\u001b[0m         \u001b[0mconcat\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmerged_abs_prod\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0msign\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mnum_digits\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\neuralnets\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    491\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    492\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 493\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    494\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    495\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-11-586086675ab9>\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m     26\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mones\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfloat64\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     27\u001b[0m         \u001b[0mconcat\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0madd_list\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 28\u001b[1;33m         \u001b[0mout\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mconcat\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     29\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mout\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     30\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\neuralnets\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    491\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    492\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 493\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    494\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    495\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\neuralnets\\lib\\site-packages\\torch\\nn\\modules\\linear.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m     90\u001b[0m     \u001b[1;33m@\u001b[0m\u001b[0mweak_script_method\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     91\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 92\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     93\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     94\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mextra_repr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\neuralnets\\lib\\site-packages\\torch\\nn\\functional.py\u001b[0m in \u001b[0;36mlinear\u001b[1;34m(input, weight, bias)\u001b[0m\n\u001b[0;32m   1406\u001b[0m         \u001b[0mret\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0maddmm\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbias\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mt\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1407\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1408\u001b[1;33m         \u001b[0moutput\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmatmul\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mweight\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mt\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1409\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mbias\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1410\u001b[0m             \u001b[0moutput\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[0mbias\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for j in range(1,train_data.shape[0]):\n",
    "    out = model_divide.forward(train_data[j-1:j])\n",
    "    temp = train_labels[j-1].unsqueeze(0).numpy()\n",
    "    out = out.detach().numpy()\n",
    "    correct = 0\n",
    "    if out[0,0] == temp[0,0] and out[0,1] == temp[0,1]:\n",
    "        correct+=1\n",
    "        print('correct')\n",
    "    else:\n",
    "        print('wrong example :',j)\n",
    "print(correct)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
