{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# import Keras items\n",
    "from keras.models import Model\n",
    "from keras.layers import Dense,Lambda,Concatenate,Input,Flatten,Reshape\n",
    "# from keras.callbacks import ModelCheckpoint, EarlyStopping, CSVLogger, ReduceLROnPlateau, TensorBoard\n",
    "# from keras import backend as K\n",
    "# from keras.utils import to_categorical,plot_model\n",
    "# from keras.initializers import constant\n",
    "# from keras.constraints import MinMaxNor\n",
    "\n",
    "from itertools import combinations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCHS = 40\n",
    "BATCH_SIZE = 4\n",
    "range_min = 0\n",
    "range_max = 999\n",
    "train_samples = 1000\n",
    "test_samples = 200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def func(x):\n",
    "    out = np.zeros((x.shape[0],3))\n",
    "    for i in range(x.shape[0]):\n",
    "        out[i,0] = x[i,8] - x[i,10]\n",
    "        out[i,1] = x[i,4] - x[i,9]\n",
    "        out[i,2] = x[i,1] - x[i,6]\n",
    "        \n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def func2(x):\n",
    "    out = np.zeros((x.shape[0],3))\n",
    "    for i in range(x.shape[0]):\n",
    "        out[i,0] = x[i,9] - x[i,13] # bf - ce\n",
    "        out[i,1] = -(x[i,4] - x[i,12]) # af - cd\n",
    "        out[i,2] = x[i,3] - x[i,7] # ae - bd\n",
    "        \n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp = np.random.randint(low=range_min,high=range_max+1,size=(train_samples,6))\n",
    "x_train = np.zeros(shape=(train_samples,30))\n",
    "for i in range(train_samples):\n",
    "    count = 0\n",
    "    for j in range(6):\n",
    "        x = temp[i,j]\n",
    "        for k in range(6):\n",
    "            if j == k:\n",
    "                continue\n",
    "                \n",
    "            x_train[i,count] = x * temp[i,k]\n",
    "            count+=1\n",
    "            \n",
    "temp = np.random.randint(low=range_min,high=range_max+1,size=(test_samples,6))\n",
    "x_test = np.zeros(shape=(test_samples,30))\n",
    "for i in range(test_samples):\n",
    "    count = 0\n",
    "    for j in range(6):\n",
    "        x = temp[i,j]\n",
    "        for k in range(6):\n",
    "            if j == k:\n",
    "                continue\n",
    "                \n",
    "            x_test[i,count] = x * temp[i,k]\n",
    "            count+=1\n",
    "            \n",
    "y_train = func2(x_train)\n",
    "y_test = func2(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate dataset\n",
    "temp = np.random.randint(low=range_min,high=range_max+1,size=(train_samples,6))\n",
    "x_train = np.zeros(shape=(train_samples,15))\n",
    "for i in range(train_samples):\n",
    "    tuples = list(combinations(temp[i],2))\n",
    "    tuples = [x[0] * x[1] for x in tuples]\n",
    "    x_train[i] = np.array(tuples)[:]\n",
    "    \n",
    "y_train = func(x_train)\n",
    "\n",
    "temp = np.random.randint(low=range_min,high=range_max+1,size=(test_samples,6))\n",
    "x_test = np.zeros(shape=(test_samples,15))\n",
    "for i in range(test_samples):\n",
    "    tuples = list(combinations(temp[i],2))\n",
    "    tuples = [x[0] * x[1] for x in tuples]\n",
    "    x_test[i] = np.array(tuples)[:]\n",
    "    \n",
    "y_test = func(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def net(inputs):\n",
    "    input_data = Input(shape=inputs)\n",
    "    out = Dense(3,use_bias=False)(input_data)\n",
    "    \n",
    "    return Model(inputs = input_data,outputs = out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_7 (InputLayer)         (None, 30)                0         \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 3)                 90        \n",
      "=================================================================\n",
      "Total params: 90\n",
      "Trainable params: 90\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = net((30,))\n",
    "model.compile(loss='MSE',optimizer='adam',metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1000 samples, validate on 200 samples\n",
      "Epoch 1/36\n",
      "1000/1000 [==============================] - 0s 306us/step - loss: 165869692370.9440 - acc: 0.3060 - val_loss: 94166455705.6000 - val_acc: 0.5100\n",
      "Epoch 2/36\n",
      "1000/1000 [==============================] - 0s 172us/step - loss: 65633634392.0640 - acc: 0.6490 - val_loss: 41174144604.1600 - val_acc: 0.7800\n",
      "Epoch 3/36\n",
      "1000/1000 [==============================] - 0s 176us/step - loss: 30557519458.3040 - acc: 0.8190 - val_loss: 20464625684.4800 - val_acc: 0.8550\n",
      "Epoch 4/36\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 17664816668.4444 - acc: 0.876 - 0s 176us/step - loss: 17574055582.7200 - acc: 0.8770 - val_loss: 13141348428.8000 - val_acc: 0.8800\n",
      "Epoch 5/36\n",
      "1000/1000 [==============================] - 0s 240us/step - loss: 12761416636.9280 - acc: 0.8980 - val_loss: 10295615695.3600 - val_acc: 0.8900\n",
      "Epoch 6/36\n",
      "1000/1000 [==============================] - 0s 265us/step - loss: 10283826629.6320 - acc: 0.9050 - val_loss: 8425653928.9600 - val_acc: 0.9000\n",
      "Epoch 7/36\n",
      "1000/1000 [==============================] - 0s 246us/step - loss: 8422179483.9040 - acc: 0.9160 - val_loss: 6797742289.9200 - val_acc: 0.9250\n",
      "Epoch 8/36\n",
      "1000/1000 [==============================] - 0s 266us/step - loss: 6785510977.2800 - acc: 0.9220 - val_loss: 5404352993.2800 - val_acc: 0.9250\n",
      "Epoch 9/36\n",
      "1000/1000 [==============================] - 0s 216us/step - loss: 5344945838.6560 - acc: 0.9270 - val_loss: 4247027238.4000 - val_acc: 0.9300\n",
      "Epoch 10/36\n",
      "1000/1000 [==============================] - 0s 169us/step - loss: 4092019650.5600 - acc: 0.9360 - val_loss: 3168079330.5600 - val_acc: 0.9300\n",
      "Epoch 11/36\n",
      "1000/1000 [==============================] - 0s 245us/step - loss: 3051317620.3840 - acc: 0.9460 - val_loss: 2400460369.9200 - val_acc: 0.9350\n",
      "Epoch 12/36\n",
      "1000/1000 [==============================] - 0s 194us/step - loss: 2197642909.2480 - acc: 0.9510 - val_loss: 1697174272.6400 - val_acc: 0.9350\n",
      "Epoch 13/36\n",
      "1000/1000 [==============================] - 0s 185us/step - loss: 1532651891.3600 - acc: 0.9570 - val_loss: 1161969065.6000 - val_acc: 0.9450\n",
      "Epoch 14/36\n",
      "1000/1000 [==============================] - 0s 174us/step - loss: 1032331186.3040 - acc: 0.9640 - val_loss: 734496664.0000 - val_acc: 0.9650\n",
      "Epoch 15/36\n",
      "1000/1000 [==============================] - 0s 237us/step - loss: 666034588.0800 - acc: 0.9730 - val_loss: 481142915.0400 - val_acc: 0.9650\n",
      "Epoch 16/36\n",
      "1000/1000 [==============================] - 0s 237us/step - loss: 407497839.2800 - acc: 0.9780 - val_loss: 294381569.6800 - val_acc: 0.9750\n",
      "Epoch 17/36\n",
      "1000/1000 [==============================] - 0s 233us/step - loss: 235925919.3280 - acc: 0.9860 - val_loss: 161718990.4800 - val_acc: 0.9800\n",
      "Epoch 18/36\n",
      "1000/1000 [==============================] - 0s 227us/step - loss: 128783195.0240 - acc: 0.9880 - val_loss: 87010742.6800 - val_acc: 0.9850\n",
      "Epoch 19/36\n",
      "1000/1000 [==============================] - 0s 232us/step - loss: 66230307.9540 - acc: 0.9930 - val_loss: 41118740.0200 - val_acc: 0.9850\n",
      "Epoch 20/36\n",
      "1000/1000 [==============================] - 0s 226us/step - loss: 30597733.6980 - acc: 0.9950 - val_loss: 19156072.4000 - val_acc: 0.9900\n",
      "Epoch 21/36\n",
      "1000/1000 [==============================] - 0s 235us/step - loss: 13288214.9590 - acc: 0.9980 - val_loss: 7621811.6837 - val_acc: 0.9950\n",
      "Epoch 22/36\n",
      "1000/1000 [==============================] - 0s 231us/step - loss: 5162904.7210 - acc: 0.9980 - val_loss: 2903553.3638 - val_acc: 1.0000\n",
      "Epoch 23/36\n",
      "1000/1000 [==============================] - 0s 235us/step - loss: 1747994.0807 - acc: 0.9980 - val_loss: 1041723.7884 - val_acc: 1.0000\n",
      "Epoch 24/36\n",
      "1000/1000 [==============================] - 0s 246us/step - loss: 564458.4351 - acc: 0.9990 - val_loss: 238339.1541 - val_acc: 1.0000\n",
      "Epoch 25/36\n",
      "1000/1000 [==============================] - 0s 211us/step - loss: 140830.4615 - acc: 0.9990 - val_loss: 56883.8320 - val_acc: 1.0000\n",
      "Epoch 26/36\n",
      "1000/1000 [==============================] - 0s 251us/step - loss: 32318.0546 - acc: 1.0000 - val_loss: 12894.3495 - val_acc: 1.0000\n",
      "Epoch 27/36\n",
      "1000/1000 [==============================] - 0s 233us/step - loss: 5833.0767 - acc: 1.0000 - val_loss: 2421.8499 - val_acc: 1.0000\n",
      "Epoch 28/36\n",
      "1000/1000 [==============================] - 0s 234us/step - loss: 925.7347 - acc: 1.0000 - val_loss: 261.9064 - val_acc: 1.0000\n",
      "Epoch 29/36\n",
      "1000/1000 [==============================] - 0s 237us/step - loss: 113.4213 - acc: 1.0000 - val_loss: 30.9747 - val_acc: 1.0000\n",
      "Epoch 30/36\n",
      "1000/1000 [==============================] - 0s 232us/step - loss: 10.3572 - acc: 1.0000 - val_loss: 2.1382 - val_acc: 1.0000\n",
      "Epoch 31/36\n",
      "1000/1000 [==============================] - 0s 245us/step - loss: 0.7738 - acc: 1.0000 - val_loss: 0.1391 - val_acc: 1.0000\n",
      "Epoch 32/36\n",
      "1000/1000 [==============================] - 0s 218us/step - loss: 0.0724 - acc: 1.0000 - val_loss: 0.0361 - val_acc: 1.0000\n",
      "Epoch 33/36\n",
      "1000/1000 [==============================] - 0s 249us/step - loss: 0.0294 - acc: 1.0000 - val_loss: 0.0196 - val_acc: 1.0000\n",
      "Epoch 34/36\n",
      "1000/1000 [==============================] - 0s 249us/step - loss: 0.0184 - acc: 1.0000 - val_loss: 0.0144 - val_acc: 1.0000\n",
      "Epoch 35/36\n",
      "1000/1000 [==============================] - 0s 245us/step - loss: 0.0142 - acc: 1.0000 - val_loss: 0.0112 - val_acc: 1.0000\n",
      "Epoch 36/36\n",
      "1000/1000 [==============================] - 0s 231us/step - loss: 0.0129 - acc: 1.0000 - val_loss: 0.0124 - val_acc: 1.0000\n"
     ]
    }
   ],
   "source": [
    "out = model.fit(x_train,y_train,\n",
    "                batch_size=BATCH_SIZE,epochs=36,\n",
    "                validation_data = (x_test,y_test),verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.00522966, -0.09576197, -0.00224456],\n",
       "       [ 0.06236473,  0.08222419,  0.00779453],\n",
       "       [-0.01317273,  0.15182112,  0.03774474],\n",
       "       [-0.08200622, -0.28984204,  0.47226918],\n",
       "       [ 0.19897032,  0.33277747,  0.2805949 ],\n",
       "       [ 0.0052297 ,  0.09576203,  0.00224456],\n",
       "       [-0.09008911, -0.20640856,  0.08586637],\n",
       "       [-0.1325207 , -0.18708298, -0.6218502 ],\n",
       "       [-0.22400635,  0.31712112,  0.10735036],\n",
       "       [ 0.5118019 , -0.15424497,  0.19211707],\n",
       "       [-0.06236456, -0.08222401, -0.00779453],\n",
       "       [ 0.09008916,  0.20640852, -0.08586638],\n",
       "       [-0.20106779, -0.72781014,  0.03681654],\n",
       "       [-0.5456294 ,  0.16088825, -0.39139682],\n",
       "       [ 0.11445398, -0.16651456,  0.20971715],\n",
       "       [ 0.01317275, -0.15182103, -0.03774468],\n",
       "       [ 0.13252082,  0.18708283, -0.3781499 ],\n",
       "       [ 0.20106776, -0.27218997, -0.03681654],\n",
       "       [ 0.06622057,  0.15154195,  0.22442633],\n",
       "       [-0.24209519,  0.3004822 , -0.03866903],\n",
       "       [ 0.08200616,  0.2898421 ,  0.52773064],\n",
       "       [ 0.22400638, -0.31712118, -0.10735029],\n",
       "       [-0.4543707 , -0.16088822,  0.39139688],\n",
       "       [-0.06622064, -0.15154193, -0.22442618],\n",
       "       [-0.20120025, -0.00412594,  0.26119074],\n",
       "       [-0.19897026,  0.66722226, -0.2805948 ],\n",
       "       [ 0.48819777,  0.15424505, -0.19211708],\n",
       "       [-0.11445395,  0.16651468, -0.20971721],\n",
       "       [ 0.24209519, -0.30048212,  0.03866902],\n",
       "       [ 0.2012004 ,  0.004126  , -0.26119077]], dtype=float32)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.get_weights()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save_weights('regression_test.h5')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
